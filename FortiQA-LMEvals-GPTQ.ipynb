{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "096548f0-94e5-4daf-9925-49cede0ff902",
   "metadata": {},
   "source": [
    "# FortiQA LM-Eval-Harness Experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6971443e-e331-4445-8ebe-dbab8121ebc3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting git+https://github.com/EleutherAI/lm-evaluation-harness.git\n",
      "  Cloning https://github.com/EleutherAI/lm-evaluation-harness.git to /tmp/pip-req-build-76871vin\n",
      "  Running command git clone --filter=blob:none --quiet https://github.com/EleutherAI/lm-evaluation-harness.git /tmp/pip-req-build-76871vin\n",
      "  Resolved https://github.com/EleutherAI/lm-evaluation-harness.git to commit a9a0e3caaeecf3fb479c7c224fffd0af30a6ed96\n",
      "  Installing build dependencies ... \u001b[?25ldone\n",
      "\u001b[?25h  Getting requirements to build wheel ... \u001b[?25ldone\n",
      "\u001b[?25h  Preparing metadata (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25hRequirement already satisfied: accelerate>=0.26.0 in /opt/conda/lib/python3.11/site-packages (from lm_eval==0.4.7) (1.4.0)\n",
      "Requirement already satisfied: evaluate in /opt/conda/lib/python3.11/site-packages (from lm_eval==0.4.7) (0.4.3)\n",
      "Requirement already satisfied: datasets>=2.16.0 in /opt/conda/lib/python3.11/site-packages (from lm_eval==0.4.7) (3.3.2)\n",
      "Requirement already satisfied: jsonlines in /opt/conda/lib/python3.11/site-packages (from lm_eval==0.4.7) (4.0.0)\n",
      "Requirement already satisfied: numexpr in /opt/conda/lib/python3.11/site-packages (from lm_eval==0.4.7) (2.9.0)\n",
      "Requirement already satisfied: peft>=0.2.0 in /opt/conda/lib/python3.11/site-packages (from lm_eval==0.4.7) (0.14.0)\n",
      "Requirement already satisfied: pybind11>=2.6.2 in /opt/conda/lib/python3.11/site-packages (from lm_eval==0.4.7) (2.13.6)\n",
      "Requirement already satisfied: pytablewriter in /opt/conda/lib/python3.11/site-packages (from lm_eval==0.4.7) (1.2.1)\n",
      "Requirement already satisfied: rouge-score>=0.0.4 in /opt/conda/lib/python3.11/site-packages (from lm_eval==0.4.7) (0.1.2)\n",
      "Requirement already satisfied: sacrebleu>=1.5.0 in /opt/conda/lib/python3.11/site-packages (from lm_eval==0.4.7) (2.5.1)\n",
      "Requirement already satisfied: scikit-learn>=0.24.1 in /opt/conda/lib/python3.11/site-packages (from lm_eval==0.4.7) (1.5.0)\n",
      "Requirement already satisfied: sqlitedict in /opt/conda/lib/python3.11/site-packages (from lm_eval==0.4.7) (2.1.0)\n",
      "Requirement already satisfied: torch>=1.8 in /opt/conda/lib/python3.11/site-packages (from lm_eval==0.4.7) (2.3.0+cu121)\n",
      "Requirement already satisfied: tqdm-multiprocess in /opt/conda/lib/python3.11/site-packages (from lm_eval==0.4.7) (0.0.11)\n",
      "Requirement already satisfied: transformers>=4.1 in /opt/conda/lib/python3.11/site-packages (from lm_eval==0.4.7) (4.49.0)\n",
      "Requirement already satisfied: zstandard in /opt/conda/lib/python3.11/site-packages (from lm_eval==0.4.7) (0.19.0)\n",
      "Requirement already satisfied: dill in /opt/conda/lib/python3.11/site-packages (from lm_eval==0.4.7) (0.3.8)\n",
      "Requirement already satisfied: word2number in /opt/conda/lib/python3.11/site-packages (from lm_eval==0.4.7) (1.1)\n",
      "Requirement already satisfied: more_itertools in /opt/conda/lib/python3.11/site-packages (from lm_eval==0.4.7) (10.6.0)\n",
      "Requirement already satisfied: numpy<3.0.0,>=1.17 in /opt/conda/lib/python3.11/site-packages (from accelerate>=0.26.0->lm_eval==0.4.7) (1.24.3)\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.11/site-packages (from accelerate>=0.26.0->lm_eval==0.4.7) (24.2)\n",
      "Requirement already satisfied: psutil in /opt/conda/lib/python3.11/site-packages (from accelerate>=0.26.0->lm_eval==0.4.7) (5.9.8)\n",
      "Requirement already satisfied: pyyaml in /opt/conda/lib/python3.11/site-packages (from accelerate>=0.26.0->lm_eval==0.4.7) (6.0.1)\n",
      "Requirement already satisfied: huggingface-hub>=0.21.0 in /opt/conda/lib/python3.11/site-packages (from accelerate>=0.26.0->lm_eval==0.4.7) (0.29.1)\n",
      "Requirement already satisfied: safetensors>=0.4.3 in /opt/conda/lib/python3.11/site-packages (from accelerate>=0.26.0->lm_eval==0.4.7) (0.5.2)\n",
      "Requirement already satisfied: filelock in /opt/conda/lib/python3.11/site-packages (from datasets>=2.16.0->lm_eval==0.4.7) (3.13.1)\n",
      "Requirement already satisfied: pyarrow>=15.0.0 in /opt/conda/lib/python3.11/site-packages (from datasets>=2.16.0->lm_eval==0.4.7) (16.1.0)\n",
      "Requirement already satisfied: pandas in /opt/conda/lib/python3.11/site-packages (from datasets>=2.16.0->lm_eval==0.4.7) (2.2.2)\n",
      "Requirement already satisfied: requests>=2.32.2 in /opt/conda/lib/python3.11/site-packages (from datasets>=2.16.0->lm_eval==0.4.7) (2.32.3)\n",
      "Requirement already satisfied: tqdm>=4.66.3 in /opt/conda/lib/python3.11/site-packages (from datasets>=2.16.0->lm_eval==0.4.7) (4.66.4)\n",
      "Requirement already satisfied: xxhash in /opt/conda/lib/python3.11/site-packages (from datasets>=2.16.0->lm_eval==0.4.7) (3.5.0)\n",
      "Requirement already satisfied: multiprocess<0.70.17 in /opt/conda/lib/python3.11/site-packages (from datasets>=2.16.0->lm_eval==0.4.7) (0.70.16)\n",
      "Requirement already satisfied: fsspec<=2024.12.0,>=2023.1.0 in /opt/conda/lib/python3.11/site-packages (from fsspec[http]<=2024.12.0,>=2023.1.0->datasets>=2.16.0->lm_eval==0.4.7) (2024.5.0)\n",
      "Requirement already satisfied: aiohttp in /opt/conda/lib/python3.11/site-packages (from datasets>=2.16.0->lm_eval==0.4.7) (3.9.5)\n",
      "Requirement already satisfied: absl-py in /opt/conda/lib/python3.11/site-packages (from rouge-score>=0.0.4->lm_eval==0.4.7) (2.1.0)\n",
      "Requirement already satisfied: nltk in /opt/conda/lib/python3.11/site-packages (from rouge-score>=0.0.4->lm_eval==0.4.7) (3.9.1)\n",
      "Requirement already satisfied: six>=1.14.0 in /opt/conda/lib/python3.11/site-packages (from rouge-score>=0.0.4->lm_eval==0.4.7) (1.16.0)\n",
      "Requirement already satisfied: portalocker in /opt/conda/lib/python3.11/site-packages (from sacrebleu>=1.5.0->lm_eval==0.4.7) (3.1.1)\n",
      "Requirement already satisfied: regex in /opt/conda/lib/python3.11/site-packages (from sacrebleu>=1.5.0->lm_eval==0.4.7) (2024.5.15)\n",
      "Requirement already satisfied: tabulate>=0.8.9 in /opt/conda/lib/python3.11/site-packages (from sacrebleu>=1.5.0->lm_eval==0.4.7) (0.9.0)\n",
      "Requirement already satisfied: colorama in /opt/conda/lib/python3.11/site-packages (from sacrebleu>=1.5.0->lm_eval==0.4.7) (0.4.6)\n",
      "Requirement already satisfied: lxml in /opt/conda/lib/python3.11/site-packages (from sacrebleu>=1.5.0->lm_eval==0.4.7) (5.3.1)\n",
      "Requirement already satisfied: scipy>=1.6.0 in /opt/conda/lib/python3.11/site-packages (from scikit-learn>=0.24.1->lm_eval==0.4.7) (1.13.1)\n",
      "Requirement already satisfied: joblib>=1.2.0 in /opt/conda/lib/python3.11/site-packages (from scikit-learn>=0.24.1->lm_eval==0.4.7) (1.4.2)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in /opt/conda/lib/python3.11/site-packages (from scikit-learn>=0.24.1->lm_eval==0.4.7) (3.5.0)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in /opt/conda/lib/python3.11/site-packages (from torch>=1.8->lm_eval==0.4.7) (4.11.0)\n",
      "Requirement already satisfied: sympy in /opt/conda/lib/python3.11/site-packages (from torch>=1.8->lm_eval==0.4.7) (1.12)\n",
      "Requirement already satisfied: networkx in /opt/conda/lib/python3.11/site-packages (from torch>=1.8->lm_eval==0.4.7) (3.3)\n",
      "Requirement already satisfied: jinja2 in /opt/conda/lib/python3.11/site-packages (from torch>=1.8->lm_eval==0.4.7) (3.1.4)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /opt/conda/lib/python3.11/site-packages (from torch>=1.8->lm_eval==0.4.7) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /opt/conda/lib/python3.11/site-packages (from torch>=1.8->lm_eval==0.4.7) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /opt/conda/lib/python3.11/site-packages (from torch>=1.8->lm_eval==0.4.7) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /opt/conda/lib/python3.11/site-packages (from torch>=1.8->lm_eval==0.4.7) (8.9.2.26)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /opt/conda/lib/python3.11/site-packages (from torch>=1.8->lm_eval==0.4.7) (12.1.3.1)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /opt/conda/lib/python3.11/site-packages (from torch>=1.8->lm_eval==0.4.7) (11.0.2.54)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /opt/conda/lib/python3.11/site-packages (from torch>=1.8->lm_eval==0.4.7) (10.3.2.106)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /opt/conda/lib/python3.11/site-packages (from torch>=1.8->lm_eval==0.4.7) (11.4.5.107)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /opt/conda/lib/python3.11/site-packages (from torch>=1.8->lm_eval==0.4.7) (12.1.0.106)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.20.5 in /opt/conda/lib/python3.11/site-packages (from torch>=1.8->lm_eval==0.4.7) (2.20.5)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /opt/conda/lib/python3.11/site-packages (from torch>=1.8->lm_eval==0.4.7) (12.1.105)\n",
      "Requirement already satisfied: triton==2.3.0 in /opt/conda/lib/python3.11/site-packages (from torch>=1.8->lm_eval==0.4.7) (2.3.0)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12 in /opt/conda/lib/python3.11/site-packages (from nvidia-cusolver-cu12==11.4.5.107->torch>=1.8->lm_eval==0.4.7) (12.3.101)\n",
      "Requirement already satisfied: tokenizers<0.22,>=0.21 in /opt/conda/lib/python3.11/site-packages (from transformers>=4.1->lm_eval==0.4.7) (0.21.0)\n",
      "Requirement already satisfied: attrs>=19.2.0 in /opt/conda/lib/python3.11/site-packages (from jsonlines->lm_eval==0.4.7) (23.2.0)\n",
      "Requirement already satisfied: setuptools>=38.3.0 in /opt/conda/lib/python3.11/site-packages (from pytablewriter->lm_eval==0.4.7) (70.0.0)\n",
      "Requirement already satisfied: DataProperty<2,>=1.1.0 in /opt/conda/lib/python3.11/site-packages (from pytablewriter->lm_eval==0.4.7) (1.1.0)\n",
      "Requirement already satisfied: mbstrdecoder<2,>=1.0.0 in /opt/conda/lib/python3.11/site-packages (from pytablewriter->lm_eval==0.4.7) (1.1.4)\n",
      "Requirement already satisfied: pathvalidate<4,>=2.3.0 in /opt/conda/lib/python3.11/site-packages (from pytablewriter->lm_eval==0.4.7) (3.2.3)\n",
      "Requirement already satisfied: tabledata<2,>=1.3.1 in /opt/conda/lib/python3.11/site-packages (from pytablewriter->lm_eval==0.4.7) (1.3.4)\n",
      "Requirement already satisfied: tcolorpy<1,>=0.0.5 in /opt/conda/lib/python3.11/site-packages (from pytablewriter->lm_eval==0.4.7) (0.1.7)\n",
      "Requirement already satisfied: typepy<2,>=1.3.2 in /opt/conda/lib/python3.11/site-packages (from typepy[datetime]<2,>=1.3.2->pytablewriter->lm_eval==0.4.7) (1.3.4)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /opt/conda/lib/python3.11/site-packages (from aiohttp->datasets>=2.16.0->lm_eval==0.4.7) (1.3.1)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /opt/conda/lib/python3.11/site-packages (from aiohttp->datasets>=2.16.0->lm_eval==0.4.7) (1.4.1)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /opt/conda/lib/python3.11/site-packages (from aiohttp->datasets>=2.16.0->lm_eval==0.4.7) (6.0.5)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /opt/conda/lib/python3.11/site-packages (from aiohttp->datasets>=2.16.0->lm_eval==0.4.7) (1.9.4)\n",
      "Requirement already satisfied: chardet<6,>=3.0.4 in /opt/conda/lib/python3.11/site-packages (from mbstrdecoder<2,>=1.0.0->pytablewriter->lm_eval==0.4.7) (5.2.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.11/site-packages (from requests>=2.32.2->datasets>=2.16.0->lm_eval==0.4.7) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.11/site-packages (from requests>=2.32.2->datasets>=2.16.0->lm_eval==0.4.7) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.11/site-packages (from requests>=2.32.2->datasets>=2.16.0->lm_eval==0.4.7) (2.2.1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.11/site-packages (from requests>=2.32.2->datasets>=2.16.0->lm_eval==0.4.7) (2024.2.2)\n",
      "Requirement already satisfied: python-dateutil<3.0.0,>=2.8.0 in /opt/conda/lib/python3.11/site-packages (from typepy[datetime]<2,>=1.3.2->pytablewriter->lm_eval==0.4.7) (2.9.0)\n",
      "Requirement already satisfied: pytz>=2018.9 in /opt/conda/lib/python3.11/site-packages (from typepy[datetime]<2,>=1.3.2->pytablewriter->lm_eval==0.4.7) (2024.1)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.11/site-packages (from jinja2->torch>=1.8->lm_eval==0.4.7) (2.1.5)\n",
      "Requirement already satisfied: click in /opt/conda/lib/python3.11/site-packages (from nltk->rouge-score>=0.0.4->lm_eval==0.4.7) (8.1.7)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /opt/conda/lib/python3.11/site-packages (from pandas->datasets>=2.16.0->lm_eval==0.4.7) (2024.1)\n",
      "Requirement already satisfied: mpmath>=0.19 in /opt/conda/lib/python3.11/site-packages (from sympy->torch>=1.8->lm_eval==0.4.7) (1.3.0)\n",
      "Requirement already satisfied: datasets in /opt/conda/lib/python3.11/site-packages (3.3.2)\n",
      "Requirement already satisfied: filelock in /opt/conda/lib/python3.11/site-packages (from datasets) (3.13.1)\n",
      "Requirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.11/site-packages (from datasets) (1.24.3)\n",
      "Requirement already satisfied: pyarrow>=15.0.0 in /opt/conda/lib/python3.11/site-packages (from datasets) (16.1.0)\n",
      "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /opt/conda/lib/python3.11/site-packages (from datasets) (0.3.8)\n",
      "Requirement already satisfied: pandas in /opt/conda/lib/python3.11/site-packages (from datasets) (2.2.2)\n",
      "Requirement already satisfied: requests>=2.32.2 in /opt/conda/lib/python3.11/site-packages (from datasets) (2.32.3)\n",
      "Requirement already satisfied: tqdm>=4.66.3 in /opt/conda/lib/python3.11/site-packages (from datasets) (4.66.4)\n",
      "Requirement already satisfied: xxhash in /opt/conda/lib/python3.11/site-packages (from datasets) (3.5.0)\n",
      "Requirement already satisfied: multiprocess<0.70.17 in /opt/conda/lib/python3.11/site-packages (from datasets) (0.70.16)\n",
      "Requirement already satisfied: fsspec<=2024.12.0,>=2023.1.0 in /opt/conda/lib/python3.11/site-packages (from fsspec[http]<=2024.12.0,>=2023.1.0->datasets) (2024.5.0)\n",
      "Requirement already satisfied: aiohttp in /opt/conda/lib/python3.11/site-packages (from datasets) (3.9.5)\n",
      "Requirement already satisfied: huggingface-hub>=0.24.0 in /opt/conda/lib/python3.11/site-packages (from datasets) (0.29.1)\n",
      "Requirement already satisfied: packaging in /opt/conda/lib/python3.11/site-packages (from datasets) (24.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.11/site-packages (from datasets) (6.0.1)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /opt/conda/lib/python3.11/site-packages (from aiohttp->datasets) (1.3.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /opt/conda/lib/python3.11/site-packages (from aiohttp->datasets) (23.2.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /opt/conda/lib/python3.11/site-packages (from aiohttp->datasets) (1.4.1)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /opt/conda/lib/python3.11/site-packages (from aiohttp->datasets) (6.0.5)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /opt/conda/lib/python3.11/site-packages (from aiohttp->datasets) (1.9.4)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.11/site-packages (from huggingface-hub>=0.24.0->datasets) (4.11.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.11/site-packages (from requests>=2.32.2->datasets) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.11/site-packages (from requests>=2.32.2->datasets) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.11/site-packages (from requests>=2.32.2->datasets) (2.2.1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.11/site-packages (from requests>=2.32.2->datasets) (2024.2.2)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /opt/conda/lib/python3.11/site-packages (from pandas->datasets) (2.9.0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.11/site-packages (from pandas->datasets) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /opt/conda/lib/python3.11/site-packages (from pandas->datasets) (2024.1)\n",
      "Requirement already satisfied: six>=1.5 in /opt/conda/lib/python3.11/site-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.16.0)\n",
      "Requirement already satisfied: huggingface_hub in /opt/conda/lib/python3.11/site-packages (0.29.1)\n",
      "Requirement already satisfied: filelock in /opt/conda/lib/python3.11/site-packages (from huggingface_hub) (3.13.1)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /opt/conda/lib/python3.11/site-packages (from huggingface_hub) (2024.5.0)\n",
      "Requirement already satisfied: packaging>=20.9 in /opt/conda/lib/python3.11/site-packages (from huggingface_hub) (24.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.11/site-packages (from huggingface_hub) (6.0.1)\n",
      "Requirement already satisfied: requests in /opt/conda/lib/python3.11/site-packages (from huggingface_hub) (2.32.3)\n",
      "Requirement already satisfied: tqdm>=4.42.1 in /opt/conda/lib/python3.11/site-packages (from huggingface_hub) (4.66.4)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.11/site-packages (from huggingface_hub) (4.11.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.11/site-packages (from requests->huggingface_hub) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.11/site-packages (from requests->huggingface_hub) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.11/site-packages (from requests->huggingface_hub) (2.2.1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.11/site-packages (from requests->huggingface_hub) (2024.2.2)\n",
      "Requirement already satisfied: datasets in /opt/conda/lib/python3.11/site-packages (3.3.2)\n",
      "Requirement already satisfied: filelock in /opt/conda/lib/python3.11/site-packages (from datasets) (3.13.1)\n",
      "Requirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.11/site-packages (from datasets) (1.24.3)\n",
      "Requirement already satisfied: pyarrow>=15.0.0 in /opt/conda/lib/python3.11/site-packages (from datasets) (16.1.0)\n",
      "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /opt/conda/lib/python3.11/site-packages (from datasets) (0.3.8)\n",
      "Requirement already satisfied: pandas in /opt/conda/lib/python3.11/site-packages (from datasets) (2.2.2)\n",
      "Requirement already satisfied: requests>=2.32.2 in /opt/conda/lib/python3.11/site-packages (from datasets) (2.32.3)\n",
      "Requirement already satisfied: tqdm>=4.66.3 in /opt/conda/lib/python3.11/site-packages (from datasets) (4.66.4)\n",
      "Requirement already satisfied: xxhash in /opt/conda/lib/python3.11/site-packages (from datasets) (3.5.0)\n",
      "Requirement already satisfied: multiprocess<0.70.17 in /opt/conda/lib/python3.11/site-packages (from datasets) (0.70.16)\n",
      "Requirement already satisfied: fsspec<=2024.12.0,>=2023.1.0 in /opt/conda/lib/python3.11/site-packages (from fsspec[http]<=2024.12.0,>=2023.1.0->datasets) (2024.5.0)\n",
      "Requirement already satisfied: aiohttp in /opt/conda/lib/python3.11/site-packages (from datasets) (3.9.5)\n",
      "Requirement already satisfied: huggingface-hub>=0.24.0 in /opt/conda/lib/python3.11/site-packages (from datasets) (0.29.1)\n",
      "Requirement already satisfied: packaging in /opt/conda/lib/python3.11/site-packages (from datasets) (24.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.11/site-packages (from datasets) (6.0.1)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /opt/conda/lib/python3.11/site-packages (from aiohttp->datasets) (1.3.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /opt/conda/lib/python3.11/site-packages (from aiohttp->datasets) (23.2.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /opt/conda/lib/python3.11/site-packages (from aiohttp->datasets) (1.4.1)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /opt/conda/lib/python3.11/site-packages (from aiohttp->datasets) (6.0.5)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /opt/conda/lib/python3.11/site-packages (from aiohttp->datasets) (1.9.4)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.11/site-packages (from huggingface-hub>=0.24.0->datasets) (4.11.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.11/site-packages (from requests>=2.32.2->datasets) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.11/site-packages (from requests>=2.32.2->datasets) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.11/site-packages (from requests>=2.32.2->datasets) (2.2.1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.11/site-packages (from requests>=2.32.2->datasets) (2024.2.2)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /opt/conda/lib/python3.11/site-packages (from pandas->datasets) (2.9.0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.11/site-packages (from pandas->datasets) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /opt/conda/lib/python3.11/site-packages (from pandas->datasets) (2024.1)\n",
      "Requirement already satisfied: six>=1.5 in /opt/conda/lib/python3.11/site-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.16.0)\n"
     ]
    }
   ],
   "source": [
    "# This doesn't save? pip install -r requirements.txt # save in one file\n",
    "# Install LM-Eval\n",
    "!pip install git+https://github.com/EleutherAI/lm-evaluation-harness.git\n",
    "# Install HuggingFace Dataset Loader\n",
    "!pip install datasets # produces an error and does not allow dataset to load\n",
    "# pip show datasets huggingface_hub # shows outdated version 0.23.2\n",
    "!pip install --upgrade huggingface_hub\n",
    "!pip install --upgrade datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95ca8dbd-76f5-435a-b32a-019024450b9e",
   "metadata": {},
   "source": [
    "## Set up SecQA Task"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5a3b56ae-d586-4a21-b0b3-cd9201744584",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DatasetDict({\n",
      "    dev: Dataset({\n",
      "        features: ['Question', 'A', 'B', 'C', 'D', 'Answer', 'Explanation'],\n",
      "        num_rows: 5\n",
      "    })\n",
      "    val: Dataset({\n",
      "        features: ['Question', 'A', 'B', 'C', 'D', 'Answer', 'Explanation'],\n",
      "        num_rows: 12\n",
      "    })\n",
      "    test: Dataset({\n",
      "        features: ['Question', 'A', 'B', 'C', 'D', 'Answer', 'Explanation'],\n",
      "        num_rows: 110\n",
      "    })\n",
      "})\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "dataset = load_dataset(\"zefang-liu/secqa\", \"secqa_v1\")\n",
    "print(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1e1a29ed-f185-4256-94b6-4d4128b5b69b",
   "metadata": {},
   "outputs": [],
   "source": [
    "YAML_secqa_string = \"\"\"\n",
    "task: secqa\n",
    "dataset_path: zefang-liu/secqa\n",
    "dataset_name: secqa_v1\n",
    "output_type: multiple_choice\n",
    "training_split: dev\n",
    "validation_split: val\n",
    "test_split: test\n",
    "doc_to_text: \"{{Question}}\\nA) {{A}}\\nB) {{B}}\\nC) {{C}}\\nD) {{D}}\\nWhat is the correct answer? Use only the letter.\"\n",
    "doc_to_target: Answer\n",
    "doc_to_choice: [\"A\",\"B\",\"C\",\"D\"]\n",
    "should_decontaminate: true\n",
    "doc_to_decontamination_query: passage\n",
    "output_type: multiple_choice\n",
    "metric_list:\n",
    "  - metric: acc\n",
    "\"\"\"\n",
    "with open(\"secqa.yaml\", \"w\") as f:\n",
    "    f.write(YAML_secqa_string)\n",
    "\n",
    "# In terminal\n",
    "!mkdir -p /opt/conda/lib/python3.11/site-packages/lm_eval/tasks/secqa\n",
    "!cp /home/jovyan/secqa.yaml /opt/conda/lib/python3.11/site-packages/lm_eval/tasks/secqa/\n",
    "\n",
    "\n",
    "!export GIT_DISCOVERY_ACROSS_FILESYSTEM=1\n",
    "\n",
    "# git config --global credential.helper store\n",
    "# huggingface-cli login\n",
    "#to access restricted models ^, try below next time to avoid terminal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5a63390c-062d-47d2-9bf8-90194d92f46f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "fd906ea1-e281-4218-bf1b-7ea390410a8b",
   "metadata": {},
   "source": [
    "## TinyLlama-1.1B-Chat-v1.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3f0d0ccb-e333-4263-a563-fbe0b0f3d68e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#--model_args pretrained= ./llama-3.2-1b-instruct-q8_0.gguf\n",
    "\n",
    "#Eluther model # takes a long time to run\n",
    "\n",
    "#limit = number of samples to run/questions to as for evaluation\n",
    "\n",
    "#    --output_path ./results #only include when ready to log, not sure how to delete files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3ac18853-2ba2-47d1-b545-17c3b239fad6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-02-23 18:52:46.591286: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-02-23 18:52:46.638088: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2025-02-23 18:52:47.563446: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "2025-02-23:18:52:49,249 INFO     [lm_eval.__main__:307] Including path: /opt/conda/lib/python3.11/site-packages/lm_eval/tasks/\n",
      "2025-02-23:18:52:50,232 INFO     [lm_eval.tasks:460] The tag 'kobest' is already registered as a group, this tag will not be registered. This may affect tasks you want to call.\n",
      "2025-02-23:18:52:50,233 INFO     [lm_eval.tasks:460] The tag 'kobest' is already registered as a group, this tag will not be registered. This may affect tasks you want to call.\n",
      "2025-02-23:18:52:50,235 INFO     [lm_eval.tasks:460] The tag 'kobest' is already registered as a group, this tag will not be registered. This may affect tasks you want to call.\n",
      "2025-02-23:18:52:50,237 INFO     [lm_eval.tasks:460] The tag 'kobest' is already registered as a group, this tag will not be registered. This may affect tasks you want to call.\n",
      "2025-02-23:18:52:50,238 INFO     [lm_eval.tasks:460] The tag 'kobest' is already registered as a group, this tag will not be registered. This may affect tasks you want to call.\n",
      "2025-02-23:18:52:51,895 DEBUG    [lm_eval.tasks:523] File _evalita-mp_ner_adg.yaml in /opt/conda/lib/python3.11/site-packages/lm_eval/tasks/evalita_llm could not be loaded\n",
      "2025-02-23:18:52:51,912 DEBUG    [lm_eval.tasks:523] File _evalita-mp_ner_wn.yaml in /opt/conda/lib/python3.11/site-packages/lm_eval/tasks/evalita_llm could not be loaded\n",
      "2025-02-23:18:52:51,922 DEBUG    [lm_eval.tasks:523] File _evalita-mp_ner_fic.yaml in /opt/conda/lib/python3.11/site-packages/lm_eval/tasks/evalita_llm could not be loaded\n",
      "2025-02-23:18:53:00,004 INFO     [lm_eval.tasks:460] The tag 'kobest' is already registered as a group, this tag will not be registered. This may affect tasks you want to call.\n",
      "2025-02-23:18:53:00,006 INFO     [lm_eval.tasks:460] The tag 'kobest' is already registered as a group, this tag will not be registered. This may affect tasks you want to call.\n",
      "2025-02-23:18:53:00,007 INFO     [lm_eval.tasks:460] The tag 'kobest' is already registered as a group, this tag will not be registered. This may affect tasks you want to call.\n",
      "2025-02-23:18:53:00,009 INFO     [lm_eval.tasks:460] The tag 'kobest' is already registered as a group, this tag will not be registered. This may affect tasks you want to call.\n",
      "2025-02-23:18:53:00,010 INFO     [lm_eval.tasks:460] The tag 'kobest' is already registered as a group, this tag will not be registered. This may affect tasks you want to call.\n",
      "2025-02-23:18:53:01,690 DEBUG    [lm_eval.tasks:523] File _evalita-mp_ner_adg.yaml in /opt/conda/lib/python3.11/site-packages/lm_eval/tasks/evalita_llm could not be loaded\n",
      "2025-02-23:18:53:01,708 DEBUG    [lm_eval.tasks:523] File _evalita-mp_ner_wn.yaml in /opt/conda/lib/python3.11/site-packages/lm_eval/tasks/evalita_llm could not be loaded\n",
      "2025-02-23:18:53:01,717 DEBUG    [lm_eval.tasks:523] File _evalita-mp_ner_fic.yaml in /opt/conda/lib/python3.11/site-packages/lm_eval/tasks/evalita_llm could not be loaded\n",
      "2025-02-23:18:53:08,765 WARNING  [lm_eval.__main__:316]  --limit SHOULD ONLY BE USED FOR TESTING.REAL METRICS SHOULD NOT BE COMPUTED USING LIMIT.\n",
      "0\n",
      "Selected Tasks: ['secqa']\n",
      "2025-02-23:18:53:08,768 INFO     [lm_eval.evaluator:169] Setting random seed to 0 | Setting numpy seed to 1234 | Setting torch manual seed to 1234 | Setting fewshot manual seed to 1234\n",
      "2025-02-23:18:53:08,768 INFO     [lm_eval.evaluator:206] Initializing hf model, with arguments: {'pretrained': 'TinyLlama/TinyLlama-1.1B-Chat-v1.0'}\n",
      "2025-02-23:18:53:08,880 INFO     [lm_eval.models.huggingface:136] Using device 'cuda'\n",
      "2025-02-23:18:53:09,924 DEBUG    [lm_eval.models.huggingface:492] Using model type 'causal'\n",
      "2025-02-23:18:53:10,934 INFO     [lm_eval.models.huggingface:376] Model parallel was set to False, max memory was not set, and device map was set to {'': 'cuda'}\n",
      "2025-02-23:19:00:45,562 WARNING  [lm_eval.api.task:804] [Task: secqa] metric acc is defined, but aggregation is not. using default aggregation=mean\n",
      "2025-02-23:19:00:45,562 WARNING  [lm_eval.api.task:816] [Task: secqa] metric acc is defined, but higher_is_better is not. using default higher_is_better=True\n",
      "2025-02-23:19:00:47,841 INFO     [lm_eval.api.task:420] Building contexts for secqa on rank 0...\n",
      "100%|███████████████████████████████████████| 110/110 [00:00<00:00, 1768.57it/s]\n",
      "2025-02-23:19:00:47,909 DEBUG    [lm_eval.evaluator:488] Task: secqa; number of requests on this rank: 440\n",
      "2025-02-23:19:00:47,909 INFO     [lm_eval.evaluator:517] Running loglikelihood requests\n",
      "Running loglikelihood requests: 100%|█████████| 440/440 [00:07<00:00, 62.11it/s]\n",
      "fatal: not a git repository (or any parent up to mount point /home)\n",
      "Stopping at filesystem boundary (GIT_DISCOVERY_ACROSS_FILESYSTEM not set).\n",
      "2025-02-23:19:01:03,942 INFO     [lm_eval.loggers.evaluation_tracker:272] Output path not provided, skipping saving results aggregated\n",
      "hf (pretrained=TinyLlama/TinyLlama-1.1B-Chat-v1.0), gen_kwargs: (None), limit: 120.0, num_fewshot: None, batch_size: 1\n",
      "|Tasks|Version|Filter|n-shot|Metric|   |Value |   |Stderr|\n",
      "|-----|-------|------|-----:|------|---|-----:|---|-----:|\n",
      "|secqa|Yaml   |none  |     0|acc   |↑  |0.1909|±  |0.0376|\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# TinyLlama-1.1B-Chat-v1.0 successful experiment #takes several minutes\n",
    "!lm_eval \\\n",
    "    --model hf \\\n",
    "    --include_path /opt/conda/lib/python3.11/site-packages/lm_eval/tasks/ \\\n",
    "    --model_args pretrained=TinyLlama/TinyLlama-1.1B-Chat-v1.0 \\\n",
    "    --tasks secqa \\\n",
    "    --limit 120 \\\n",
    "    --verbosity DEBUG"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc5e499d-f3ee-4ec5-b678-0f5ef6c16e12",
   "metadata": {},
   "source": [
    "## Mistral-7B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6418cdca-a9de-407e-b9d9-b5f3358a9538",
   "metadata": {},
   "outputs": [],
   "source": [
    "from huggingface_hub import login\n",
    "login(token=\"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\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "487928e5-b099-47df-9957-b3282f9cc5e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !export HUGGING_FACE_HUB_TOKEN=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\n",
    "# !HUGGING_FACE_HUB_TOKEN=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 lm_eval \\\n",
    "#     --model hf \\\n",
    "#     --include_path /opt/conda/lib/python3.11/site-packages/lm_eval/tasks/ \\\n",
    "#     --model_args pretrained=mistralai/Mistral-7B-Instruct,token=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 \\\n",
    "#     --tasks secqa \\\n",
    "#     --limit 10 \\\n",
    "#     --verbosity DEBUG\n",
    "\n",
    "# raise EnvironmentError(\n",
    "# OSError: mistralai/Mistral-7B-Instruct is not a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'\n",
    "# If this is a private repository, make sure to pass a token having permission to this repo either by logging in with `huggingface-cli login` or by passing `token=<your_token>`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "941f57b8-308c-43e4-8400-b3716eba51a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from huggingface_hub import HfApi\n",
    "# api = HfApi()\n",
    "# api.model_info(\"mistralai/Mistral-7B-Instruct\", token=\"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\")\n",
    "\n",
    "# RepositoryNotFoundError: 404 Client Error. (Request ID: Root=1-67aaf6e2-3aebb68e4c780c423c471c29;59cfe869-d2f1-4585-b1e2-bb5dbece4f59)\n",
    "\n",
    "# Repository Not Found for url: https://huggingface.co/api/models/mistralai/Mistral-7B-Instruct.\n",
    "# Please make sure you specified the correct `repo_id` and `repo_type`.\n",
    "# If you are trying to access a private or gated repo, make sure you are authenticated."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "40970ab4-6e42-4b48-91b9-1293d6c0a2db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'type': 'user', 'id': '67a813c39cf69ce2315ea2b7', 'name': 'mgaddi', 'fullname': 'Matilda Gaddi', 'isPro': False, 'avatarUrl': 'https://cdn-avatars.huggingface.co/v1/production/uploads/no-auth/fpVpRk3UYfML7boNVQPWd.png', 'orgs': [], 'auth': {'type': 'access_token', 'accessToken': {'displayName': 'token1', 'role': 'fineGrained', 'createdAt': '2025-02-09T02:59:01.120Z', 'fineGrained': {'canReadGatedRepos': True, 'global': ['inference.serverless.write'], 'scoped': [{'entity': {'_id': '67a813c39cf69ce2315ea2b7', 'type': 'user', 'name': 'mgaddi'}, 'permissions': ['repo.content.read', 'inference.endpoints.infer.write', 'user.webhooks.read', 'collection.read']}]}}}}\n"
     ]
    }
   ],
   "source": [
    "from huggingface_hub import whoami\n",
    "\n",
    "print(whoami(token=\"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\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "18100015-e7ec-44dc-9f18-1ccb8bb97006",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "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\n"
     ]
    }
   ],
   "source": [
    "from huggingface_hub import HfFolder\n",
    "print(HfFolder.get_token())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "1a0b0c35-648c-411a-8172-d86a906fc171",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load model directly #Takes like 4 minutes\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"mistralai/Mistral-7B-Instruct-v0.2\")\n",
    "model = AutoModelForCausalLM.from_pretrained(\"mistralai/Mistral-7B-Instruct-v0.2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "6e4ff7c4-ce16-4aed-9e70-276776e159ba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('./mistralai/Mistral-7B-Instruct-v0.2/tokenizer_config.json',\n",
       " './mistralai/Mistral-7B-Instruct-v0.2/special_tokens_map.json',\n",
       " './mistralai/Mistral-7B-Instruct-v0.2/tokenizer.model',\n",
       " './mistralai/Mistral-7B-Instruct-v0.2/added_tokens.json',\n",
       " './mistralai/Mistral-7B-Instruct-v0.2/tokenizer.json')"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Save the model and tokenizer locally #Takes ~4min\n",
    "model.save_pretrained(\"./mistralai/Mistral-7B-Instruct-v0.2\")\n",
    "tokenizer.save_pretrained(\"./mistralai/Mistral-7B-Instruct-v0.2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae7a4658-7fb4-4c66-b0a1-c6edf0d451cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-02-11 08:04:31.749296: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "2025-02-11:08:04:33,400 INFO     [__main__.py:284] Verbosity set to DEBUG\n",
      "2025-02-11:08:04:33,400 INFO     [__main__.py:308] Including path: /opt/conda/lib/python3.11/site-packages/lm_eval/tasks/\n",
      "2025-02-11:08:04:34,838 INFO     [__init__.py:459] The tag 'kobest' is already registered as a group, this tag will not be registered. This may affect tasks you want to call.\n",
      "2025-02-11:08:04:45,011 INFO     [__init__.py:459] The tag 'kobest' is already registered as a group, this tag will not be registered. This may affect tasks you want to call.\n",
      "2025-02-11:08:04:53,762 WARNING  [__main__.py:317]  --limit SHOULD ONLY BE USED FOR TESTING.REAL METRICS SHOULD NOT BE COMPUTED USING LIMIT.\n",
      "2025-02-11:08:04:53,763 INFO     [__main__.py:381] Selected Tasks: ['secqa']\n",
      "2025-02-11:08:04:53,765 INFO     [evaluator.py:165] Setting random seed to 0 | Setting numpy seed to 1234 | Setting torch manual seed to 1234 | Setting fewshot manual seed to 1234\n",
      "2025-02-11:08:04:53,765 INFO     [evaluator.py:202] Initializing hf model, with arguments: {'pretrained': '/home/jovyan/mistralai/Mistral-7B-Instruct-v0.2'}\n",
      "2025-02-11:08:04:53,852 INFO     [huggingface.py:135] Using device 'cuda'\n",
      "2025-02-11:08:04:53,854 DEBUG    [huggingface.py:491] Using model type 'causal'\n",
      "2025-02-11:08:04:53,963 INFO     [huggingface.py:375] Model parallel was set to False, max memory was not set, and device map was set to {'': 'cuda'}\n",
      "Loading checkpoint shards:   0%|                          | 0/6 [00:00<?, ?it/s]"
     ]
    }
   ],
   "source": [
    "# with model locally saved \n",
    "# needs whole path to model\n",
    "# not getting past Loading checkpoint shards:   0%|                          | 0/6 [00:00<?, ?it/s]^C\n",
    "!lm_eval \\\n",
    "    --model hf \\\n",
    "    --include_path /opt/conda/lib/python3.11/site-packages/lm_eval/tasks/ \\\n",
    "    --model_args pretrained=/home/jovyan/mistralai/Mistral-7B-Instruct-v0.2 \\\n",
    "    --tasks secqa \\\n",
    "    --limit 10 \\\n",
    "    --verbosity DEBUG"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38c9bd57-4dba-4dd6-9a9f-2512bb024394",
   "metadata": {},
   "source": [
    "## LLaMa-7B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38591376-a71a-4e96-a316-4846035d0df2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# stuck for over 10min at, Loading checkpoint shards:   0%|                          | 0/2 [00:00<?, ?it/s]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "603181c4-ac75-43aa-83b6-bb91a8cae7eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: numpy in /opt/conda/lib/python3.11/site-packages (1.26.4)\n",
      "Collecting numpy\n",
      "  Using cached numpy-2.2.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (62 kB)\n",
      "Using cached numpy-2.2.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (16.4 MB)\n",
      "Installing collected packages: numpy\n",
      "  Attempting uninstall: numpy\n",
      "    Found existing installation: numpy 1.26.4\n",
      "    Uninstalling numpy-1.26.4:\n",
      "      Successfully uninstalled numpy-1.26.4\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "cupy-cuda11x 13.1.0 requires numpy<1.29,>=1.22, but you have numpy 2.2.2 which is incompatible.\n",
      "cuquantum-python-cu11 24.3.0.post1 requires numpy~=1.21, but you have numpy 2.2.2 which is incompatible.\n",
      "langchain 0.1.20 requires numpy<2,>=1, but you have numpy 2.2.2 which is incompatible.\n",
      "langchain-community 0.0.38 requires numpy<2,>=1, but you have numpy 2.2.2 which is incompatible.\n",
      "tensorflow 2.16.1 requires numpy<2.0.0,>=1.23.5; python_version <= \"3.11\", but you have numpy 2.2.2 which is incompatible.\n",
      "numba 0.59.1 requires numpy<1.27,>=1.22, but you have numpy 2.2.2 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0mSuccessfully installed numpy-2.2.2\n"
     ]
    }
   ],
   "source": [
    "#!pip install --upgrade pandas\n",
    "##!pip install --upgrade numpy #do not, not compaible #this might have killed the server previously\n",
    "#!pip install --upgrade torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "477f9d64-ffd2-436b-9712-ba6aa8d16627",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "A module that was compiled using NumPy 1.x cannot be run in\n",
      "NumPy 2.2.2 as it may crash. To support both 1.x and 2.x\n",
      "versions of NumPy, modules must be compiled with NumPy 2.0.\n",
      "Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.\n",
      "\n",
      "If you are a user of the module, the easiest solution will be to\n",
      "downgrade to 'numpy<2' or try to upgrade the affected module.\n",
      "We expect that some modules will need time to support NumPy 2.\n",
      "\n",
      "Traceback (most recent call last):  File \"/opt/conda/bin/lm_eval\", line 5, in <module>\n",
      "    from lm_eval.__main__ import cli_evaluate\n",
      "  File \"/opt/conda/lib/python3.11/site-packages/lm_eval/__init__.py\", line 1, in <module>\n",
      "    from .evaluator import evaluate, simple_evaluate\n",
      "  File \"/opt/conda/lib/python3.11/site-packages/lm_eval/evaluator.py\", line 12, in <module>\n",
      "    import lm_eval.api.metrics\n",
      "  File \"/opt/conda/lib/python3.11/site-packages/lm_eval/api/metrics.py\", line 12, in <module>\n",
      "    from lm_eval.api.registry import register_aggregation, register_metric\n",
      "  File \"/opt/conda/lib/python3.11/site-packages/lm_eval/api/registry.py\", line 4, in <module>\n",
      "    import evaluate as hf_evaluate\n",
      "  File \"/opt/conda/lib/python3.11/site-packages/evaluate/__init__.py\", line 29, in <module>\n",
      "    from .evaluation_suite import EvaluationSuite\n",
      "  File \"/opt/conda/lib/python3.11/site-packages/evaluate/evaluation_suite/__init__.py\", line 7, in <module>\n",
      "    from datasets import Dataset, DownloadConfig, DownloadMode, load_dataset\n",
      "  File \"/opt/conda/lib/python3.11/site-packages/datasets/__init__.py\", line 17, in <module>\n",
      "    from .arrow_dataset import Dataset\n",
      "  File \"/opt/conda/lib/python3.11/site-packages/datasets/arrow_dataset.py\", line 59, in <module>\n",
      "    import pandas as pd\n",
      "  File \"/opt/conda/lib/python3.11/site-packages/pandas/__init__.py\", line 26, in <module>\n",
      "    from pandas.compat import (\n",
      "  File \"/opt/conda/lib/python3.11/site-packages/pandas/compat/__init__.py\", line 27, in <module>\n",
      "    from pandas.compat.pyarrow import (\n",
      "  File \"/opt/conda/lib/python3.11/site-packages/pandas/compat/pyarrow.py\", line 8, in <module>\n",
      "    import pyarrow as pa\n",
      "  File \"/opt/conda/lib/python3.11/site-packages/pyarrow/__init__.py\", line 65, in <module>\n",
      "    import pyarrow.lib as _lib\n",
      "AttributeError: _ARRAY_API not found\n",
      "\n",
      "A module that was compiled using NumPy 1.x cannot be run in\n",
      "NumPy 2.2.2 as it may crash. To support both 1.x and 2.x\n",
      "versions of NumPy, modules must be compiled with NumPy 2.0.\n",
      "Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.\n",
      "\n",
      "If you are a user of the module, the easiest solution will be to\n",
      "downgrade to 'numpy<2' or try to upgrade the affected module.\n",
      "We expect that some modules will need time to support NumPy 2.\n",
      "\n",
      "Traceback (most recent call last):  File \"/opt/conda/bin/lm_eval\", line 5, in <module>\n",
      "    from lm_eval.__main__ import cli_evaluate\n",
      "  File \"/opt/conda/lib/python3.11/site-packages/lm_eval/__init__.py\", line 1, in <module>\n",
      "    from .evaluator import evaluate, simple_evaluate\n",
      "  File \"/opt/conda/lib/python3.11/site-packages/lm_eval/evaluator.py\", line 12, in <module>\n",
      "    import lm_eval.api.metrics\n",
      "  File \"/opt/conda/lib/python3.11/site-packages/lm_eval/api/metrics.py\", line 12, in <module>\n",
      "    from lm_eval.api.registry import register_aggregation, register_metric\n",
      "  File \"/opt/conda/lib/python3.11/site-packages/lm_eval/api/registry.py\", line 4, in <module>\n",
      "    import evaluate as hf_evaluate\n",
      "  File \"/opt/conda/lib/python3.11/site-packages/evaluate/__init__.py\", line 29, in <module>\n",
      "    from .evaluation_suite import EvaluationSuite\n",
      "  File \"/opt/conda/lib/python3.11/site-packages/evaluate/evaluation_suite/__init__.py\", line 7, in <module>\n",
      "    from datasets import Dataset, DownloadConfig, DownloadMode, load_dataset\n",
      "  File \"/opt/conda/lib/python3.11/site-packages/datasets/__init__.py\", line 17, in <module>\n",
      "    from .arrow_dataset import Dataset\n",
      "  File \"/opt/conda/lib/python3.11/site-packages/datasets/arrow_dataset.py\", line 59, in <module>\n",
      "    import pandas as pd\n",
      "  File \"/opt/conda/lib/python3.11/site-packages/pandas/__init__.py\", line 49, in <module>\n",
      "    from pandas.core.api import (\n",
      "  File \"/opt/conda/lib/python3.11/site-packages/pandas/core/api.py\", line 9, in <module>\n",
      "    from pandas.core.dtypes.dtypes import (\n",
      "  File \"/opt/conda/lib/python3.11/site-packages/pandas/core/dtypes/dtypes.py\", line 24, in <module>\n",
      "    from pandas._libs import (\n",
      "  File \"/opt/conda/lib/python3.11/site-packages/pyarrow/__init__.py\", line 65, in <module>\n",
      "    import pyarrow.lib as _lib\n",
      "AttributeError: _ARRAY_API not found\n",
      "\n",
      "A module that was compiled using NumPy 1.x cannot be run in\n",
      "NumPy 2.2.2 as it may crash. To support both 1.x and 2.x\n",
      "versions of NumPy, modules must be compiled with NumPy 2.0.\n",
      "Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.\n",
      "\n",
      "If you are a user of the module, the easiest solution will be to\n",
      "downgrade to 'numpy<2' or try to upgrade the affected module.\n",
      "We expect that some modules will need time to support NumPy 2.\n",
      "\n",
      "Traceback (most recent call last):  File \"/opt/conda/bin/lm_eval\", line 5, in <module>\n",
      "    from lm_eval.__main__ import cli_evaluate\n",
      "  File \"/opt/conda/lib/python3.11/site-packages/lm_eval/__init__.py\", line 1, in <module>\n",
      "    from .evaluator import evaluate, simple_evaluate\n",
      "  File \"/opt/conda/lib/python3.11/site-packages/lm_eval/evaluator.py\", line 12, in <module>\n",
      "    import lm_eval.api.metrics\n",
      "  File \"/opt/conda/lib/python3.11/site-packages/lm_eval/api/metrics.py\", line 12, in <module>\n",
      "    from lm_eval.api.registry import register_aggregation, register_metric\n",
      "  File \"/opt/conda/lib/python3.11/site-packages/lm_eval/api/registry.py\", line 4, in <module>\n",
      "    import evaluate as hf_evaluate\n",
      "  File \"/opt/conda/lib/python3.11/site-packages/evaluate/__init__.py\", line 29, in <module>\n",
      "    from .evaluation_suite import EvaluationSuite\n",
      "  File \"/opt/conda/lib/python3.11/site-packages/evaluate/evaluation_suite/__init__.py\", line 7, in <module>\n",
      "    from datasets import Dataset, DownloadConfig, DownloadMode, load_dataset\n",
      "  File \"/opt/conda/lib/python3.11/site-packages/datasets/__init__.py\", line 17, in <module>\n",
      "    from .arrow_dataset import Dataset\n",
      "  File \"/opt/conda/lib/python3.11/site-packages/datasets/arrow_dataset.py\", line 59, in <module>\n",
      "    import pandas as pd\n",
      "  File \"/opt/conda/lib/python3.11/site-packages/pandas/__init__.py\", line 49, in <module>\n",
      "    from pandas.core.api import (\n",
      "  File \"/opt/conda/lib/python3.11/site-packages/pandas/core/api.py\", line 28, in <module>\n",
      "    from pandas.core.arrays import Categorical\n",
      "  File \"/opt/conda/lib/python3.11/site-packages/pandas/core/arrays/__init__.py\", line 1, in <module>\n",
      "    from pandas.core.arrays.arrow import ArrowExtensionArray\n",
      "  File \"/opt/conda/lib/python3.11/site-packages/pandas/core/arrays/arrow/__init__.py\", line 5, in <module>\n",
      "    from pandas.core.arrays.arrow.array import ArrowExtensionArray\n",
      "  File \"/opt/conda/lib/python3.11/site-packages/pandas/core/arrays/arrow/array.py\", line 50, in <module>\n",
      "    from pandas.core import (\n",
      "  File \"/opt/conda/lib/python3.11/site-packages/pandas/core/ops/__init__.py\", line 8, in <module>\n",
      "    from pandas.core.ops.array_ops import (\n",
      "  File \"/opt/conda/lib/python3.11/site-packages/pandas/core/ops/array_ops.py\", line 56, in <module>\n",
      "    from pandas.core.computation import expressions\n",
      "  File \"/opt/conda/lib/python3.11/site-packages/pandas/core/computation/expressions.py\", line 21, in <module>\n",
      "    from pandas.core.computation.check import NUMEXPR_INSTALLED\n",
      "  File \"/opt/conda/lib/python3.11/site-packages/pandas/core/computation/check.py\", line 5, in <module>\n",
      "    ne = import_optional_dependency(\"numexpr\", errors=\"warn\")\n",
      "  File \"/opt/conda/lib/python3.11/site-packages/pandas/compat/_optional.py\", line 135, in import_optional_dependency\n",
      "    module = importlib.import_module(name)\n",
      "  File \"/opt/conda/lib/python3.11/importlib/__init__.py\", line 126, in import_module\n",
      "    return _bootstrap._gcd_import(name[level:], package, level)\n",
      "  File \"/opt/conda/lib/python3.11/site-packages/numexpr/__init__.py\", line 24, in <module>\n",
      "    from numexpr.interpreter import MAX_THREADS, use_vml, __BLOCK_SIZE1__\n",
      "AttributeError: _ARRAY_API not found\n",
      "\n",
      "A module that was compiled using NumPy 1.x cannot be run in\n",
      "NumPy 2.2.2 as it may crash. To support both 1.x and 2.x\n",
      "versions of NumPy, modules must be compiled with NumPy 2.0.\n",
      "Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.\n",
      "\n",
      "If you are a user of the module, the easiest solution will be to\n",
      "downgrade to 'numpy<2' or try to upgrade the affected module.\n",
      "We expect that some modules will need time to support NumPy 2.\n",
      "\n",
      "Traceback (most recent call last):  File \"/opt/conda/bin/lm_eval\", line 5, in <module>\n",
      "    from lm_eval.__main__ import cli_evaluate\n",
      "  File \"/opt/conda/lib/python3.11/site-packages/lm_eval/__init__.py\", line 1, in <module>\n",
      "    from .evaluator import evaluate, simple_evaluate\n",
      "  File \"/opt/conda/lib/python3.11/site-packages/lm_eval/evaluator.py\", line 12, in <module>\n",
      "    import lm_eval.api.metrics\n",
      "  File \"/opt/conda/lib/python3.11/site-packages/lm_eval/api/metrics.py\", line 12, in <module>\n",
      "    from lm_eval.api.registry import register_aggregation, register_metric\n",
      "  File \"/opt/conda/lib/python3.11/site-packages/lm_eval/api/registry.py\", line 4, in <module>\n",
      "    import evaluate as hf_evaluate\n",
      "  File \"/opt/conda/lib/python3.11/site-packages/evaluate/__init__.py\", line 29, in <module>\n",
      "    from .evaluation_suite import EvaluationSuite\n",
      "  File \"/opt/conda/lib/python3.11/site-packages/evaluate/evaluation_suite/__init__.py\", line 7, in <module>\n",
      "    from datasets import Dataset, DownloadConfig, DownloadMode, load_dataset\n",
      "  File \"/opt/conda/lib/python3.11/site-packages/datasets/__init__.py\", line 17, in <module>\n",
      "    from .arrow_dataset import Dataset\n",
      "  File \"/opt/conda/lib/python3.11/site-packages/datasets/arrow_dataset.py\", line 59, in <module>\n",
      "    import pandas as pd\n",
      "  File \"/opt/conda/lib/python3.11/site-packages/pandas/__init__.py\", line 49, in <module>\n",
      "    from pandas.core.api import (\n",
      "  File \"/opt/conda/lib/python3.11/site-packages/pandas/core/api.py\", line 28, in <module>\n",
      "    from pandas.core.arrays import Categorical\n",
      "  File \"/opt/conda/lib/python3.11/site-packages/pandas/core/arrays/__init__.py\", line 1, in <module>\n",
      "    from pandas.core.arrays.arrow import ArrowExtensionArray\n",
      "  File \"/opt/conda/lib/python3.11/site-packages/pandas/core/arrays/arrow/__init__.py\", line 5, in <module>\n",
      "    from pandas.core.arrays.arrow.array import ArrowExtensionArray\n",
      "  File \"/opt/conda/lib/python3.11/site-packages/pandas/core/arrays/arrow/array.py\", line 64, in <module>\n",
      "    from pandas.core.arrays.masked import BaseMaskedArray\n",
      "  File \"/opt/conda/lib/python3.11/site-packages/pandas/core/arrays/masked.py\", line 60, in <module>\n",
      "    from pandas.core import (\n",
      "  File \"/opt/conda/lib/python3.11/site-packages/pandas/core/nanops.py\", line 52, in <module>\n",
      "    bn = import_optional_dependency(\"bottleneck\", errors=\"warn\")\n",
      "  File \"/opt/conda/lib/python3.11/site-packages/pandas/compat/_optional.py\", line 135, in import_optional_dependency\n",
      "    module = importlib.import_module(name)\n",
      "  File \"/opt/conda/lib/python3.11/importlib/__init__.py\", line 126, in import_module\n",
      "    return _bootstrap._gcd_import(name[level:], package, level)\n",
      "  File \"/opt/conda/lib/python3.11/site-packages/bottleneck/__init__.py\", line 7, in <module>\n",
      "    from .move import (move_argmax, move_argmin, move_max, move_mean, move_median,\n",
      "AttributeError: _ARRAY_API not found\n",
      "\n",
      "A module that was compiled using NumPy 1.x cannot be run in\n",
      "NumPy 2.2.2 as it may crash. To support both 1.x and 2.x\n",
      "versions of NumPy, modules must be compiled with NumPy 2.0.\n",
      "Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.\n",
      "\n",
      "If you are a user of the module, the easiest solution will be to\n",
      "downgrade to 'numpy<2' or try to upgrade the affected module.\n",
      "We expect that some modules will need time to support NumPy 2.\n",
      "\n",
      "Traceback (most recent call last):  File \"/opt/conda/bin/lm_eval\", line 5, in <module>\n",
      "    from lm_eval.__main__ import cli_evaluate\n",
      "  File \"/opt/conda/lib/python3.11/site-packages/lm_eval/__init__.py\", line 1, in <module>\n",
      "    from .evaluator import evaluate, simple_evaluate\n",
      "  File \"/opt/conda/lib/python3.11/site-packages/lm_eval/evaluator.py\", line 12, in <module>\n",
      "    import lm_eval.api.metrics\n",
      "  File \"/opt/conda/lib/python3.11/site-packages/lm_eval/api/metrics.py\", line 12, in <module>\n",
      "    from lm_eval.api.registry import register_aggregation, register_metric\n",
      "  File \"/opt/conda/lib/python3.11/site-packages/lm_eval/api/registry.py\", line 4, in <module>\n",
      "    import evaluate as hf_evaluate\n",
      "  File \"/opt/conda/lib/python3.11/site-packages/evaluate/__init__.py\", line 29, in <module>\n",
      "    from .evaluation_suite import EvaluationSuite\n",
      "  File \"/opt/conda/lib/python3.11/site-packages/evaluate/evaluation_suite/__init__.py\", line 7, in <module>\n",
      "    from datasets import Dataset, DownloadConfig, DownloadMode, load_dataset\n",
      "  File \"/opt/conda/lib/python3.11/site-packages/datasets/__init__.py\", line 17, in <module>\n",
      "    from .arrow_dataset import Dataset\n",
      "  File \"/opt/conda/lib/python3.11/site-packages/datasets/arrow_dataset.py\", line 60, in <module>\n",
      "    import pyarrow as pa\n",
      "  File \"/opt/conda/lib/python3.11/site-packages/pyarrow/__init__.py\", line 65, in <module>\n",
      "    import pyarrow.lib as _lib\n",
      "AttributeError: _ARRAY_API not found\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/bin/lm_eval\", line 5, in <module>\n",
      "    from lm_eval.__main__ import cli_evaluate\n",
      "  File \"/opt/conda/lib/python3.11/site-packages/lm_eval/__init__.py\", line 1, in <module>\n",
      "    from .evaluator import evaluate, simple_evaluate\n",
      "  File \"/opt/conda/lib/python3.11/site-packages/lm_eval/evaluator.py\", line 12, in <module>\n",
      "    import lm_eval.api.metrics\n",
      "  File \"/opt/conda/lib/python3.11/site-packages/lm_eval/api/metrics.py\", line 12, in <module>\n",
      "    from lm_eval.api.registry import register_aggregation, register_metric\n",
      "  File \"/opt/conda/lib/python3.11/site-packages/lm_eval/api/registry.py\", line 4, in <module>\n",
      "    import evaluate as hf_evaluate\n",
      "  File \"/opt/conda/lib/python3.11/site-packages/evaluate/__init__.py\", line 29, in <module>\n",
      "    from .evaluation_suite import EvaluationSuite\n",
      "  File \"/opt/conda/lib/python3.11/site-packages/evaluate/evaluation_suite/__init__.py\", line 7, in <module>\n",
      "    from datasets import Dataset, DownloadConfig, DownloadMode, load_dataset\n",
      "  File \"/opt/conda/lib/python3.11/site-packages/datasets/__init__.py\", line 17, in <module>\n",
      "    from .arrow_dataset import Dataset\n",
      "  File \"/opt/conda/lib/python3.11/site-packages/datasets/arrow_dataset.py\", line 60, in <module>\n",
      "    import pyarrow as pa\n",
      "  File \"/opt/conda/lib/python3.11/site-packages/pyarrow/__init__.py\", line 65, in <module>\n",
      "    import pyarrow.lib as _lib\n",
      "  File \"pyarrow/lib.pyx\", line 36, in init pyarrow.lib\n",
      "ImportError: numpy.core.multiarray failed to import\n"
     ]
    }
   ],
   "source": [
    "!lm_eval \\\n",
    "    --model hf \\\n",
    "    --include_path /opt/conda/lib/python3.11/site-packages/lm_eval/tasks/ \\\n",
    "    --model_args pretrained=meta-llama/Llama-2-7b-chat-hf \\\n",
    "    --tasks secqa \\\n",
    "    --limit 10 \\\n",
    "    --verbosity DEBUG"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e61c962-7dcb-45b4-88ef-cf90c006103a",
   "metadata": {},
   "source": [
    "## CyberBench"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "547b0d55-c4ca-4fb5-82d2-bb1b5f3ba770",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "LookupError",
     "evalue": "\n**********************************************************************\n  Resource \u001b[93mwordnet\u001b[0m not found.\n  Please use the NLTK Downloader to obtain the resource:\n\n  \u001b[31m>>> import nltk\n  >>> nltk.download('wordnet')\n  \u001b[0m\n  For more information see: https://www.nltk.org/data.html\n\n  Attempted to load \u001b[93mcorpora/wordnet\u001b[0m\n\n  Searched in:\n    - '/home/jovyan/nltk_data'\n    - '/opt/conda/nltk_data'\n    - '/opt/conda/share/nltk_data'\n    - '/opt/conda/lib/nltk_data'\n    - '/usr/share/nltk_data'\n    - '/usr/local/share/nltk_data'\n    - '/usr/lib/nltk_data'\n    - '/usr/local/lib/nltk_data'\n**********************************************************************\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mLookupError\u001b[0m                               Traceback (most recent call last)",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/nltk/corpus/util.py:84\u001b[0m, in \u001b[0;36mLazyCorpusLoader.__load\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     83\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 84\u001b[0m     root \u001b[38;5;241m=\u001b[39m \u001b[43mnltk\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdata\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfind\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43mf\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msubdir\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m/\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mzip_name\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     85\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mLookupError\u001b[39;00m:\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/nltk/data.py:579\u001b[0m, in \u001b[0;36mfind\u001b[0;34m(resource_name, paths)\u001b[0m\n\u001b[1;32m    578\u001b[0m resource_not_found \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00msep\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mmsg\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00msep\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m--> 579\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mLookupError\u001b[39;00m(resource_not_found)\n",
      "\u001b[0;31mLookupError\u001b[0m: \n**********************************************************************\n  Resource \u001b[93mwordnet\u001b[0m not found.\n  Please use the NLTK Downloader to obtain the resource:\n\n  \u001b[31m>>> import nltk\n  >>> nltk.download('wordnet')\n  \u001b[0m\n  For more information see: https://www.nltk.org/data.html\n\n  Attempted to load \u001b[93mcorpora/wordnet.zip/wordnet/\u001b[0m\n\n  Searched in:\n    - '/home/jovyan/nltk_data'\n    - '/opt/conda/nltk_data'\n    - '/opt/conda/share/nltk_data'\n    - '/opt/conda/lib/nltk_data'\n    - '/usr/share/nltk_data'\n    - '/usr/local/share/nltk_data'\n    - '/usr/lib/nltk_data'\n    - '/usr/local/lib/nltk_data'\n**********************************************************************\n",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mLookupError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[15], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnltk\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdata\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28mprint\u001b[39m(nltk\u001b[38;5;241m.\u001b[39mdata\u001b[38;5;241m.\u001b[39mpath)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/nltk/__init__.py:156\u001b[0m\n\u001b[1;32m    154\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mnltk\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtree\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;241m*\u001b[39m\n\u001b[1;32m    155\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mnltk\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msem\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;241m*\u001b[39m\n\u001b[0;32m--> 156\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mnltk\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mstem\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;241m*\u001b[39m\n\u001b[1;32m    158\u001b[0m \u001b[38;5;66;03m# Packages which can be lazily imported\u001b[39;00m\n\u001b[1;32m    159\u001b[0m \u001b[38;5;66;03m# (a) we don't import *\u001b[39;00m\n\u001b[1;32m    160\u001b[0m \u001b[38;5;66;03m# (b) they're slow to import or have run-time dependencies\u001b[39;00m\n\u001b[1;32m    161\u001b[0m \u001b[38;5;66;03m#     that can safely fail at run time\u001b[39;00m\n\u001b[1;32m    163\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mnltk\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m lazyimport\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/nltk/stem/__init__.py:34\u001b[0m\n\u001b[1;32m     32\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mnltk\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mstem\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mrslp\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m RSLPStemmer\n\u001b[1;32m     33\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mnltk\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mstem\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msnowball\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m SnowballStemmer\n\u001b[0;32m---> 34\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mnltk\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mstem\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mwordnet\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m WordNetLemmatizer\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/nltk/stem/wordnet.py:13\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Natural Language Toolkit: WordNet stemmer interface\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;66;03m#\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;66;03m# Copyright (C) 2001-2024 NLTK Project\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;66;03m# URL: <https://www.nltk.org/>\u001b[39;00m\n\u001b[1;32m      8\u001b[0m \u001b[38;5;66;03m# For license information, see LICENSE.TXT\u001b[39;00m\n\u001b[1;32m     10\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mnltk\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcorpus\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m wordnet \u001b[38;5;28;01mas\u001b[39;00m wn\n\u001b[0;32m---> 13\u001b[0m \u001b[38;5;28;43;01mclass\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;21;43;01mWordNetLemmatizer\u001b[39;49;00m\u001b[43m:\u001b[49m\n\u001b[1;32m     14\u001b[0m \u001b[38;5;250;43m    \u001b[39;49m\u001b[38;5;124;43;03m\"\"\"\u001b[39;49;00m\n\u001b[1;32m     15\u001b[0m \u001b[38;5;124;43;03m    WordNet Lemmatizer\u001b[39;49;00m\n\u001b[1;32m     16\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     45\u001b[0m \n\u001b[1;32m     46\u001b[0m \u001b[38;5;124;43;03m    \"\"\"\u001b[39;49;00m\n\u001b[1;32m     48\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmorphy\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mwn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmorphy\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/nltk/stem/wordnet.py:48\u001b[0m, in \u001b[0;36mWordNetLemmatizer\u001b[0;34m()\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[38;5;28;01mclass\u001b[39;00m \u001b[38;5;21;01mWordNetLemmatizer\u001b[39;00m:\n\u001b[1;32m     14\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m     15\u001b[0m \u001b[38;5;124;03m    WordNet Lemmatizer\u001b[39;00m\n\u001b[1;32m     16\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     45\u001b[0m \n\u001b[1;32m     46\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m---> 48\u001b[0m     morphy \u001b[38;5;241m=\u001b[39m \u001b[43mwn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmorphy\u001b[49m\n\u001b[1;32m     50\u001b[0m     _morphy \u001b[38;5;241m=\u001b[39m wn\u001b[38;5;241m.\u001b[39m_morphy\n\u001b[1;32m     52\u001b[0m     \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mlemmatize\u001b[39m(\u001b[38;5;28mself\u001b[39m, word: \u001b[38;5;28mstr\u001b[39m, pos: \u001b[38;5;28mstr\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mn\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28mstr\u001b[39m:\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/nltk/corpus/util.py:120\u001b[0m, in \u001b[0;36mLazyCorpusLoader.__getattr__\u001b[0;34m(self, attr)\u001b[0m\n\u001b[1;32m    117\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m attr \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__bases__\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m    118\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAttributeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLazyCorpusLoader object has no attribute \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m__bases__\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m--> 120\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m__load\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    121\u001b[0m \u001b[38;5;66;03m# This looks circular, but its not, since __load() changes our\u001b[39;00m\n\u001b[1;32m    122\u001b[0m \u001b[38;5;66;03m# __class__ to something new:\u001b[39;00m\n\u001b[1;32m    123\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(\u001b[38;5;28mself\u001b[39m, attr)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/nltk/corpus/util.py:86\u001b[0m, in \u001b[0;36mLazyCorpusLoader.__load\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     84\u001b[0m             root \u001b[38;5;241m=\u001b[39m nltk\u001b[38;5;241m.\u001b[39mdata\u001b[38;5;241m.\u001b[39mfind(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msubdir\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mzip_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     85\u001b[0m         \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mLookupError\u001b[39;00m:\n\u001b[0;32m---> 86\u001b[0m             \u001b[38;5;28;01mraise\u001b[39;00m e\n\u001b[1;32m     88\u001b[0m \u001b[38;5;66;03m# Load the corpus.\u001b[39;00m\n\u001b[1;32m     89\u001b[0m corpus \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m__reader_cls(root, \u001b[38;5;241m*\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m__args, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m__kwargs)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/nltk/corpus/util.py:81\u001b[0m, in \u001b[0;36mLazyCorpusLoader.__load\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     79\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     80\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 81\u001b[0m         root \u001b[38;5;241m=\u001b[39m \u001b[43mnltk\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdata\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfind\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43mf\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msubdir\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m/\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m__name\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     82\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mLookupError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     83\u001b[0m         \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/nltk/data.py:579\u001b[0m, in \u001b[0;36mfind\u001b[0;34m(resource_name, paths)\u001b[0m\n\u001b[1;32m    577\u001b[0m sep \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m*\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m*\u001b[39m \u001b[38;5;241m70\u001b[39m\n\u001b[1;32m    578\u001b[0m resource_not_found \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00msep\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mmsg\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00msep\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m--> 579\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mLookupError\u001b[39;00m(resource_not_found)\n",
      "\u001b[0;31mLookupError\u001b[0m: \n**********************************************************************\n  Resource \u001b[93mwordnet\u001b[0m not found.\n  Please use the NLTK Downloader to obtain the resource:\n\n  \u001b[31m>>> import nltk\n  >>> nltk.download('wordnet')\n  \u001b[0m\n  For more information see: https://www.nltk.org/data.html\n\n  Attempted to load \u001b[93mcorpora/wordnet\u001b[0m\n\n  Searched in:\n    - '/home/jovyan/nltk_data'\n    - '/opt/conda/nltk_data'\n    - '/opt/conda/share/nltk_data'\n    - '/opt/conda/lib/nltk_data'\n    - '/usr/share/nltk_data'\n    - '/usr/local/share/nltk_data'\n    - '/usr/lib/nltk_data'\n    - '/usr/local/lib/nltk_data'\n**********************************************************************\n"
     ]
    }
   ],
   "source": [
    "import nltk.data\n",
    "print(nltk.data.path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c8b4f93d-f6da-4117-b8e2-db289420c329",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import wordnet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "acffbb05-7fb0-400a-b566-79d1a4094336",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'nltk'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[19], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnltk\u001b[39;00m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'nltk'"
     ]
    }
   ],
   "source": [
    "import nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "e9e88d24-b052-46bc-a7cd-30b0c796e359",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: nltk in /opt/conda/lib/python3.11/site-packages (3.9)\n",
      "Requirement already satisfied: click in /opt/conda/lib/python3.11/site-packages (from nltk) (8.1.7)\n",
      "Requirement already satisfied: joblib in /opt/conda/lib/python3.11/site-packages (from nltk) (1.4.2)\n",
      "Requirement already satisfied: regex>=2021.8.3 in /opt/conda/lib/python3.11/site-packages (from nltk) (2024.5.15)\n",
      "Requirement already satisfied: tqdm in /opt/conda/lib/python3.11/site-packages (from nltk) (4.66.3)\n"
     ]
    }
   ],
   "source": [
    "!pip install nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "4f3f6390-c3e4-4db8-a21b-b480049756d2",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'nltk'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[24], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnltk\u001b[39;00m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'nltk'"
     ]
    }
   ],
   "source": [
    "import nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "03e55613-0ea0-4684-abbc-122b0170c7e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nltk                          3.9\n"
     ]
    }
   ],
   "source": [
    "!pip list | grep nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "85eaf372-1e0c-4904-be02-2243b981eb31",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install --upgrade numpy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "698c6af6-af6e-466b-8b19-272dfdaf8a8b",
   "metadata": {},
   "source": [
    "## GPTQModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "69d4169d-60e0-4276-b240-9fbb88f6685b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/usr/local/cuda-12.4\n"
     ]
    }
   ],
   "source": [
    "## clone repo\n",
    "#!git clone https://github.com/ModelCloud/GPTQModel.git && cd GPTQModel\n",
    "import os\n",
    "os.environ['CUDA_HOME'] = '/usr/local/cuda-12.4'  # have to explicitly define CUDA_HOME for gptqmodel install to work\n",
    "os.environ['PATH'] = f\"{os.environ['CUDA_HOME']}/bin:{os.environ['PATH']}\"\n",
    "os.environ['LD_LIBRARY_PATH'] = f\"{os.environ['CUDA_HOME']}/lib64:{os.environ.get('LD_LIBRARY_PATH', '')}\"\n",
    "!echo $CUDA_HOME"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c8717b3e-2ea3-4bc4-a374-6ce9beea2030",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: accelerate>=1.3.0 in /opt/conda/lib/python3.11/site-packages (from -r /home/jovyan/GPTQModel/requirements.txt (line 1)) (1.4.0)\n",
      "Requirement already satisfied: datasets>=3.2.0 in /opt/conda/lib/python3.11/site-packages (from -r /home/jovyan/GPTQModel/requirements.txt (line 2)) (3.3.2)\n",
      "Collecting numpy>=2.2.2 (from -r /home/jovyan/GPTQModel/requirements.txt (line 3))\n",
      "  Using cached numpy-2.2.3-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (62 kB)\n",
      "Requirement already satisfied: torch>=2.2.0 in /opt/conda/lib/python3.11/site-packages (from -r /home/jovyan/GPTQModel/requirements.txt (line 4)) (2.3.0+cu121)\n",
      "Requirement already satisfied: safetensors>=0.5.2 in /opt/conda/lib/python3.11/site-packages (from -r /home/jovyan/GPTQModel/requirements.txt (line 5)) (0.5.2)\n",
      "Requirement already satisfied: transformers>=4.48.3 in /opt/conda/lib/python3.11/site-packages (from -r /home/jovyan/GPTQModel/requirements.txt (line 6)) (4.49.0)\n",
      "Requirement already satisfied: threadpoolctl>=3.5.0 in /opt/conda/lib/python3.11/site-packages (from -r /home/jovyan/GPTQModel/requirements.txt (line 7)) (3.5.0)\n",
      "Requirement already satisfied: packaging>=24.2 in /opt/conda/lib/python3.11/site-packages (from -r /home/jovyan/GPTQModel/requirements.txt (line 8)) (24.2)\n",
      "Requirement already satisfied: device-smi==0.3.3 in /opt/conda/lib/python3.11/site-packages (from -r /home/jovyan/GPTQModel/requirements.txt (line 9)) (0.3.3)\n",
      "Requirement already satisfied: protobuf>=5.29.3 in /opt/conda/lib/python3.11/site-packages (from -r /home/jovyan/GPTQModel/requirements.txt (line 10)) (5.29.3)\n",
      "Requirement already satisfied: pillow>=11.1.0 in /opt/conda/lib/python3.11/site-packages (from -r /home/jovyan/GPTQModel/requirements.txt (line 11)) (11.1.0)\n",
      "Requirement already satisfied: hf_transfer>=0.1.9 in /opt/conda/lib/python3.11/site-packages (from -r /home/jovyan/GPTQModel/requirements.txt (line 12)) (0.1.9)\n",
      "Requirement already satisfied: huggingface_hub>=0.28.1 in /opt/conda/lib/python3.11/site-packages (from -r /home/jovyan/GPTQModel/requirements.txt (line 13)) (0.29.1)\n",
      "Requirement already satisfied: tokenicer>=0.0.2 in /opt/conda/lib/python3.11/site-packages (from -r /home/jovyan/GPTQModel/requirements.txt (line 14)) (0.0.4)\n",
      "Requirement already satisfied: psutil in /opt/conda/lib/python3.11/site-packages (from accelerate>=1.3.0->-r /home/jovyan/GPTQModel/requirements.txt (line 1)) (5.9.8)\n",
      "Requirement already satisfied: pyyaml in /opt/conda/lib/python3.11/site-packages (from accelerate>=1.3.0->-r /home/jovyan/GPTQModel/requirements.txt (line 1)) (6.0.1)\n",
      "Requirement already satisfied: filelock in /opt/conda/lib/python3.11/site-packages (from datasets>=3.2.0->-r /home/jovyan/GPTQModel/requirements.txt (line 2)) (3.13.1)\n",
      "Requirement already satisfied: pyarrow>=15.0.0 in /opt/conda/lib/python3.11/site-packages (from datasets>=3.2.0->-r /home/jovyan/GPTQModel/requirements.txt (line 2)) (16.1.0)\n",
      "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /opt/conda/lib/python3.11/site-packages (from datasets>=3.2.0->-r /home/jovyan/GPTQModel/requirements.txt (line 2)) (0.3.8)\n",
      "Requirement already satisfied: pandas in /opt/conda/lib/python3.11/site-packages (from datasets>=3.2.0->-r /home/jovyan/GPTQModel/requirements.txt (line 2)) (2.2.2)\n",
      "Requirement already satisfied: requests>=2.32.2 in /opt/conda/lib/python3.11/site-packages (from datasets>=3.2.0->-r /home/jovyan/GPTQModel/requirements.txt (line 2)) (2.32.3)\n",
      "Requirement already satisfied: tqdm>=4.66.3 in /opt/conda/lib/python3.11/site-packages (from datasets>=3.2.0->-r /home/jovyan/GPTQModel/requirements.txt (line 2)) (4.66.4)\n",
      "Requirement already satisfied: xxhash in /opt/conda/lib/python3.11/site-packages (from datasets>=3.2.0->-r /home/jovyan/GPTQModel/requirements.txt (line 2)) (3.5.0)\n",
      "Requirement already satisfied: multiprocess<0.70.17 in /opt/conda/lib/python3.11/site-packages (from datasets>=3.2.0->-r /home/jovyan/GPTQModel/requirements.txt (line 2)) (0.70.16)\n",
      "Requirement already satisfied: fsspec<=2024.12.0,>=2023.1.0 in /opt/conda/lib/python3.11/site-packages (from fsspec[http]<=2024.12.0,>=2023.1.0->datasets>=3.2.0->-r /home/jovyan/GPTQModel/requirements.txt (line 2)) (2024.5.0)\n",
      "Requirement already satisfied: aiohttp in /opt/conda/lib/python3.11/site-packages (from datasets>=3.2.0->-r /home/jovyan/GPTQModel/requirements.txt (line 2)) (3.9.5)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in /opt/conda/lib/python3.11/site-packages (from torch>=2.2.0->-r /home/jovyan/GPTQModel/requirements.txt (line 4)) (4.11.0)\n",
      "Requirement already satisfied: sympy in /opt/conda/lib/python3.11/site-packages (from torch>=2.2.0->-r /home/jovyan/GPTQModel/requirements.txt (line 4)) (1.12)\n",
      "Requirement already satisfied: networkx in /opt/conda/lib/python3.11/site-packages (from torch>=2.2.0->-r /home/jovyan/GPTQModel/requirements.txt (line 4)) (3.3)\n",
      "Requirement already satisfied: jinja2 in /opt/conda/lib/python3.11/site-packages (from torch>=2.2.0->-r /home/jovyan/GPTQModel/requirements.txt (line 4)) (3.1.4)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /opt/conda/lib/python3.11/site-packages (from torch>=2.2.0->-r /home/jovyan/GPTQModel/requirements.txt (line 4)) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /opt/conda/lib/python3.11/site-packages (from torch>=2.2.0->-r /home/jovyan/GPTQModel/requirements.txt (line 4)) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /opt/conda/lib/python3.11/site-packages (from torch>=2.2.0->-r /home/jovyan/GPTQModel/requirements.txt (line 4)) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /opt/conda/lib/python3.11/site-packages (from torch>=2.2.0->-r /home/jovyan/GPTQModel/requirements.txt (line 4)) (8.9.2.26)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /opt/conda/lib/python3.11/site-packages (from torch>=2.2.0->-r /home/jovyan/GPTQModel/requirements.txt (line 4)) (12.1.3.1)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /opt/conda/lib/python3.11/site-packages (from torch>=2.2.0->-r /home/jovyan/GPTQModel/requirements.txt (line 4)) (11.0.2.54)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /opt/conda/lib/python3.11/site-packages (from torch>=2.2.0->-r /home/jovyan/GPTQModel/requirements.txt (line 4)) (10.3.2.106)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /opt/conda/lib/python3.11/site-packages (from torch>=2.2.0->-r /home/jovyan/GPTQModel/requirements.txt (line 4)) (11.4.5.107)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /opt/conda/lib/python3.11/site-packages (from torch>=2.2.0->-r /home/jovyan/GPTQModel/requirements.txt (line 4)) (12.1.0.106)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.20.5 in /opt/conda/lib/python3.11/site-packages (from torch>=2.2.0->-r /home/jovyan/GPTQModel/requirements.txt (line 4)) (2.20.5)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /opt/conda/lib/python3.11/site-packages (from torch>=2.2.0->-r /home/jovyan/GPTQModel/requirements.txt (line 4)) (12.1.105)\n",
      "Requirement already satisfied: triton==2.3.0 in /opt/conda/lib/python3.11/site-packages (from torch>=2.2.0->-r /home/jovyan/GPTQModel/requirements.txt (line 4)) (2.3.0)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12 in /opt/conda/lib/python3.11/site-packages (from nvidia-cusolver-cu12==11.4.5.107->torch>=2.2.0->-r /home/jovyan/GPTQModel/requirements.txt (line 4)) (12.3.101)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.11/site-packages (from transformers>=4.48.3->-r /home/jovyan/GPTQModel/requirements.txt (line 6)) (2024.5.15)\n",
      "Requirement already satisfied: tokenizers<0.22,>=0.21 in /opt/conda/lib/python3.11/site-packages (from transformers>=4.48.3->-r /home/jovyan/GPTQModel/requirements.txt (line 6)) (0.21.0)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /opt/conda/lib/python3.11/site-packages (from aiohttp->datasets>=3.2.0->-r /home/jovyan/GPTQModel/requirements.txt (line 2)) (1.3.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /opt/conda/lib/python3.11/site-packages (from aiohttp->datasets>=3.2.0->-r /home/jovyan/GPTQModel/requirements.txt (line 2)) (23.2.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /opt/conda/lib/python3.11/site-packages (from aiohttp->datasets>=3.2.0->-r /home/jovyan/GPTQModel/requirements.txt (line 2)) (1.4.1)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /opt/conda/lib/python3.11/site-packages (from aiohttp->datasets>=3.2.0->-r /home/jovyan/GPTQModel/requirements.txt (line 2)) (6.0.5)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /opt/conda/lib/python3.11/site-packages (from aiohttp->datasets>=3.2.0->-r /home/jovyan/GPTQModel/requirements.txt (line 2)) (1.9.4)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.11/site-packages (from requests>=2.32.2->datasets>=3.2.0->-r /home/jovyan/GPTQModel/requirements.txt (line 2)) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.11/site-packages (from requests>=2.32.2->datasets>=3.2.0->-r /home/jovyan/GPTQModel/requirements.txt (line 2)) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.11/site-packages (from requests>=2.32.2->datasets>=3.2.0->-r /home/jovyan/GPTQModel/requirements.txt (line 2)) (2.2.1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.11/site-packages (from requests>=2.32.2->datasets>=3.2.0->-r /home/jovyan/GPTQModel/requirements.txt (line 2)) (2024.2.2)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.11/site-packages (from jinja2->torch>=2.2.0->-r /home/jovyan/GPTQModel/requirements.txt (line 4)) (2.1.5)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /opt/conda/lib/python3.11/site-packages (from pandas->datasets>=3.2.0->-r /home/jovyan/GPTQModel/requirements.txt (line 2)) (2.9.0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.11/site-packages (from pandas->datasets>=3.2.0->-r /home/jovyan/GPTQModel/requirements.txt (line 2)) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /opt/conda/lib/python3.11/site-packages (from pandas->datasets>=3.2.0->-r /home/jovyan/GPTQModel/requirements.txt (line 2)) (2024.1)\n",
      "Requirement already satisfied: mpmath>=0.19 in /opt/conda/lib/python3.11/site-packages (from sympy->torch>=2.2.0->-r /home/jovyan/GPTQModel/requirements.txt (line 4)) (1.3.0)\n",
      "Requirement already satisfied: six>=1.5 in /opt/conda/lib/python3.11/site-packages (from python-dateutil>=2.8.2->pandas->datasets>=3.2.0->-r /home/jovyan/GPTQModel/requirements.txt (line 2)) (1.16.0)\n",
      "Using cached numpy-2.2.3-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (16.4 MB)\n",
      "Installing collected packages: numpy\n",
      "  Attempting uninstall: numpy\n",
      "    Found existing installation: numpy 1.24.3\n",
      "    Uninstalling numpy-1.24.3:\n",
      "      Successfully uninstalled numpy-1.24.3\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "cupy-cuda11x 13.1.0 requires numpy<1.29,>=1.22, but you have numpy 2.2.3 which is incompatible.\n",
      "cuquantum-python-cu11 24.3.0.post1 requires numpy~=1.21, but you have numpy 2.2.3 which is incompatible.\n",
      "langchain 0.1.20 requires numpy<2,>=1, but you have numpy 2.2.3 which is incompatible.\n",
      "langchain-community 0.0.38 requires numpy<2,>=1, but you have numpy 2.2.3 which is incompatible.\n",
      "together 1.2.0 requires pillow<11.0.0,>=10.3.0, but you have pillow 11.1.0 which is incompatible.\n",
      "tensorflow 2.16.1 requires numpy<2.0.0,>=1.23.5; python_version <= \"3.11\", but you have numpy 2.2.3 which is incompatible.\n",
      "tensorflow 2.16.1 requires protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3, but you have protobuf 5.29.3 which is incompatible.\n",
      "numba 0.59.1 requires numpy<1.27,>=1.22, but you have numpy 2.2.3 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0mSuccessfully installed numpy-2.2.3\n"
     ]
    }
   ],
   "source": [
    "!pip install -r /home/jovyan/GPTQModel/requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ecfd1d25-e51f-4b53-a1e1-5814ff7b0b1c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting gptqmodel\n",
      "  Using cached gptqmodel-1.9.0+cu121torch2.3-cp311-cp311-linux_x86_64.whl\n",
      "Discarding \u001b[4;34mhttps://files.pythonhosted.org/packages/db/b6/348569757042bb3a674935fe20ae059e56866b4c544e0fa354daf47db14f/gptqmodel-1.9.0.tar.gz (from https://pypi.org/simple/gptqmodel/) (requires-python:>=3.9.0)\u001b[0m: \u001b[33mRequested gptqmodel from file:///home/jovyan/.cache/pip/wheels/75/dc/a8/85f4e3aafe265c6f4df9f372b22be86b20de8d1b65b0680268/gptqmodel-1.9.0%2Bcu121torch2.3-cp311-cp311-linux_x86_64.whl has inconsistent version: expected '1.9.0', but metadata has '1.9.0+cu121torch2.3'\u001b[0m\n",
      "  Using cached gptqmodel-1.8.1+cu121torch2.3-cp311-cp311-linux_x86_64.whl\n",
      "Discarding \u001b[4;34mhttps://files.pythonhosted.org/packages/46/30/cb98de206a29807a59e63c10238eb90570143229df9b67a9a7f2342672bd/gptqmodel-1.8.1.tar.gz (from https://pypi.org/simple/gptqmodel/) (requires-python:>=3.9.0)\u001b[0m: \u001b[33mRequested gptqmodel from file:///home/jovyan/.cache/pip/wheels/64/3e/c4/a4d5f7b326cc1970ddee6324a2d6652b2cd290f40cda86cfc9/gptqmodel-1.8.1%2Bcu121torch2.3-cp311-cp311-linux_x86_64.whl has inconsistent version: expected '1.8.1', but metadata has '1.8.1+cu121torch2.3'\u001b[0m\n",
      "  Using cached gptqmodel-1.8.0+cu121torch2.3-cp311-cp311-linux_x86_64.whl\n",
      "Discarding \u001b[4;34mhttps://files.pythonhosted.org/packages/a2/de/aed10b4936b7c56870d3af7892ce51ebcdff2d5d0f13a09cb9b337e91df0/gptqmodel-1.8.0.tar.gz (from https://pypi.org/simple/gptqmodel/) (requires-python:>=3.9.0)\u001b[0m: \u001b[33mRequested gptqmodel from file:///home/jovyan/.cache/pip/wheels/02/57/fe/68ece9edf903fa00e392f794ca6b3a915d352a71a9aafe4246/gptqmodel-1.8.0%2Bcu121torch2.3-cp311-cp311-linux_x86_64.whl has inconsistent version: expected '1.8.0', but metadata has '1.8.0+cu121torch2.3'\u001b[0m\n",
      "  Using cached gptqmodel-1.7.4+cu121torch2.3-cp311-cp311-linux_x86_64.whl\n",
      "Discarding \u001b[4;34mhttps://files.pythonhosted.org/packages/b3/03/bbe6e9cd935f24f4a789b8919bcc7948bbe9860b2c67c972d4f474e12632/gptqmodel-1.7.4.tar.gz (from https://pypi.org/simple/gptqmodel/) (requires-python:>=3.9.0)\u001b[0m: \u001b[33mRequested gptqmodel from file:///home/jovyan/.cache/pip/wheels/b0/d9/43/6f4492a30c6ea2cb0b8e078b029f952ebbc11b9ff94ea6d376/gptqmodel-1.7.4%2Bcu121torch2.3-cp311-cp311-linux_x86_64.whl has inconsistent version: expected '1.7.4', but metadata has '1.7.4+cu121torch2.3'\u001b[0m\n",
      "  Using cached gptqmodel-1.7.3.tar.gz (295 kB)\n",
      "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hRequirement already satisfied: accelerate>=1.2.1 in /opt/conda/lib/python3.11/site-packages (from gptqmodel) (1.4.0)\n",
      "Requirement already satisfied: datasets>=3.1.0 in /opt/conda/lib/python3.11/site-packages (from gptqmodel) (3.3.2)\n",
      "Requirement already satisfied: numpy>=1.26.4 in /opt/conda/lib/python3.11/site-packages (from gptqmodel) (2.2.3)\n",
      "Requirement already satisfied: torch>=2.0.0 in /opt/conda/lib/python3.11/site-packages (from gptqmodel) (2.3.0+cu121)\n",
      "Requirement already satisfied: safetensors>=0.4.5 in /opt/conda/lib/python3.11/site-packages (from gptqmodel) (0.5.2)\n",
      "Requirement already satisfied: transformers>=4.47.1 in /opt/conda/lib/python3.11/site-packages (from gptqmodel) (4.49.0)\n",
      "Requirement already satisfied: threadpoolctl>=3.5.0 in /opt/conda/lib/python3.11/site-packages (from gptqmodel) (3.5.0)\n",
      "Requirement already satisfied: packaging>=24.2 in /opt/conda/lib/python3.11/site-packages (from gptqmodel) (24.2)\n",
      "Requirement already satisfied: device-smi==0.3.3 in /opt/conda/lib/python3.11/site-packages (from gptqmodel) (0.3.3)\n",
      "Requirement already satisfied: sentencepiece>=0.2.0 in /opt/conda/lib/python3.11/site-packages (from gptqmodel) (0.2.0)\n",
      "Requirement already satisfied: protobuf>=5.29.1 in /opt/conda/lib/python3.11/site-packages (from gptqmodel) (5.29.3)\n",
      "Requirement already satisfied: pillow>=10.4.0 in /opt/conda/lib/python3.11/site-packages (from gptqmodel) (11.1.0)\n",
      "Requirement already satisfied: psutil in /opt/conda/lib/python3.11/site-packages (from accelerate>=1.2.1->gptqmodel) (5.9.8)\n",
      "Requirement already satisfied: pyyaml in /opt/conda/lib/python3.11/site-packages (from accelerate>=1.2.1->gptqmodel) (6.0.1)\n",
      "Requirement already satisfied: huggingface-hub>=0.21.0 in /opt/conda/lib/python3.11/site-packages (from accelerate>=1.2.1->gptqmodel) (0.29.1)\n",
      "Requirement already satisfied: filelock in /opt/conda/lib/python3.11/site-packages (from datasets>=3.1.0->gptqmodel) (3.13.1)\n",
      "Requirement already satisfied: pyarrow>=15.0.0 in /opt/conda/lib/python3.11/site-packages (from datasets>=3.1.0->gptqmodel) (16.1.0)\n",
      "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /opt/conda/lib/python3.11/site-packages (from datasets>=3.1.0->gptqmodel) (0.3.8)\n",
      "Requirement already satisfied: pandas in /opt/conda/lib/python3.11/site-packages (from datasets>=3.1.0->gptqmodel) (2.2.2)\n",
      "Requirement already satisfied: requests>=2.32.2 in /opt/conda/lib/python3.11/site-packages (from datasets>=3.1.0->gptqmodel) (2.32.3)\n",
      "Requirement already satisfied: tqdm>=4.66.3 in /opt/conda/lib/python3.11/site-packages (from datasets>=3.1.0->gptqmodel) (4.66.4)\n",
      "Requirement already satisfied: xxhash in /opt/conda/lib/python3.11/site-packages (from datasets>=3.1.0->gptqmodel) (3.5.0)\n",
      "Requirement already satisfied: multiprocess<0.70.17 in /opt/conda/lib/python3.11/site-packages (from datasets>=3.1.0->gptqmodel) (0.70.16)\n",
      "Requirement already satisfied: fsspec<=2024.12.0,>=2023.1.0 in /opt/conda/lib/python3.11/site-packages (from fsspec[http]<=2024.12.0,>=2023.1.0->datasets>=3.1.0->gptqmodel) (2024.5.0)\n",
      "Requirement already satisfied: aiohttp in /opt/conda/lib/python3.11/site-packages (from datasets>=3.1.0->gptqmodel) (3.9.5)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in /opt/conda/lib/python3.11/site-packages (from torch>=2.0.0->gptqmodel) (4.11.0)\n",
      "Requirement already satisfied: sympy in /opt/conda/lib/python3.11/site-packages (from torch>=2.0.0->gptqmodel) (1.12)\n",
      "Requirement already satisfied: networkx in /opt/conda/lib/python3.11/site-packages (from torch>=2.0.0->gptqmodel) (3.3)\n",
      "Requirement already satisfied: jinja2 in /opt/conda/lib/python3.11/site-packages (from torch>=2.0.0->gptqmodel) (3.1.4)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /opt/conda/lib/python3.11/site-packages (from torch>=2.0.0->gptqmodel) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /opt/conda/lib/python3.11/site-packages (from torch>=2.0.0->gptqmodel) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /opt/conda/lib/python3.11/site-packages (from torch>=2.0.0->gptqmodel) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /opt/conda/lib/python3.11/site-packages (from torch>=2.0.0->gptqmodel) (8.9.2.26)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /opt/conda/lib/python3.11/site-packages (from torch>=2.0.0->gptqmodel) (12.1.3.1)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /opt/conda/lib/python3.11/site-packages (from torch>=2.0.0->gptqmodel) (11.0.2.54)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /opt/conda/lib/python3.11/site-packages (from torch>=2.0.0->gptqmodel) (10.3.2.106)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /opt/conda/lib/python3.11/site-packages (from torch>=2.0.0->gptqmodel) (11.4.5.107)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /opt/conda/lib/python3.11/site-packages (from torch>=2.0.0->gptqmodel) (12.1.0.106)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.20.5 in /opt/conda/lib/python3.11/site-packages (from torch>=2.0.0->gptqmodel) (2.20.5)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /opt/conda/lib/python3.11/site-packages (from torch>=2.0.0->gptqmodel) (12.1.105)\n",
      "Requirement already satisfied: triton==2.3.0 in /opt/conda/lib/python3.11/site-packages (from torch>=2.0.0->gptqmodel) (2.3.0)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12 in /opt/conda/lib/python3.11/site-packages (from nvidia-cusolver-cu12==11.4.5.107->torch>=2.0.0->gptqmodel) (12.3.101)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.11/site-packages (from transformers>=4.47.1->gptqmodel) (2024.5.15)\n",
      "Requirement already satisfied: tokenizers<0.22,>=0.21 in /opt/conda/lib/python3.11/site-packages (from transformers>=4.47.1->gptqmodel) (0.21.0)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /opt/conda/lib/python3.11/site-packages (from aiohttp->datasets>=3.1.0->gptqmodel) (1.3.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /opt/conda/lib/python3.11/site-packages (from aiohttp->datasets>=3.1.0->gptqmodel) (23.2.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /opt/conda/lib/python3.11/site-packages (from aiohttp->datasets>=3.1.0->gptqmodel) (1.4.1)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /opt/conda/lib/python3.11/site-packages (from aiohttp->datasets>=3.1.0->gptqmodel) (6.0.5)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /opt/conda/lib/python3.11/site-packages (from aiohttp->datasets>=3.1.0->gptqmodel) (1.9.4)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.11/site-packages (from requests>=2.32.2->datasets>=3.1.0->gptqmodel) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.11/site-packages (from requests>=2.32.2->datasets>=3.1.0->gptqmodel) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.11/site-packages (from requests>=2.32.2->datasets>=3.1.0->gptqmodel) (2.2.1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.11/site-packages (from requests>=2.32.2->datasets>=3.1.0->gptqmodel) (2024.2.2)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.11/site-packages (from jinja2->torch>=2.0.0->gptqmodel) (2.1.5)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /opt/conda/lib/python3.11/site-packages (from pandas->datasets>=3.1.0->gptqmodel) (2.9.0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.11/site-packages (from pandas->datasets>=3.1.0->gptqmodel) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /opt/conda/lib/python3.11/site-packages (from pandas->datasets>=3.1.0->gptqmodel) (2024.1)\n",
      "Requirement already satisfied: mpmath>=0.19 in /opt/conda/lib/python3.11/site-packages (from sympy->torch>=2.0.0->gptqmodel) (1.3.0)\n",
      "Requirement already satisfied: six>=1.5 in /opt/conda/lib/python3.11/site-packages (from python-dateutil>=2.8.2->pandas->datasets>=3.1.0->gptqmodel) (1.16.0)\n",
      "Building wheels for collected packages: gptqmodel\n",
      "  Building wheel for gptqmodel (setup.py) ... \u001b[?25lerror\n",
      "  \u001b[1;31merror\u001b[0m: \u001b[1msubprocess-exited-with-error\u001b[0m\n",
      "  \n",
      "  \u001b[31m×\u001b[0m \u001b[32mpython setup.py bdist_wheel\u001b[0m did not run successfully.\n",
      "  \u001b[31m│\u001b[0m exit code: \u001b[1;36m1\u001b[0m\n",
      "  \u001b[31m╰─>\u001b[0m \u001b[31m[226 lines of output]\u001b[0m\n",
      "  \u001b[31m   \u001b[0m Requirement already satisfied: accelerate>=1.2.1 in /opt/conda/lib/python3.11/site-packages (from -r requirements.txt (line 1)) (1.4.0)\n",
      "  \u001b[31m   \u001b[0m Requirement already satisfied: datasets>=3.1.0 in /opt/conda/lib/python3.11/site-packages (from -r requirements.txt (line 2)) (3.3.2)\n",
      "  \u001b[31m   \u001b[0m Requirement already satisfied: numpy>=1.26.4 in /opt/conda/lib/python3.11/site-packages (from -r requirements.txt (line 3)) (2.2.3)\n",
      "  \u001b[31m   \u001b[0m Requirement already satisfied: torch>=2.0.0 in /opt/conda/lib/python3.11/site-packages (from -r requirements.txt (line 4)) (2.3.0+cu121)\n",
      "  \u001b[31m   \u001b[0m Requirement already satisfied: safetensors>=0.4.5 in /opt/conda/lib/python3.11/site-packages (from -r requirements.txt (line 5)) (0.5.2)\n",
      "  \u001b[31m   \u001b[0m Requirement already satisfied: transformers>=4.47.1 in /opt/conda/lib/python3.11/site-packages (from -r requirements.txt (line 6)) (4.49.0)\n",
      "  \u001b[31m   \u001b[0m Requirement already satisfied: threadpoolctl>=3.5.0 in /opt/conda/lib/python3.11/site-packages (from -r requirements.txt (line 7)) (3.5.0)\n",
      "  \u001b[31m   \u001b[0m Requirement already satisfied: packaging>=24.2 in /opt/conda/lib/python3.11/site-packages (from -r requirements.txt (line 8)) (24.2)\n",
      "  \u001b[31m   \u001b[0m Requirement already satisfied: device-smi==0.3.3 in /opt/conda/lib/python3.11/site-packages (from -r requirements.txt (line 9)) (0.3.3)\n",
      "  \u001b[31m   \u001b[0m Requirement already satisfied: sentencepiece>=0.2.0 in /opt/conda/lib/python3.11/site-packages (from -r requirements.txt (line 10)) (0.2.0)\n",
      "  \u001b[31m   \u001b[0m Requirement already satisfied: protobuf>=5.29.1 in /opt/conda/lib/python3.11/site-packages (from -r requirements.txt (line 11)) (5.29.3)\n",
      "  \u001b[31m   \u001b[0m Requirement already satisfied: pillow>=10.4.0 in /opt/conda/lib/python3.11/site-packages (from -r requirements.txt (line 12)) (11.1.0)\n",
      "  \u001b[31m   \u001b[0m Requirement already satisfied: psutil in /opt/conda/lib/python3.11/site-packages (from accelerate>=1.2.1->-r requirements.txt (line 1)) (5.9.8)\n",
      "  \u001b[31m   \u001b[0m Requirement already satisfied: pyyaml in /opt/conda/lib/python3.11/site-packages (from accelerate>=1.2.1->-r requirements.txt (line 1)) (6.0.1)\n",
      "  \u001b[31m   \u001b[0m Requirement already satisfied: huggingface-hub>=0.21.0 in /opt/conda/lib/python3.11/site-packages (from accelerate>=1.2.1->-r requirements.txt (line 1)) (0.29.1)\n",
      "  \u001b[31m   \u001b[0m Requirement already satisfied: filelock in /opt/conda/lib/python3.11/site-packages (from datasets>=3.1.0->-r requirements.txt (line 2)) (3.13.1)\n",
      "  \u001b[31m   \u001b[0m Requirement already satisfied: pyarrow>=15.0.0 in /opt/conda/lib/python3.11/site-packages (from datasets>=3.1.0->-r requirements.txt (line 2)) (16.1.0)\n",
      "  \u001b[31m   \u001b[0m Requirement already satisfied: dill<0.3.9,>=0.3.0 in /opt/conda/lib/python3.11/site-packages (from datasets>=3.1.0->-r requirements.txt (line 2)) (0.3.8)\n",
      "  \u001b[31m   \u001b[0m Requirement already satisfied: pandas in /opt/conda/lib/python3.11/site-packages (from datasets>=3.1.0->-r requirements.txt (line 2)) (2.2.2)\n",
      "  \u001b[31m   \u001b[0m Requirement already satisfied: requests>=2.32.2 in /opt/conda/lib/python3.11/site-packages (from datasets>=3.1.0->-r requirements.txt (line 2)) (2.32.3)\n",
      "  \u001b[31m   \u001b[0m Requirement already satisfied: tqdm>=4.66.3 in /opt/conda/lib/python3.11/site-packages (from datasets>=3.1.0->-r requirements.txt (line 2)) (4.66.4)\n",
      "  \u001b[31m   \u001b[0m Requirement already satisfied: xxhash in /opt/conda/lib/python3.11/site-packages (from datasets>=3.1.0->-r requirements.txt (line 2)) (3.5.0)\n",
      "  \u001b[31m   \u001b[0m Requirement already satisfied: multiprocess<0.70.17 in /opt/conda/lib/python3.11/site-packages (from datasets>=3.1.0->-r requirements.txt (line 2)) (0.70.16)\n",
      "  \u001b[31m   \u001b[0m Requirement already satisfied: fsspec<=2024.12.0,>=2023.1.0 in /opt/conda/lib/python3.11/site-packages (from fsspec[http]<=2024.12.0,>=2023.1.0->datasets>=3.1.0->-r requirements.txt (line 2)) (2024.5.0)\n",
      "  \u001b[31m   \u001b[0m Requirement already satisfied: aiohttp in /opt/conda/lib/python3.11/site-packages (from datasets>=3.1.0->-r requirements.txt (line 2)) (3.9.5)\n",
      "  \u001b[31m   \u001b[0m Requirement already satisfied: typing-extensions>=4.8.0 in /opt/conda/lib/python3.11/site-packages (from torch>=2.0.0->-r requirements.txt (line 4)) (4.11.0)\n",
      "  \u001b[31m   \u001b[0m Requirement already satisfied: sympy in /opt/conda/lib/python3.11/site-packages (from torch>=2.0.0->-r requirements.txt (line 4)) (1.12)\n",
      "  \u001b[31m   \u001b[0m Requirement already satisfied: networkx in /opt/conda/lib/python3.11/site-packages (from torch>=2.0.0->-r requirements.txt (line 4)) (3.3)\n",
      "  \u001b[31m   \u001b[0m Requirement already satisfied: jinja2 in /opt/conda/lib/python3.11/site-packages (from torch>=2.0.0->-r requirements.txt (line 4)) (3.1.4)\n",
      "  \u001b[31m   \u001b[0m Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /opt/conda/lib/python3.11/site-packages (from torch>=2.0.0->-r requirements.txt (line 4)) (12.1.105)\n",
      "  \u001b[31m   \u001b[0m Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /opt/conda/lib/python3.11/site-packages (from torch>=2.0.0->-r requirements.txt (line 4)) (12.1.105)\n",
      "  \u001b[31m   \u001b[0m Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /opt/conda/lib/python3.11/site-packages (from torch>=2.0.0->-r requirements.txt (line 4)) (12.1.105)\n",
      "  \u001b[31m   \u001b[0m Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /opt/conda/lib/python3.11/site-packages (from torch>=2.0.0->-r requirements.txt (line 4)) (8.9.2.26)\n",
      "  \u001b[31m   \u001b[0m Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /opt/conda/lib/python3.11/site-packages (from torch>=2.0.0->-r requirements.txt (line 4)) (12.1.3.1)\n",
      "  \u001b[31m   \u001b[0m Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /opt/conda/lib/python3.11/site-packages (from torch>=2.0.0->-r requirements.txt (line 4)) (11.0.2.54)\n",
      "  \u001b[31m   \u001b[0m Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /opt/conda/lib/python3.11/site-packages (from torch>=2.0.0->-r requirements.txt (line 4)) (10.3.2.106)\n",
      "  \u001b[31m   \u001b[0m Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /opt/conda/lib/python3.11/site-packages (from torch>=2.0.0->-r requirements.txt (line 4)) (11.4.5.107)\n",
      "  \u001b[31m   \u001b[0m Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /opt/conda/lib/python3.11/site-packages (from torch>=2.0.0->-r requirements.txt (line 4)) (12.1.0.106)\n",
      "  \u001b[31m   \u001b[0m Requirement already satisfied: nvidia-nccl-cu12==2.20.5 in /opt/conda/lib/python3.11/site-packages (from torch>=2.0.0->-r requirements.txt (line 4)) (2.20.5)\n",
      "  \u001b[31m   \u001b[0m Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /opt/conda/lib/python3.11/site-packages (from torch>=2.0.0->-r requirements.txt (line 4)) (12.1.105)\n",
      "  \u001b[31m   \u001b[0m Requirement already satisfied: triton==2.3.0 in /opt/conda/lib/python3.11/site-packages (from torch>=2.0.0->-r requirements.txt (line 4)) (2.3.0)\n",
      "  \u001b[31m   \u001b[0m Requirement already satisfied: nvidia-nvjitlink-cu12 in /opt/conda/lib/python3.11/site-packages (from nvidia-cusolver-cu12==11.4.5.107->torch>=2.0.0->-r requirements.txt (line 4)) (12.3.101)\n",
      "  \u001b[31m   \u001b[0m Requirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.11/site-packages (from transformers>=4.47.1->-r requirements.txt (line 6)) (2024.5.15)\n",
      "  \u001b[31m   \u001b[0m Requirement already satisfied: tokenizers<0.22,>=0.21 in /opt/conda/lib/python3.11/site-packages (from transformers>=4.47.1->-r requirements.txt (line 6)) (0.21.0)\n",
      "  \u001b[31m   \u001b[0m Requirement already satisfied: aiosignal>=1.1.2 in /opt/conda/lib/python3.11/site-packages (from aiohttp->datasets>=3.1.0->-r requirements.txt (line 2)) (1.3.1)\n",
      "  \u001b[31m   \u001b[0m Requirement already satisfied: attrs>=17.3.0 in /opt/conda/lib/python3.11/site-packages (from aiohttp->datasets>=3.1.0->-r requirements.txt (line 2)) (23.2.0)\n",
      "  \u001b[31m   \u001b[0m Requirement already satisfied: frozenlist>=1.1.1 in /opt/conda/lib/python3.11/site-packages (from aiohttp->datasets>=3.1.0->-r requirements.txt (line 2)) (1.4.1)\n",
      "  \u001b[31m   \u001b[0m Requirement already satisfied: multidict<7.0,>=4.5 in /opt/conda/lib/python3.11/site-packages (from aiohttp->datasets>=3.1.0->-r requirements.txt (line 2)) (6.0.5)\n",
      "  \u001b[31m   \u001b[0m Requirement already satisfied: yarl<2.0,>=1.0 in /opt/conda/lib/python3.11/site-packages (from aiohttp->datasets>=3.1.0->-r requirements.txt (line 2)) (1.9.4)\n",
      "  \u001b[31m   \u001b[0m Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.11/site-packages (from requests>=2.32.2->datasets>=3.1.0->-r requirements.txt (line 2)) (3.3.2)\n",
      "  \u001b[31m   \u001b[0m Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.11/site-packages (from requests>=2.32.2->datasets>=3.1.0->-r requirements.txt (line 2)) (3.7)\n",
      "  \u001b[31m   \u001b[0m Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.11/site-packages (from requests>=2.32.2->datasets>=3.1.0->-r requirements.txt (line 2)) (2.2.1)\n",
      "  \u001b[31m   \u001b[0m Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.11/site-packages (from requests>=2.32.2->datasets>=3.1.0->-r requirements.txt (line 2)) (2024.2.2)\n",
      "  \u001b[31m   \u001b[0m Requirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.11/site-packages (from jinja2->torch>=2.0.0->-r requirements.txt (line 4)) (2.1.5)\n",
      "  \u001b[31m   \u001b[0m Requirement already satisfied: python-dateutil>=2.8.2 in /opt/conda/lib/python3.11/site-packages (from pandas->datasets>=3.1.0->-r requirements.txt (line 2)) (2.9.0)\n",
      "  \u001b[31m   \u001b[0m Requirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.11/site-packages (from pandas->datasets>=3.1.0->-r requirements.txt (line 2)) (2024.1)\n",
      "  \u001b[31m   \u001b[0m Requirement already satisfied: tzdata>=2022.7 in /opt/conda/lib/python3.11/site-packages (from pandas->datasets>=3.1.0->-r requirements.txt (line 2)) (2024.1)\n",
      "  \u001b[31m   \u001b[0m Requirement already satisfied: mpmath>=0.19 in /opt/conda/lib/python3.11/site-packages (from sympy->torch>=2.0.0->-r requirements.txt (line 4)) (1.3.0)\n",
      "  \u001b[31m   \u001b[0m Requirement already satisfied: six>=1.5 in /opt/conda/lib/python3.11/site-packages (from python-dateutil>=2.8.2->pandas->datasets>=3.1.0->-r requirements.txt (line 2)) (1.16.0)\n",
      "  \u001b[31m   \u001b[0m conda_cuda_include_dir /opt/conda/lib/python3.11/site-packages/nvidia/cuda_runtime/include\n",
      "  \u001b[31m   \u001b[0m appending conda cuda include dir /opt/conda/lib/python3.11/site-packages/nvidia/cuda_runtime/include\n",
      "  \u001b[31m   \u001b[0m marlin kernel only supports compute capability >= 8.0, there's no such cuda device, skipped.\n",
      "  \u001b[31m   \u001b[0m running bdist_wheel\n",
      "  \u001b[31m   \u001b[0m /opt/conda/lib/python3.11/site-packages/torch/utils/cpp_extension.py:499: UserWarning: Attempted to use ninja as the BuildExtension backend but we could not find ninja.. Falling back to using the slow distutils backend.\n",
      "  \u001b[31m   \u001b[0m   warnings.warn(msg.format('we could not find ninja.'))\n",
      "  \u001b[31m   \u001b[0m running build\n",
      "  \u001b[31m   \u001b[0m running build_py\n",
      "  \u001b[31m   \u001b[0m creating build\n",
      "  \u001b[31m   \u001b[0m creating build/lib.linux-x86_64-cpython-311\n",
      "  \u001b[31m   \u001b[0m creating build/lib.linux-x86_64-cpython-311/gptqmodel\n",
      "  \u001b[31m   \u001b[0m copying gptqmodel/__init__.py -> build/lib.linux-x86_64-cpython-311/gptqmodel\n",
      "  \u001b[31m   \u001b[0m copying gptqmodel/version.py -> build/lib.linux-x86_64-cpython-311/gptqmodel\n",
      "  \u001b[31m   \u001b[0m creating build/lib.linux-x86_64-cpython-311/gptqmodel/integration\n",
      "  \u001b[31m   \u001b[0m copying gptqmodel/integration/__init__.py -> build/lib.linux-x86_64-cpython-311/gptqmodel/integration\n",
      "  \u001b[31m   \u001b[0m copying gptqmodel/integration/integration.py -> build/lib.linux-x86_64-cpython-311/gptqmodel/integration\n",
      "  \u001b[31m   \u001b[0m copying gptqmodel/integration/integration_vllm.py -> build/lib.linux-x86_64-cpython-311/gptqmodel/integration\n",
      "  \u001b[31m   \u001b[0m creating build/lib.linux-x86_64-cpython-311/gptqmodel/models\n",
      "  \u001b[31m   \u001b[0m copying gptqmodel/models/__init__.py -> build/lib.linux-x86_64-cpython-311/gptqmodel/models\n",
      "  \u001b[31m   \u001b[0m copying gptqmodel/models/_const.py -> build/lib.linux-x86_64-cpython-311/gptqmodel/models\n",
      "  \u001b[31m   \u001b[0m copying gptqmodel/models/auto.py -> build/lib.linux-x86_64-cpython-311/gptqmodel/models\n",
      "  \u001b[31m   \u001b[0m copying gptqmodel/models/base.py -> build/lib.linux-x86_64-cpython-311/gptqmodel/models\n",
      "  \u001b[31m   \u001b[0m copying gptqmodel/models/loader.py -> build/lib.linux-x86_64-cpython-311/gptqmodel/models\n",
      "  \u001b[31m   \u001b[0m copying gptqmodel/models/writer.py -> build/lib.linux-x86_64-cpython-311/gptqmodel/models\n",
      "  \u001b[31m   \u001b[0m creating build/lib.linux-x86_64-cpython-311/gptqmodel/nn_modules\n",
      "  \u001b[31m   \u001b[0m copying gptqmodel/nn_modules/__init__.py -> build/lib.linux-x86_64-cpython-311/gptqmodel/nn_modules\n",
      "  \u001b[31m   \u001b[0m copying gptqmodel/nn_modules/hooked_linear.py -> build/lib.linux-x86_64-cpython-311/gptqmodel/nn_modules\n",
      "  \u001b[31m   \u001b[0m creating build/lib.linux-x86_64-cpython-311/gptqmodel/quantization\n",
      "  \u001b[31m   \u001b[0m copying gptqmodel/quantization/__init__.py -> build/lib.linux-x86_64-cpython-311/gptqmodel/quantization\n",
      "  \u001b[31m   \u001b[0m copying gptqmodel/quantization/config.py -> build/lib.linux-x86_64-cpython-311/gptqmodel/quantization\n",
      "  \u001b[31m   \u001b[0m copying gptqmodel/quantization/gptq.py -> build/lib.linux-x86_64-cpython-311/gptqmodel/quantization\n",
      "  \u001b[31m   \u001b[0m copying gptqmodel/quantization/quantizer.py -> build/lib.linux-x86_64-cpython-311/gptqmodel/quantization\n",
      "  \u001b[31m   \u001b[0m creating build/lib.linux-x86_64-cpython-311/gptqmodel/utils\n",
      "  \u001b[31m   \u001b[0m copying gptqmodel/utils/__init__.py -> build/lib.linux-x86_64-cpython-311/gptqmodel/utils\n",
      "  \u001b[31m   \u001b[0m copying gptqmodel/utils/backend.py -> build/lib.linux-x86_64-cpython-311/gptqmodel/utils\n",
      "  \u001b[31m   \u001b[0m copying gptqmodel/utils/bitblas.py -> build/lib.linux-x86_64-cpython-311/gptqmodel/utils\n",
      "  \u001b[31m   \u001b[0m copying gptqmodel/utils/calibration.py -> build/lib.linux-x86_64-cpython-311/gptqmodel/utils\n",
      "  \u001b[31m   \u001b[0m copying gptqmodel/utils/data.py -> build/lib.linux-x86_64-cpython-311/gptqmodel/utils\n",
      "  \u001b[31m   \u001b[0m copying gptqmodel/utils/device.py -> build/lib.linux-x86_64-cpython-311/gptqmodel/utils\n",
      "  \u001b[31m   \u001b[0m copying gptqmodel/utils/eval.py -> build/lib.linux-x86_64-cpython-311/gptqmodel/utils\n",
      "  \u001b[31m   \u001b[0m copying gptqmodel/utils/exllama.py -> build/lib.linux-x86_64-cpython-311/gptqmodel/utils\n",
      "  \u001b[31m   \u001b[0m copying gptqmodel/utils/image.py -> build/lib.linux-x86_64-cpython-311/gptqmodel/utils\n",
      "  \u001b[31m   \u001b[0m copying gptqmodel/utils/importer.py -> build/lib.linux-x86_64-cpython-311/gptqmodel/utils\n",
      "  \u001b[31m   \u001b[0m copying gptqmodel/utils/logger.py -> build/lib.linux-x86_64-cpython-311/gptqmodel/utils\n",
      "  \u001b[31m   \u001b[0m copying gptqmodel/utils/marlin.py -> build/lib.linux-x86_64-cpython-311/gptqmodel/utils\n",
      "  \u001b[31m   \u001b[0m copying gptqmodel/utils/mlx.py -> build/lib.linux-x86_64-cpython-311/gptqmodel/utils\n",
      "  \u001b[31m   \u001b[0m copying gptqmodel/utils/model.py -> build/lib.linux-x86_64-cpython-311/gptqmodel/utils\n",
      "  \u001b[31m   \u001b[0m copying gptqmodel/utils/openai_server.py -> build/lib.linux-x86_64-cpython-311/gptqmodel/utils\n",
      "  \u001b[31m   \u001b[0m copying gptqmodel/utils/perplexity.py -> build/lib.linux-x86_64-cpython-311/gptqmodel/utils\n",
      "  \u001b[31m   \u001b[0m copying gptqmodel/utils/plotly.py -> build/lib.linux-x86_64-cpython-311/gptqmodel/utils\n",
      "  \u001b[31m   \u001b[0m copying gptqmodel/utils/progress.py -> build/lib.linux-x86_64-cpython-311/gptqmodel/utils\n",
      "  \u001b[31m   \u001b[0m copying gptqmodel/utils/rocm.py -> build/lib.linux-x86_64-cpython-311/gptqmodel/utils\n",
      "  \u001b[31m   \u001b[0m copying gptqmodel/utils/sglang.py -> build/lib.linux-x86_64-cpython-311/gptqmodel/utils\n",
      "  \u001b[31m   \u001b[0m copying gptqmodel/utils/tensor.py -> build/lib.linux-x86_64-cpython-311/gptqmodel/utils\n",
      "  \u001b[31m   \u001b[0m copying gptqmodel/utils/torch.py -> build/lib.linux-x86_64-cpython-311/gptqmodel/utils\n",
      "  \u001b[31m   \u001b[0m copying gptqmodel/utils/vllm.py -> build/lib.linux-x86_64-cpython-311/gptqmodel/utils\n",
      "  \u001b[31m   \u001b[0m copying gptqmodel/utils/vram.py -> build/lib.linux-x86_64-cpython-311/gptqmodel/utils\n",
      "  \u001b[31m   \u001b[0m creating build/lib.linux-x86_64-cpython-311/gptqmodel/integration/src\n",
      "  \u001b[31m   \u001b[0m copying gptqmodel/integration/src/__init__.py -> build/lib.linux-x86_64-cpython-311/gptqmodel/integration/src\n",
      "  \u001b[31m   \u001b[0m creating build/lib.linux-x86_64-cpython-311/gptqmodel/integration/src/optimum\n",
      "  \u001b[31m   \u001b[0m copying gptqmodel/integration/src/optimum/__init__.py -> build/lib.linux-x86_64-cpython-311/gptqmodel/integration/src/optimum\n",
      "  \u001b[31m   \u001b[0m creating build/lib.linux-x86_64-cpython-311/gptqmodel/integration/src/peft\n",
      "  \u001b[31m   \u001b[0m copying gptqmodel/integration/src/peft/__init__.py -> build/lib.linux-x86_64-cpython-311/gptqmodel/integration/src/peft\n",
      "  \u001b[31m   \u001b[0m copying gptqmodel/integration/src/peft/import_utils.py -> build/lib.linux-x86_64-cpython-311/gptqmodel/integration/src/peft\n",
      "  \u001b[31m   \u001b[0m creating build/lib.linux-x86_64-cpython-311/gptqmodel/integration/src/transformers\n",
      "  \u001b[31m   \u001b[0m copying gptqmodel/integration/src/transformers/__init__.py -> build/lib.linux-x86_64-cpython-311/gptqmodel/integration/src/transformers\n",
      "  \u001b[31m   \u001b[0m copying gptqmodel/integration/src/transformers/testing_utils.py -> build/lib.linux-x86_64-cpython-311/gptqmodel/integration/src/transformers\n",
      "  \u001b[31m   \u001b[0m creating build/lib.linux-x86_64-cpython-311/gptqmodel/integration/src/vllm\n",
      "  \u001b[31m   \u001b[0m copying gptqmodel/integration/src/vllm/__init__.py -> build/lib.linux-x86_64-cpython-311/gptqmodel/integration/src/vllm\n",
      "  \u001b[31m   \u001b[0m copying gptqmodel/integration/src/vllm/gptq_marlin.py -> build/lib.linux-x86_64-cpython-311/gptqmodel/integration/src/vllm\n",
      "  \u001b[31m   \u001b[0m creating build/lib.linux-x86_64-cpython-311/gptqmodel/integration/src/optimum/gptq\n",
      "  \u001b[31m   \u001b[0m copying gptqmodel/integration/src/optimum/gptq/__init__.py -> build/lib.linux-x86_64-cpython-311/gptqmodel/integration/src/optimum/gptq\n",
      "  \u001b[31m   \u001b[0m copying gptqmodel/integration/src/optimum/gptq/quantizer.py -> build/lib.linux-x86_64-cpython-311/gptqmodel/integration/src/optimum/gptq\n",
      "  \u001b[31m   \u001b[0m copying gptqmodel/integration/src/optimum/gptq/utils.py -> build/lib.linux-x86_64-cpython-311/gptqmodel/integration/src/optimum/gptq\n",
      "  \u001b[31m   \u001b[0m creating build/lib.linux-x86_64-cpython-311/gptqmodel/integration/src/optimum/utils\n",
      "  \u001b[31m   \u001b[0m copying gptqmodel/integration/src/optimum/utils/__init__.py -> build/lib.linux-x86_64-cpython-311/gptqmodel/integration/src/optimum/utils\n",
      "  \u001b[31m   \u001b[0m copying gptqmodel/integration/src/optimum/utils/import_utils.py -> build/lib.linux-x86_64-cpython-311/gptqmodel/integration/src/optimum/utils\n",
      "  \u001b[31m   \u001b[0m copying gptqmodel/integration/src/optimum/utils/testing_utils.py -> build/lib.linux-x86_64-cpython-311/gptqmodel/integration/src/optimum/utils\n",
      "  \u001b[31m   \u001b[0m creating build/lib.linux-x86_64-cpython-311/gptqmodel/integration/src/peft/tuners\n",
      "  \u001b[31m   \u001b[0m copying gptqmodel/integration/src/peft/tuners/__init__.py -> build/lib.linux-x86_64-cpython-311/gptqmodel/integration/src/peft/tuners\n",
      "  \u001b[31m   \u001b[0m creating build/lib.linux-x86_64-cpython-311/gptqmodel/integration/src/peft/utils\n",
      "  \u001b[31m   \u001b[0m copying gptqmodel/integration/src/peft/utils/__init__.py -> build/lib.linux-x86_64-cpython-311/gptqmodel/integration/src/peft/utils\n",
      "  \u001b[31m   \u001b[0m copying gptqmodel/integration/src/peft/utils/other.py -> build/lib.linux-x86_64-cpython-311/gptqmodel/integration/src/peft/utils\n",
      "  \u001b[31m   \u001b[0m creating build/lib.linux-x86_64-cpython-311/gptqmodel/integration/src/peft/tuners/adalora\n",
      "  \u001b[31m   \u001b[0m copying gptqmodel/integration/src/peft/tuners/adalora/__init__.py -> build/lib.linux-x86_64-cpython-311/gptqmodel/integration/src/peft/tuners/adalora\n",
      "  \u001b[31m   \u001b[0m copying gptqmodel/integration/src/peft/tuners/adalora/model.py -> build/lib.linux-x86_64-cpython-311/gptqmodel/integration/src/peft/tuners/adalora\n",
      "  \u001b[31m   \u001b[0m creating build/lib.linux-x86_64-cpython-311/gptqmodel/integration/src/peft/tuners/lora\n",
      "  \u001b[31m   \u001b[0m copying gptqmodel/integration/src/peft/tuners/lora/__init__.py -> build/lib.linux-x86_64-cpython-311/gptqmodel/integration/src/peft/tuners/lora\n",
      "  \u001b[31m   \u001b[0m copying gptqmodel/integration/src/peft/tuners/lora/gptq.py -> build/lib.linux-x86_64-cpython-311/gptqmodel/integration/src/peft/tuners/lora\n",
      "  \u001b[31m   \u001b[0m copying gptqmodel/integration/src/peft/tuners/lora/model.py -> build/lib.linux-x86_64-cpython-311/gptqmodel/integration/src/peft/tuners/lora\n",
      "  \u001b[31m   \u001b[0m creating build/lib.linux-x86_64-cpython-311/gptqmodel/integration/src/transformers/quantizers\n",
      "  \u001b[31m   \u001b[0m copying gptqmodel/integration/src/transformers/quantizers/__init__.py -> build/lib.linux-x86_64-cpython-311/gptqmodel/integration/src/transformers/quantizers\n",
      "  \u001b[31m   \u001b[0m copying gptqmodel/integration/src/transformers/quantizers/quantizer_gptq.py -> build/lib.linux-x86_64-cpython-311/gptqmodel/integration/src/transformers/quantizers\n",
      "  \u001b[31m   \u001b[0m creating build/lib.linux-x86_64-cpython-311/gptqmodel/integration/src/transformers/utils\n",
      "  \u001b[31m   \u001b[0m copying gptqmodel/integration/src/transformers/utils/__init__.py -> build/lib.linux-x86_64-cpython-311/gptqmodel/integration/src/transformers/utils\n",
      "  \u001b[31m   \u001b[0m copying gptqmodel/integration/src/transformers/utils/import_utils.py -> build/lib.linux-x86_64-cpython-311/gptqmodel/integration/src/transformers/utils\n",
      "  \u001b[31m   \u001b[0m copying gptqmodel/integration/src/transformers/utils/quantization_config.py -> build/lib.linux-x86_64-cpython-311/gptqmodel/integration/src/transformers/utils\n",
      "  \u001b[31m   \u001b[0m creating build/lib.linux-x86_64-cpython-311/gptqmodel/models/definitions\n",
      "  \u001b[31m   \u001b[0m copying gptqmodel/models/definitions/__init__.py -> build/lib.linux-x86_64-cpython-311/gptqmodel/models/definitions\n",
      "  \u001b[31m   \u001b[0m copying gptqmodel/models/definitions/baichuan.py -> build/lib.linux-x86_64-cpython-311/gptqmodel/models/definitions\n",
      "  \u001b[31m   \u001b[0m copying gptqmodel/models/definitions/bloom.py -> build/lib.linux-x86_64-cpython-311/gptqmodel/models/definitions\n",
      "  \u001b[31m   \u001b[0m copying gptqmodel/models/definitions/chatglm.py -> build/lib.linux-x86_64-cpython-311/gptqmodel/models/definitions\n",
      "  \u001b[31m   \u001b[0m copying gptqmodel/models/definitions/codegen.py -> build/lib.linux-x86_64-cpython-311/gptqmodel/models/definitions\n",
      "  \u001b[31m   \u001b[0m copying gptqmodel/models/definitions/cohere.py -> build/lib.linux-x86_64-cpython-311/gptqmodel/models/definitions\n",
      "  \u001b[31m   \u001b[0m copying gptqmodel/models/definitions/cohere2.py -> build/lib.linux-x86_64-cpython-311/gptqmodel/models/definitions\n",
      "  \u001b[31m   \u001b[0m copying gptqmodel/models/definitions/dbrx.py -> build/lib.linux-x86_64-cpython-311/gptqmodel/models/definitions\n",
      "  \u001b[31m   \u001b[0m copying gptqmodel/models/definitions/dbrx_converted.py -> build/lib.linux-x86_64-cpython-311/gptqmodel/models/definitions\n",
      "  \u001b[31m   \u001b[0m copying gptqmodel/models/definitions/decilm.py -> build/lib.linux-x86_64-cpython-311/gptqmodel/models/definitions\n",
      "  \u001b[31m   \u001b[0m copying gptqmodel/models/definitions/deepseek_v2.py -> build/lib.linux-x86_64-cpython-311/gptqmodel/models/definitions\n",
      "  \u001b[31m   \u001b[0m copying gptqmodel/models/definitions/exaone.py -> build/lib.linux-x86_64-cpython-311/gptqmodel/models/definitions\n",
      "  \u001b[31m   \u001b[0m copying gptqmodel/models/definitions/gemma.py -> build/lib.linux-x86_64-cpython-311/gptqmodel/models/definitions\n",
      "  \u001b[31m   \u001b[0m copying gptqmodel/models/definitions/gemma2.py -> build/lib.linux-x86_64-cpython-311/gptqmodel/models/definitions\n",
      "  \u001b[31m   \u001b[0m copying gptqmodel/models/definitions/glm.py -> build/lib.linux-x86_64-cpython-311/gptqmodel/models/definitions\n",
      "  \u001b[31m   \u001b[0m copying gptqmodel/models/definitions/gpt2.py -> build/lib.linux-x86_64-cpython-311/gptqmodel/models/definitions\n",
      "  \u001b[31m   \u001b[0m copying gptqmodel/models/definitions/gpt_bigcode.py -> build/lib.linux-x86_64-cpython-311/gptqmodel/models/definitions\n",
      "  \u001b[31m   \u001b[0m copying gptqmodel/models/definitions/gpt_neox.py -> build/lib.linux-x86_64-cpython-311/gptqmodel/models/definitions\n",
      "  \u001b[31m   \u001b[0m copying gptqmodel/models/definitions/gptj.py -> build/lib.linux-x86_64-cpython-311/gptqmodel/models/definitions\n",
      "  \u001b[31m   \u001b[0m copying gptqmodel/models/definitions/granite.py -> build/lib.linux-x86_64-cpython-311/gptqmodel/models/definitions\n",
      "  \u001b[31m   \u001b[0m copying gptqmodel/models/definitions/grinmoe.py -> build/lib.linux-x86_64-cpython-311/gptqmodel/models/definitions\n",
      "  \u001b[31m   \u001b[0m copying gptqmodel/models/definitions/hymba.py -> build/lib.linux-x86_64-cpython-311/gptqmodel/models/definitions\n",
      "  \u001b[31m   \u001b[0m copying gptqmodel/models/definitions/internlm.py -> build/lib.linux-x86_64-cpython-311/gptqmodel/models/definitions\n",
      "  \u001b[31m   \u001b[0m copying gptqmodel/models/definitions/internlm2.py -> build/lib.linux-x86_64-cpython-311/gptqmodel/models/definitions\n",
      "  \u001b[31m   \u001b[0m copying gptqmodel/models/definitions/llama.py -> build/lib.linux-x86_64-cpython-311/gptqmodel/models/definitions\n",
      "  \u001b[31m   \u001b[0m copying gptqmodel/models/definitions/longllama.py -> build/lib.linux-x86_64-cpython-311/gptqmodel/models/definitions\n",
      "  \u001b[31m   \u001b[0m copying gptqmodel/models/definitions/minicpm.py -> build/lib.linux-x86_64-cpython-311/gptqmodel/models/definitions\n",
      "  \u001b[31m   \u001b[0m copying gptqmodel/models/definitions/minicpm3.py -> build/lib.linux-x86_64-cpython-311/gptqmodel/models/definitions\n",
      "  \u001b[31m   \u001b[0m copying gptqmodel/models/definitions/mistral.py -> build/lib.linux-x86_64-cpython-311/gptqmodel/models/definitions\n",
      "  \u001b[31m   \u001b[0m copying gptqmodel/models/definitions/mixtral.py -> build/lib.linux-x86_64-cpython-311/gptqmodel/models/definitions\n",
      "  \u001b[31m   \u001b[0m copying gptqmodel/models/definitions/mllama.py -> build/lib.linux-x86_64-cpython-311/gptqmodel/models/definitions\n",
      "  \u001b[31m   \u001b[0m copying gptqmodel/models/definitions/mobilellm.py -> build/lib.linux-x86_64-cpython-311/gptqmodel/models/definitions\n",
      "  \u001b[31m   \u001b[0m copying gptqmodel/models/definitions/moss.py -> build/lib.linux-x86_64-cpython-311/gptqmodel/models/definitions\n",
      "  \u001b[31m   \u001b[0m copying gptqmodel/models/definitions/mpt.py -> build/lib.linux-x86_64-cpython-311/gptqmodel/models/definitions\n",
      "  \u001b[31m   \u001b[0m copying gptqmodel/models/definitions/olmo2.py -> build/lib.linux-x86_64-cpython-311/gptqmodel/models/definitions\n",
      "  \u001b[31m   \u001b[0m copying gptqmodel/models/definitions/opt.py -> build/lib.linux-x86_64-cpython-311/gptqmodel/models/definitions\n",
      "  \u001b[31m   \u001b[0m copying gptqmodel/models/definitions/ovis.py -> build/lib.linux-x86_64-cpython-311/gptqmodel/models/definitions\n",
      "  \u001b[31m   \u001b[0m copying gptqmodel/models/definitions/phi.py -> build/lib.linux-x86_64-cpython-311/gptqmodel/models/definitions\n",
      "  \u001b[31m   \u001b[0m copying gptqmodel/models/definitions/phi3.py -> build/lib.linux-x86_64-cpython-311/gptqmodel/models/definitions\n",
      "  \u001b[31m   \u001b[0m copying gptqmodel/models/definitions/qwen.py -> build/lib.linux-x86_64-cpython-311/gptqmodel/models/definitions\n",
      "  \u001b[31m   \u001b[0m copying gptqmodel/models/definitions/qwen2.py -> build/lib.linux-x86_64-cpython-311/gptqmodel/models/definitions\n",
      "  \u001b[31m   \u001b[0m copying gptqmodel/models/definitions/qwen2_moe.py -> build/lib.linux-x86_64-cpython-311/gptqmodel/models/definitions\n",
      "  \u001b[31m   \u001b[0m copying gptqmodel/models/definitions/qwen2_vl.py -> build/lib.linux-x86_64-cpython-311/gptqmodel/models/definitions\n",
      "  \u001b[31m   \u001b[0m copying gptqmodel/models/definitions/rw.py -> build/lib.linux-x86_64-cpython-311/gptqmodel/models/definitions\n",
      "  \u001b[31m   \u001b[0m copying gptqmodel/models/definitions/stablelmepoch.py -> build/lib.linux-x86_64-cpython-311/gptqmodel/models/definitions\n",
      "  \u001b[31m   \u001b[0m copying gptqmodel/models/definitions/starcoder2.py -> build/lib.linux-x86_64-cpython-311/gptqmodel/models/definitions\n",
      "  \u001b[31m   \u001b[0m copying gptqmodel/models/definitions/telechat2.py -> build/lib.linux-x86_64-cpython-311/gptqmodel/models/definitions\n",
      "  \u001b[31m   \u001b[0m copying gptqmodel/models/definitions/xverse.py -> build/lib.linux-x86_64-cpython-311/gptqmodel/models/definitions\n",
      "  \u001b[31m   \u001b[0m copying gptqmodel/models/definitions/yi.py -> build/lib.linux-x86_64-cpython-311/gptqmodel/models/definitions\n",
      "  \u001b[31m   \u001b[0m creating build/lib.linux-x86_64-cpython-311/gptqmodel/nn_modules/qlinear\n",
      "  \u001b[31m   \u001b[0m copying gptqmodel/nn_modules/qlinear/__init__.py -> build/lib.linux-x86_64-cpython-311/gptqmodel/nn_modules/qlinear\n",
      "  \u001b[31m   \u001b[0m copying gptqmodel/nn_modules/qlinear/bitblas.py -> build/lib.linux-x86_64-cpython-311/gptqmodel/nn_modules/qlinear\n",
      "  \u001b[31m   \u001b[0m copying gptqmodel/nn_modules/qlinear/bitblas_target_detector.py -> build/lib.linux-x86_64-cpython-311/gptqmodel/nn_modules/qlinear\n",
      "  \u001b[31m   \u001b[0m copying gptqmodel/nn_modules/qlinear/dynamic_cuda.py -> build/lib.linux-x86_64-cpython-311/gptqmodel/nn_modules/qlinear\n",
      "  \u001b[31m   \u001b[0m copying gptqmodel/nn_modules/qlinear/exllama.py -> build/lib.linux-x86_64-cpython-311/gptqmodel/nn_modules/qlinear\n",
      "  \u001b[31m   \u001b[0m copying gptqmodel/nn_modules/qlinear/exllamav2.py -> build/lib.linux-x86_64-cpython-311/gptqmodel/nn_modules/qlinear\n",
      "  \u001b[31m   \u001b[0m copying gptqmodel/nn_modules/qlinear/ipex.py -> build/lib.linux-x86_64-cpython-311/gptqmodel/nn_modules/qlinear\n",
      "  \u001b[31m   \u001b[0m copying gptqmodel/nn_modules/qlinear/marlin.py -> build/lib.linux-x86_64-cpython-311/gptqmodel/nn_modules/qlinear\n",
      "  \u001b[31m   \u001b[0m copying gptqmodel/nn_modules/qlinear/torch.py -> build/lib.linux-x86_64-cpython-311/gptqmodel/nn_modules/qlinear\n",
      "  \u001b[31m   \u001b[0m copying gptqmodel/nn_modules/qlinear/tritonv2.py -> build/lib.linux-x86_64-cpython-311/gptqmodel/nn_modules/qlinear\n",
      "  \u001b[31m   \u001b[0m copying gptqmodel/nn_modules/qlinear/utils.py -> build/lib.linux-x86_64-cpython-311/gptqmodel/nn_modules/qlinear\n",
      "  \u001b[31m   \u001b[0m creating build/lib.linux-x86_64-cpython-311/gptqmodel/nn_modules/triton_utils\n",
      "  \u001b[31m   \u001b[0m copying gptqmodel/nn_modules/triton_utils/__init__.py -> build/lib.linux-x86_64-cpython-311/gptqmodel/nn_modules/triton_utils\n",
      "  \u001b[31m   \u001b[0m copying gptqmodel/nn_modules/triton_utils/custom_autotune.py -> build/lib.linux-x86_64-cpython-311/gptqmodel/nn_modules/triton_utils\n",
      "  \u001b[31m   \u001b[0m copying gptqmodel/nn_modules/triton_utils/dequant.py -> build/lib.linux-x86_64-cpython-311/gptqmodel/nn_modules/triton_utils\n",
      "  \u001b[31m   \u001b[0m copying gptqmodel/nn_modules/triton_utils/kernels.py -> build/lib.linux-x86_64-cpython-311/gptqmodel/nn_modules/triton_utils\n",
      "  \u001b[31m   \u001b[0m copying gptqmodel/nn_modules/triton_utils/mixin.py -> build/lib.linux-x86_64-cpython-311/gptqmodel/nn_modules/triton_utils\n",
      "  \u001b[31m   \u001b[0m running build_ext\n",
      "  \u001b[31m   \u001b[0m error: [Errno 2] No such file or directory: '/usr/local/cuda-12.4/bin/nvcc'\n",
      "  \u001b[31m   \u001b[0m \u001b[31m[end of output]\u001b[0m\n",
      "  \n",
      "  \u001b[1;35mnote\u001b[0m: This error originates from a subprocess, and is likely not a problem with pip.\n",
      "\u001b[31m  ERROR: Failed building wheel for gptqmodel\u001b[0m\u001b[31m\n",
      "\u001b[0m\u001b[?25h  Running setup.py clean for gptqmodel\n",
      "Failed to build gptqmodel\n",
      "\u001b[31mERROR: Could not build wheels for gptqmodel, which is required to install pyproject.toml-based projects\u001b[0m\u001b[31m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!pip install gptqmodel --no-build-isolation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9f92c15e-4b74-4a7a-b7d1-58b3781a5c94",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1.26.4'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy\n",
    "numpy.version.version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a61c4402-aee1-4e3b-bccc-875d22347824",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found existing installation: numpy 2.2.3\n",
      "Uninstalling numpy-2.2.3:\n",
      "  Successfully uninstalled numpy-2.2.3\n",
      "Collecting numpy==1.24.3\n",
      "  Using cached numpy-1.24.3-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (5.6 kB)\n",
      "Using cached numpy-1.24.3-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (17.3 MB)\n",
      "Installing collected packages: numpy\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "together 1.2.0 requires pillow<11.0.0,>=10.3.0, but you have pillow 11.1.0 which is incompatible.\n",
      "tensorflow 2.16.1 requires protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3, but you have protobuf 5.29.3 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0mSuccessfully installed numpy-1.24.3\n"
     ]
    }
   ],
   "source": [
    "!pip uninstall -y numpy\n",
    "!pip install numpy==1.24.3 # to work with multiarray module used in gptqmodel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9bca8321-434c-4309-9ebe-f596414dcf9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !export CUDA_HOME=/opt/conda && echo $CUDA_HOME\n",
    "# # !export CUDA_HOME=/home/jovyan/cuda-12.4 not working but right version\n",
    "# #!pip install gptqmodel\n",
    "# #!pip install lm-eval>=0.4.7\n",
    "# ## !pip install -v gptqmodel --no-build-isolation\n",
    "\n",
    "# # pip: compile and install\n",
    "# # You can install optional modules like autoround, ipex, vllm, sglang, bitblas, and ipex.\n",
    "# # Example: pip install -v --no-build-isolation .[vllm,sglang,bitblas,ipex,auto_round]\n",
    "\n",
    "# #in terminal:\n",
    "# cd GPTQModel\n",
    "# pip install -v . --no-build-isolation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "1d1b7bdd-43cc-4f97-b569-00b7da1657ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: gptqmodel[evalplus] in /opt/conda/lib/python3.11/site-packages (1.7.4+cu121torch2.3)\n",
      "\u001b[33mWARNING: gptqmodel 1.7.4+cu121torch2.3 does not provide the extra 'evalplus'\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!pip install gptqmodel[evalplus]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "16ef4960-9b87-4244-b174-bd619e8e99c8",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'gptqmodel'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[7], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m#!uv pip install -v gptqmodel --no-build-isolation\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mgptqmodel\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m GPTQModel\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mgptqmodel\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01meval\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m EVAL\n\u001b[1;32m      5\u001b[0m \u001b[38;5;66;03m# model_id = \"ModelCloud/Llama-3.2-1B-Instruct-gptqmodel-4bit-vortex-v1\"\u001b[39;00m\n\u001b[1;32m      6\u001b[0m \n\u001b[1;32m      7\u001b[0m \u001b[38;5;66;03m# # Use `lm-eval` as framework to evaluate the model\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[38;5;66;03m# # Use `evalplus` as framework to evaluate the model\u001b[39;00m\n\u001b[1;32m     11\u001b[0m \u001b[38;5;66;03m# evalplus_results = GPTQModel.eval(model_id, framework=EVAL.EVALPLUS, tasks=[EVAL.EVALPLUS.HUMAN], output_file='evalplus_result.json')\u001b[39;00m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'gptqmodel'"
     ]
    }
   ],
   "source": [
    "#!uv pip install -v gptqmodel --no-build-isolation\n",
    "from gptqmodel import GPTQModel\n",
    "from gptqmodel.utils.eval import EVAL\n",
    "\n",
    "# model_id = \"ModelCloud/Llama-3.2-1B-Instruct-gptqmodel-4bit-vortex-v1\"\n",
    "\n",
    "# # Use `lm-eval` as framework to evaluate the model\n",
    "# lm_eval_results = GPTQModel.eval(model_id, framework=EVAL.LM_EVAL, tasks=[EVAL.LM_EVAL.ARC_CHALLENGE], output_file='lm-eval_result.json')\n",
    "\n",
    "# # Use `evalplus` as framework to evaluate the model\n",
    "# evalplus_results = GPTQModel.eval(model_id, framework=EVAL.EVALPLUS, tasks=[EVAL.EVALPLUS.HUMAN], output_file='evalplus_result.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ca5881e6-4010-439c-8e6b-50b7abf49c72",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1039.17s - pydevd: Sending message related to process being replaced timed-out after 5 seconds\n",
      "Collecting git+https://github.com/EleutherAI/lm-evaluation-harness.git (from -r FortiQAGPTQrequirements.txt (line 1))\n",
      "  Cloning https://github.com/EleutherAI/lm-evaluation-harness.git to /tmp/pip-req-build-87usys_i\n",
      "  Running command git clone --filter=blob:none --quiet https://github.com/EleutherAI/lm-evaluation-harness.git /tmp/pip-req-build-87usys_i\n",
      "  Resolved https://github.com/EleutherAI/lm-evaluation-harness.git to commit 5e0b6f16cc5121eb889d73ed3c7418def096c3f9\n",
      "  Installing build dependencies ... \u001b[?25ldone\n",
      "\u001b[?25h  Getting requirements to build wheel ... \u001b[?25ldone\n",
      "\u001b[?25h  Preparing metadata (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25hRequirement already satisfied: huggingface_hub==0.29.1 in /opt/conda/lib/python3.11/site-packages (from -r FortiQAGPTQrequirements.txt (line 2)) (0.29.1)\n",
      "Requirement already satisfied: datasets==3.3.2 in /opt/conda/lib/python3.11/site-packages (from -r FortiQAGPTQrequirements.txt (line 3)) (3.3.2)\n",
      "Requirement already satisfied: numpy==1.24.3 in /opt/conda/lib/python3.11/site-packages (from -r FortiQAGPTQrequirements.txt (line 4)) (1.24.3)\n",
      "Collecting beautifulsoup4==4.10.0 (from -r FortiQAGPTQrequirements.txt (line 6))\n",
      "  Using cached beautifulsoup4-4.10.0-py3-none-any.whl.metadata (3.5 kB)\n",
      "Collecting evaluate==0.4.0 (from -r FortiQAGPTQrequirements.txt (line 7))\n",
      "  Using cached evaluate-0.4.0-py3-none-any.whl.metadata (9.4 kB)\n",
      "Collecting langchain==0.3.7 (from -r FortiQAGPTQrequirements.txt (line 8))\n",
      "  Using cached langchain-0.3.7-py3-none-any.whl.metadata (7.1 kB)\n",
      "Collecting langchain-community==0.3.4 (from -r FortiQAGPTQrequirements.txt (line 9))\n",
      "  Using cached langchain_community-0.3.4-py3-none-any.whl.metadata (2.9 kB)\n",
      "Collecting langchain-core==0.3.15 (from -r FortiQAGPTQrequirements.txt (line 10))\n",
      "  Using cached langchain_core-0.3.15-py3-none-any.whl.metadata (6.3 kB)\n",
      "Collecting langchain-huggingface==0.1.0 (from -r FortiQAGPTQrequirements.txt (line 11))\n",
      "  Using cached langchain_huggingface-0.1.0-py3-none-any.whl.metadata (1.3 kB)\n",
      "Collecting langchain-openai==0.2.4 (from -r FortiQAGPTQrequirements.txt (line 12))\n",
      "  Using cached langchain_openai-0.2.4-py3-none-any.whl.metadata (2.6 kB)\n",
      "Collecting markdown==3.4.4 (from -r FortiQAGPTQrequirements.txt (line 13))\n",
      "  Using cached Markdown-3.4.4-py3-none-any.whl.metadata (6.9 kB)\n",
      "Collecting mitreattack-python==2.0.14 (from -r FortiQAGPTQrequirements.txt (line 14))\n",
      "  Using cached mitreattack_python-2.0.14-py3-none-any.whl.metadata (7.0 kB)\n",
      "Collecting nltk==3.9 (from -r FortiQAGPTQrequirements.txt (line 15))\n",
      "  Using cached nltk-3.9-py3-none-any.whl.metadata (2.9 kB)\n",
      "Collecting openai==1.54.1 (from -r FortiQAGPTQrequirements.txt (line 17))\n",
      "  Using cached openai-1.54.1-py3-none-any.whl.metadata (24 kB)\n",
      "Collecting pandas==1.4.1 (from -r FortiQAGPTQrequirements.txt (line 18))\n",
      "  Using cached pandas-1.4.1-cp311-cp311-linux_x86_64.whl\n",
      "Collecting peft==0.4.0 (from -r FortiQAGPTQrequirements.txt (line 19))\n",
      "  Using cached peft-0.4.0-py3-none-any.whl.metadata (21 kB)\n",
      "Requirement already satisfied: scikit-learn==1.5.0 in /opt/conda/lib/python3.11/site-packages (from -r FortiQAGPTQrequirements.txt (line 20)) (1.5.0)\n",
      "Collecting sentence-transformers==3.1.1 (from -r FortiQAGPTQrequirements.txt (line 21))\n",
      "  Using cached sentence_transformers-3.1.1-py3-none-any.whl.metadata (10 kB)\n",
      "Collecting tokenizers==0.20.2 (from -r FortiQAGPTQrequirements.txt (line 22))\n",
      "  Using cached tokenizers-0.20.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.7 kB)\n",
      "Collecting torch==2.2.0 (from -r FortiQAGPTQrequirements.txt (line 23))\n",
      "  Using cached torch-2.2.0-cp311-cp311-manylinux1_x86_64.whl.metadata (25 kB)\n",
      "Collecting tqdm==4.66.3 (from -r FortiQAGPTQrequirements.txt (line 24))\n",
      "  Using cached tqdm-4.66.3-py3-none-any.whl.metadata (57 kB)\n",
      "Collecting transformers==4.45.2 (from -r FortiQAGPTQrequirements.txt (line 25))\n",
      "  Using cached transformers-4.45.2-py3-none-any.whl.metadata (44 kB)\n",
      "Requirement already satisfied: filelock in /opt/conda/lib/python3.11/site-packages (from huggingface_hub==0.29.1->-r FortiQAGPTQrequirements.txt (line 2)) (3.13.1)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /opt/conda/lib/python3.11/site-packages (from huggingface_hub==0.29.1->-r FortiQAGPTQrequirements.txt (line 2)) (2024.5.0)\n",
      "Requirement already satisfied: packaging>=20.9 in /opt/conda/lib/python3.11/site-packages (from huggingface_hub==0.29.1->-r FortiQAGPTQrequirements.txt (line 2)) (23.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.11/site-packages (from huggingface_hub==0.29.1->-r FortiQAGPTQrequirements.txt (line 2)) (6.0.1)\n",
      "Requirement already satisfied: requests in /opt/conda/lib/python3.11/site-packages (from huggingface_hub==0.29.1->-r FortiQAGPTQrequirements.txt (line 2)) (2.32.3)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.11/site-packages (from huggingface_hub==0.29.1->-r FortiQAGPTQrequirements.txt (line 2)) (4.11.0)\n",
      "Requirement already satisfied: pyarrow>=15.0.0 in /opt/conda/lib/python3.11/site-packages (from datasets==3.3.2->-r FortiQAGPTQrequirements.txt (line 3)) (16.1.0)\n",
      "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /opt/conda/lib/python3.11/site-packages (from datasets==3.3.2->-r FortiQAGPTQrequirements.txt (line 3)) (0.3.8)\n",
      "Requirement already satisfied: xxhash in /opt/conda/lib/python3.11/site-packages (from datasets==3.3.2->-r FortiQAGPTQrequirements.txt (line 3)) (3.5.0)\n",
      "Requirement already satisfied: multiprocess<0.70.17 in /opt/conda/lib/python3.11/site-packages (from datasets==3.3.2->-r FortiQAGPTQrequirements.txt (line 3)) (0.70.16)\n",
      "Requirement already satisfied: aiohttp in /opt/conda/lib/python3.11/site-packages (from datasets==3.3.2->-r FortiQAGPTQrequirements.txt (line 3)) (3.9.5)\n",
      "Requirement already satisfied: soupsieve>1.2 in /opt/conda/lib/python3.11/site-packages (from beautifulsoup4==4.10.0->-r FortiQAGPTQrequirements.txt (line 6)) (2.5)\n",
      "Collecting responses<0.19 (from evaluate==0.4.0->-r FortiQAGPTQrequirements.txt (line 7))\n",
      "  Using cached responses-0.18.0-py3-none-any.whl.metadata (29 kB)\n",
      "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /opt/conda/lib/python3.11/site-packages (from langchain==0.3.7->-r FortiQAGPTQrequirements.txt (line 8)) (2.0.30)\n",
      "Collecting langchain-text-splitters<0.4.0,>=0.3.0 (from langchain==0.3.7->-r FortiQAGPTQrequirements.txt (line 8))\n",
      "  Using cached langchain_text_splitters-0.3.6-py3-none-any.whl.metadata (1.9 kB)\n",
      "Requirement already satisfied: langsmith<0.2.0,>=0.1.17 in /opt/conda/lib/python3.11/site-packages (from langchain==0.3.7->-r FortiQAGPTQrequirements.txt (line 8)) (0.1.65)\n",
      "Collecting pydantic<3.0.0,>=2.7.4 (from langchain==0.3.7->-r FortiQAGPTQrequirements.txt (line 8))\n",
      "  Using cached pydantic-2.10.6-py3-none-any.whl.metadata (30 kB)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<10,>=8.1.0 in /opt/conda/lib/python3.11/site-packages (from langchain==0.3.7->-r FortiQAGPTQrequirements.txt (line 8)) (8.3.0)\n",
      "Requirement already satisfied: dataclasses-json<0.7,>=0.5.7 in /opt/conda/lib/python3.11/site-packages (from langchain-community==0.3.4->-r FortiQAGPTQrequirements.txt (line 9)) (0.6.6)\n",
      "Collecting httpx-sse<0.5.0,>=0.4.0 (from langchain-community==0.3.4->-r FortiQAGPTQrequirements.txt (line 9))\n",
      "  Using cached httpx_sse-0.4.0-py3-none-any.whl.metadata (9.0 kB)\n",
      "Collecting langsmith<0.2.0,>=0.1.17 (from langchain==0.3.7->-r FortiQAGPTQrequirements.txt (line 8))\n",
      "  Using cached langsmith-0.1.147-py3-none-any.whl.metadata (14 kB)\n",
      "Collecting pydantic-settings<3.0.0,>=2.4.0 (from langchain-community==0.3.4->-r FortiQAGPTQrequirements.txt (line 9))\n",
      "  Downloading pydantic_settings-2.8.0-py3-none-any.whl.metadata (3.5 kB)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /opt/conda/lib/python3.11/site-packages (from langchain-core==0.3.15->-r FortiQAGPTQrequirements.txt (line 10)) (1.33)\n",
      "Requirement already satisfied: tiktoken<1,>=0.7 in /opt/conda/lib/python3.11/site-packages (from langchain-openai==0.2.4->-r FortiQAGPTQrequirements.txt (line 12)) (0.7.0)\n",
      "Collecting colour (from mitreattack-python==2.0.14->-r FortiQAGPTQrequirements.txt (line 14))\n",
      "  Using cached colour-0.1.5-py2.py3-none-any.whl.metadata (18 kB)\n",
      "Collecting deepdiff (from mitreattack-python==2.0.14->-r FortiQAGPTQrequirements.txt (line 14))\n",
      "  Using cached deepdiff-8.2.0-py3-none-any.whl.metadata (6.3 kB)\n",
      "Collecting drawsvg>=2.0.0 (from mitreattack-python==2.0.14->-r FortiQAGPTQrequirements.txt (line 14))\n",
      "  Using cached drawsvg-2.4.0-py3-none-any.whl.metadata (19 kB)\n",
      "Collecting loguru (from mitreattack-python==2.0.14->-r FortiQAGPTQrequirements.txt (line 14))\n",
      "  Using cached loguru-0.7.3-py3-none-any.whl.metadata (22 kB)\n",
      "Requirement already satisfied: openpyxl in /opt/conda/lib/python3.11/site-packages (from mitreattack-python==2.0.14->-r FortiQAGPTQrequirements.txt (line 14)) (3.1.2)\n",
      "Collecting pooch (from mitreattack-python==2.0.14->-r FortiQAGPTQrequirements.txt (line 14))\n",
      "  Using cached pooch-1.8.2-py3-none-any.whl.metadata (10 kB)\n",
      "Requirement already satisfied: python-dateutil in /opt/conda/lib/python3.11/site-packages (from mitreattack-python==2.0.14->-r FortiQAGPTQrequirements.txt (line 14)) (2.9.0)\n",
      "Requirement already satisfied: Pillow in /opt/conda/lib/python3.11/site-packages (from mitreattack-python==2.0.14->-r FortiQAGPTQrequirements.txt (line 14)) (10.3.0)\n",
      "Requirement already satisfied: rich in /opt/conda/lib/python3.11/site-packages (from mitreattack-python==2.0.14->-r FortiQAGPTQrequirements.txt (line 14)) (13.7.1)\n",
      "Collecting stix2 (from mitreattack-python==2.0.14->-r FortiQAGPTQrequirements.txt (line 14))\n",
      "  Using cached stix2-3.0.1-py2.py3-none-any.whl.metadata (10 kB)\n",
      "Collecting stix2-elevator (from mitreattack-python==2.0.14->-r FortiQAGPTQrequirements.txt (line 14))\n",
      "  Using cached stix2_elevator-4.1.7-py2.py3-none-any.whl.metadata (17 kB)\n",
      "Requirement already satisfied: tabulate in /opt/conda/lib/python3.11/site-packages (from mitreattack-python==2.0.14->-r FortiQAGPTQrequirements.txt (line 14)) (0.9.0)\n",
      "Collecting taxii2-client (from mitreattack-python==2.0.14->-r FortiQAGPTQrequirements.txt (line 14))\n",
      "  Using cached taxii2_client-2.3.0-py2.py3-none-any.whl.metadata (11 kB)\n",
      "Requirement already satisfied: typer in /opt/conda/lib/python3.11/site-packages (from mitreattack-python==2.0.14->-r FortiQAGPTQrequirements.txt (line 14)) (0.9.4)\n",
      "Collecting xlsxwriter (from mitreattack-python==2.0.14->-r FortiQAGPTQrequirements.txt (line 14))\n",
      "  Using cached XlsxWriter-3.2.2-py3-none-any.whl.metadata (2.8 kB)\n",
      "Requirement already satisfied: click in /opt/conda/lib/python3.11/site-packages (from nltk==3.9->-r FortiQAGPTQrequirements.txt (line 15)) (8.1.7)\n",
      "Requirement already satisfied: joblib in /opt/conda/lib/python3.11/site-packages (from nltk==3.9->-r FortiQAGPTQrequirements.txt (line 15)) (1.4.2)\n",
      "Requirement already satisfied: regex>=2021.8.3 in /opt/conda/lib/python3.11/site-packages (from nltk==3.9->-r FortiQAGPTQrequirements.txt (line 15)) (2024.5.15)\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in /opt/conda/lib/python3.11/site-packages (from openai==1.54.1->-r FortiQAGPTQrequirements.txt (line 17)) (4.3.0)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in /opt/conda/lib/python3.11/site-packages (from openai==1.54.1->-r FortiQAGPTQrequirements.txt (line 17)) (1.9.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in /opt/conda/lib/python3.11/site-packages (from openai==1.54.1->-r FortiQAGPTQrequirements.txt (line 17)) (0.27.0)\n",
      "Requirement already satisfied: jiter<1,>=0.4.0 in /opt/conda/lib/python3.11/site-packages (from openai==1.54.1->-r FortiQAGPTQrequirements.txt (line 17)) (0.4.0)\n",
      "Requirement already satisfied: sniffio in /opt/conda/lib/python3.11/site-packages (from openai==1.54.1->-r FortiQAGPTQrequirements.txt (line 17)) (1.3.1)\n",
      "Requirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.11/site-packages (from pandas==1.4.1->-r FortiQAGPTQrequirements.txt (line 18)) (2024.1)\n",
      "Requirement already satisfied: psutil in /opt/conda/lib/python3.11/site-packages (from peft==0.4.0->-r FortiQAGPTQrequirements.txt (line 19)) (5.9.8)\n",
      "Requirement already satisfied: accelerate in /opt/conda/lib/python3.11/site-packages (from peft==0.4.0->-r FortiQAGPTQrequirements.txt (line 19)) (1.4.0)\n",
      "Requirement already satisfied: safetensors in /opt/conda/lib/python3.11/site-packages (from peft==0.4.0->-r FortiQAGPTQrequirements.txt (line 19)) (0.5.2)\n",
      "Requirement already satisfied: scipy>=1.6.0 in /opt/conda/lib/python3.11/site-packages (from scikit-learn==1.5.0->-r FortiQAGPTQrequirements.txt (line 20)) (1.13.1)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in /opt/conda/lib/python3.11/site-packages (from scikit-learn==1.5.0->-r FortiQAGPTQrequirements.txt (line 20)) (3.5.0)\n",
      "Requirement already satisfied: sympy in /opt/conda/lib/python3.11/site-packages (from torch==2.2.0->-r FortiQAGPTQrequirements.txt (line 23)) (1.12)\n",
      "Requirement already satisfied: networkx in /opt/conda/lib/python3.11/site-packages (from torch==2.2.0->-r FortiQAGPTQrequirements.txt (line 23)) (3.3)\n",
      "Requirement already satisfied: jinja2 in /opt/conda/lib/python3.11/site-packages (from torch==2.2.0->-r FortiQAGPTQrequirements.txt (line 23)) (3.1.4)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /opt/conda/lib/python3.11/site-packages (from torch==2.2.0->-r FortiQAGPTQrequirements.txt (line 23)) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /opt/conda/lib/python3.11/site-packages (from torch==2.2.0->-r FortiQAGPTQrequirements.txt (line 23)) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /opt/conda/lib/python3.11/site-packages (from torch==2.2.0->-r FortiQAGPTQrequirements.txt (line 23)) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /opt/conda/lib/python3.11/site-packages (from torch==2.2.0->-r FortiQAGPTQrequirements.txt (line 23)) (8.9.2.26)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /opt/conda/lib/python3.11/site-packages (from torch==2.2.0->-r FortiQAGPTQrequirements.txt (line 23)) (12.1.3.1)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /opt/conda/lib/python3.11/site-packages (from torch==2.2.0->-r FortiQAGPTQrequirements.txt (line 23)) (11.0.2.54)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /opt/conda/lib/python3.11/site-packages (from torch==2.2.0->-r FortiQAGPTQrequirements.txt (line 23)) (10.3.2.106)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /opt/conda/lib/python3.11/site-packages (from torch==2.2.0->-r FortiQAGPTQrequirements.txt (line 23)) (11.4.5.107)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /opt/conda/lib/python3.11/site-packages (from torch==2.2.0->-r FortiQAGPTQrequirements.txt (line 23)) (12.1.0.106)\n",
      "Collecting nvidia-nccl-cu12==2.19.3 (from torch==2.2.0->-r FortiQAGPTQrequirements.txt (line 23))\n",
      "  Using cached nvidia_nccl_cu12-2.19.3-py3-none-manylinux1_x86_64.whl.metadata (1.8 kB)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /opt/conda/lib/python3.11/site-packages (from torch==2.2.0->-r FortiQAGPTQrequirements.txt (line 23)) (12.1.105)\n",
      "Collecting triton==2.2.0 (from torch==2.2.0->-r FortiQAGPTQrequirements.txt (line 23))\n",
      "  Using cached triton-2.2.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (1.4 kB)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12 in /opt/conda/lib/python3.11/site-packages (from nvidia-cusolver-cu12==11.4.5.107->torch==2.2.0->-r FortiQAGPTQrequirements.txt (line 23)) (12.3.101)\n",
      "Requirement already satisfied: jsonlines in /opt/conda/lib/python3.11/site-packages (from lm_eval==0.4.7->-r FortiQAGPTQrequirements.txt (line 1)) (4.0.0)\n",
      "Requirement already satisfied: numexpr in /opt/conda/lib/python3.11/site-packages (from lm_eval==0.4.7->-r FortiQAGPTQrequirements.txt (line 1)) (2.9.0)\n",
      "Requirement already satisfied: pybind11>=2.6.2 in /opt/conda/lib/python3.11/site-packages (from lm_eval==0.4.7->-r FortiQAGPTQrequirements.txt (line 1)) (2.13.6)\n",
      "Requirement already satisfied: pytablewriter in /opt/conda/lib/python3.11/site-packages (from lm_eval==0.4.7->-r FortiQAGPTQrequirements.txt (line 1)) (1.2.1)\n",
      "Requirement already satisfied: rouge-score>=0.0.4 in /opt/conda/lib/python3.11/site-packages (from lm_eval==0.4.7->-r FortiQAGPTQrequirements.txt (line 1)) (0.1.2)\n",
      "Requirement already satisfied: sacrebleu>=1.5.0 in /opt/conda/lib/python3.11/site-packages (from lm_eval==0.4.7->-r FortiQAGPTQrequirements.txt (line 1)) (2.5.1)\n",
      "Requirement already satisfied: sqlitedict in /opt/conda/lib/python3.11/site-packages (from lm_eval==0.4.7->-r FortiQAGPTQrequirements.txt (line 1)) (2.1.0)\n",
      "Requirement already satisfied: tqdm-multiprocess in /opt/conda/lib/python3.11/site-packages (from lm_eval==0.4.7->-r FortiQAGPTQrequirements.txt (line 1)) (0.0.11)\n",
      "Requirement already satisfied: zstandard in /opt/conda/lib/python3.11/site-packages (from lm_eval==0.4.7->-r FortiQAGPTQrequirements.txt (line 1)) (0.19.0)\n",
      "Requirement already satisfied: word2number in /opt/conda/lib/python3.11/site-packages (from lm_eval==0.4.7->-r FortiQAGPTQrequirements.txt (line 1)) (1.1)\n",
      "Requirement already satisfied: more_itertools in /opt/conda/lib/python3.11/site-packages (from lm_eval==0.4.7->-r FortiQAGPTQrequirements.txt (line 1)) (10.6.0)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /opt/conda/lib/python3.11/site-packages (from aiohttp->datasets==3.3.2->-r FortiQAGPTQrequirements.txt (line 3)) (1.3.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /opt/conda/lib/python3.11/site-packages (from aiohttp->datasets==3.3.2->-r FortiQAGPTQrequirements.txt (line 3)) (23.2.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /opt/conda/lib/python3.11/site-packages (from aiohttp->datasets==3.3.2->-r FortiQAGPTQrequirements.txt (line 3)) (1.4.1)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /opt/conda/lib/python3.11/site-packages (from aiohttp->datasets==3.3.2->-r FortiQAGPTQrequirements.txt (line 3)) (6.0.5)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /opt/conda/lib/python3.11/site-packages (from aiohttp->datasets==3.3.2->-r FortiQAGPTQrequirements.txt (line 3)) (1.9.4)\n",
      "Requirement already satisfied: idna>=2.8 in /opt/conda/lib/python3.11/site-packages (from anyio<5,>=3.5.0->openai==1.54.1->-r FortiQAGPTQrequirements.txt (line 17)) (3.7)\n",
      "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /opt/conda/lib/python3.11/site-packages (from dataclasses-json<0.7,>=0.5.7->langchain-community==0.3.4->-r FortiQAGPTQrequirements.txt (line 9)) (3.21.2)\n",
      "Requirement already satisfied: typing-inspect<1,>=0.4.0 in /opt/conda/lib/python3.11/site-packages (from dataclasses-json<0.7,>=0.5.7->langchain-community==0.3.4->-r FortiQAGPTQrequirements.txt (line 9)) (0.9.0)\n",
      "Requirement already satisfied: certifi in /opt/conda/lib/python3.11/site-packages (from httpx<1,>=0.23.0->openai==1.54.1->-r FortiQAGPTQrequirements.txt (line 17)) (2024.2.2)\n",
      "Requirement already satisfied: httpcore==1.* in /opt/conda/lib/python3.11/site-packages (from httpx<1,>=0.23.0->openai==1.54.1->-r FortiQAGPTQrequirements.txt (line 17)) (1.0.5)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in /opt/conda/lib/python3.11/site-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai==1.54.1->-r FortiQAGPTQrequirements.txt (line 17)) (0.14.0)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in /opt/conda/lib/python3.11/site-packages (from jsonpatch<2.0,>=1.33->langchain-core==0.3.15->-r FortiQAGPTQrequirements.txt (line 10)) (2.4)\n",
      "INFO: pip is looking at multiple versions of langchain-text-splitters to determine which version is compatible with other requirements. This could take a while.\n",
      "Collecting langchain-text-splitters<0.4.0,>=0.3.0 (from langchain==0.3.7->-r FortiQAGPTQrequirements.txt (line 8))\n",
      "  Using cached langchain_text_splitters-0.3.5-py3-none-any.whl.metadata (2.3 kB)\n",
      "  Using cached langchain_text_splitters-0.3.4-py3-none-any.whl.metadata (2.3 kB)\n",
      "  Using cached langchain_text_splitters-0.3.3-py3-none-any.whl.metadata (2.3 kB)\n",
      "  Using cached langchain_text_splitters-0.3.2-py3-none-any.whl.metadata (2.3 kB)\n",
      "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /opt/conda/lib/python3.11/site-packages (from langsmith<0.2.0,>=0.1.17->langchain==0.3.7->-r FortiQAGPTQrequirements.txt (line 8)) (3.10.3)\n",
      "Collecting requests-toolbelt<2.0.0,>=1.0.0 (from langsmith<0.2.0,>=0.1.17->langchain==0.3.7->-r FortiQAGPTQrequirements.txt (line 8))\n",
      "  Using cached requests_toolbelt-1.0.0-py2.py3-none-any.whl.metadata (14 kB)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /opt/conda/lib/python3.11/site-packages (from pydantic<3.0.0,>=2.7.4->langchain==0.3.7->-r FortiQAGPTQrequirements.txt (line 8)) (0.7.0)\n",
      "Collecting pydantic-core==2.27.2 (from pydantic<3.0.0,>=2.7.4->langchain==0.3.7->-r FortiQAGPTQrequirements.txt (line 8))\n",
      "  Using cached pydantic_core-2.27.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.6 kB)\n",
      "Collecting typing-extensions>=3.7.4.3 (from huggingface_hub==0.29.1->-r FortiQAGPTQrequirements.txt (line 2))\n",
      "  Using cached typing_extensions-4.12.2-py3-none-any.whl.metadata (3.0 kB)\n",
      "Requirement already satisfied: python-dotenv>=0.21.0 in /opt/conda/lib/python3.11/site-packages (from pydantic-settings<3.0.0,>=2.4.0->langchain-community==0.3.4->-r FortiQAGPTQrequirements.txt (line 9)) (1.0.1)\n",
      "Requirement already satisfied: six>=1.5 in /opt/conda/lib/python3.11/site-packages (from python-dateutil->mitreattack-python==2.0.14->-r FortiQAGPTQrequirements.txt (line 14)) (1.16.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.11/site-packages (from requests->huggingface_hub==0.29.1->-r FortiQAGPTQrequirements.txt (line 2)) (3.3.2)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.11/site-packages (from requests->huggingface_hub==0.29.1->-r FortiQAGPTQrequirements.txt (line 2)) (2.2.1)\n",
      "Requirement already satisfied: absl-py in /opt/conda/lib/python3.11/site-packages (from rouge-score>=0.0.4->lm_eval==0.4.7->-r FortiQAGPTQrequirements.txt (line 1)) (2.1.0)\n",
      "Requirement already satisfied: portalocker in /opt/conda/lib/python3.11/site-packages (from sacrebleu>=1.5.0->lm_eval==0.4.7->-r FortiQAGPTQrequirements.txt (line 1)) (3.1.1)\n",
      "Requirement already satisfied: colorama in /opt/conda/lib/python3.11/site-packages (from sacrebleu>=1.5.0->lm_eval==0.4.7->-r FortiQAGPTQrequirements.txt (line 1)) (0.4.6)\n",
      "Requirement already satisfied: lxml in /opt/conda/lib/python3.11/site-packages (from sacrebleu>=1.5.0->lm_eval==0.4.7->-r FortiQAGPTQrequirements.txt (line 1)) (5.3.1)\n",
      "Requirement already satisfied: greenlet!=0.4.17 in /opt/conda/lib/python3.11/site-packages (from SQLAlchemy<3,>=1.4->langchain==0.3.7->-r FortiQAGPTQrequirements.txt (line 8)) (3.0.3)\n",
      "Collecting orderly-set<6,>=5.3.0 (from deepdiff->mitreattack-python==2.0.14->-r FortiQAGPTQrequirements.txt (line 14))\n",
      "  Using cached orderly_set-5.3.0-py3-none-any.whl.metadata (6.2 kB)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.11/site-packages (from jinja2->torch==2.2.0->-r FortiQAGPTQrequirements.txt (line 23)) (2.1.5)\n",
      "Requirement already satisfied: et-xmlfile in /opt/conda/lib/python3.11/site-packages (from openpyxl->mitreattack-python==2.0.14->-r FortiQAGPTQrequirements.txt (line 14)) (1.1.0)\n",
      "Requirement already satisfied: platformdirs>=2.5.0 in /opt/conda/lib/python3.11/site-packages (from pooch->mitreattack-python==2.0.14->-r FortiQAGPTQrequirements.txt (line 14)) (4.2.2)\n",
      "Requirement already satisfied: setuptools>=38.3.0 in /opt/conda/lib/python3.11/site-packages (from pytablewriter->lm_eval==0.4.7->-r FortiQAGPTQrequirements.txt (line 1)) (70.0.0)\n",
      "Requirement already satisfied: DataProperty<2,>=1.1.0 in /opt/conda/lib/python3.11/site-packages (from pytablewriter->lm_eval==0.4.7->-r FortiQAGPTQrequirements.txt (line 1)) (1.1.0)\n",
      "Requirement already satisfied: mbstrdecoder<2,>=1.0.0 in /opt/conda/lib/python3.11/site-packages (from pytablewriter->lm_eval==0.4.7->-r FortiQAGPTQrequirements.txt (line 1)) (1.1.4)\n",
      "Requirement already satisfied: pathvalidate<4,>=2.3.0 in /opt/conda/lib/python3.11/site-packages (from pytablewriter->lm_eval==0.4.7->-r FortiQAGPTQrequirements.txt (line 1)) (3.2.3)\n",
      "Requirement already satisfied: tabledata<2,>=1.3.1 in /opt/conda/lib/python3.11/site-packages (from pytablewriter->lm_eval==0.4.7->-r FortiQAGPTQrequirements.txt (line 1)) (1.3.4)\n",
      "Requirement already satisfied: tcolorpy<1,>=0.0.5 in /opt/conda/lib/python3.11/site-packages (from pytablewriter->lm_eval==0.4.7->-r FortiQAGPTQrequirements.txt (line 1)) (0.1.7)\n",
      "Requirement already satisfied: typepy<2,>=1.3.2 in /opt/conda/lib/python3.11/site-packages (from typepy[datetime]<2,>=1.3.2->pytablewriter->lm_eval==0.4.7->-r FortiQAGPTQrequirements.txt (line 1)) (1.3.4)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in /opt/conda/lib/python3.11/site-packages (from rich->mitreattack-python==2.0.14->-r FortiQAGPTQrequirements.txt (line 14)) (3.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /opt/conda/lib/python3.11/site-packages (from rich->mitreattack-python==2.0.14->-r FortiQAGPTQrequirements.txt (line 14)) (2.18.0)\n",
      "Collecting simplejson (from stix2->mitreattack-python==2.0.14->-r FortiQAGPTQrequirements.txt (line 14))\n",
      "  Downloading simplejson-3.20.1-cp311-cp311-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.2 kB)\n",
      "Collecting stix2-patterns>=1.2.0 (from stix2->mitreattack-python==2.0.14->-r FortiQAGPTQrequirements.txt (line 14))\n",
      "  Using cached stix2_patterns-2.0.0-py2.py3-none-any.whl.metadata (8.3 kB)\n",
      "Collecting maec (from stix2-elevator->mitreattack-python==2.0.14->-r FortiQAGPTQrequirements.txt (line 14))\n",
      "  Using cached maec-4.1.0.17-py2.py3-none-any.whl.metadata (5.8 kB)\n",
      "Collecting netaddr (from stix2-elevator->mitreattack-python==2.0.14->-r FortiQAGPTQrequirements.txt (line 14))\n",
      "  Using cached netaddr-1.3.0-py3-none-any.whl.metadata (5.0 kB)\n",
      "Collecting pycountry>=20.7.0 (from stix2-elevator->mitreattack-python==2.0.14->-r FortiQAGPTQrequirements.txt (line 14))\n",
      "  Using cached pycountry-24.6.1-py3-none-any.whl.metadata (12 kB)\n",
      "Collecting pluralizer (from stix2-elevator->mitreattack-python==2.0.14->-r FortiQAGPTQrequirements.txt (line 14))\n",
      "  Using cached pluralizer-1.2.0-py3-none-any.whl.metadata (2.9 kB)\n",
      "Collecting stix<1.2.1.0,>=1.1.1.9 (from stix2-elevator->mitreattack-python==2.0.14->-r FortiQAGPTQrequirements.txt (line 14))\n",
      "  Using cached stix-1.2.0.11-py2.py3-none-any.whl.metadata (5.2 kB)\n",
      "Collecting stix2-validator>=3.0.0 (from stix2-elevator->mitreattack-python==2.0.14->-r FortiQAGPTQrequirements.txt (line 14))\n",
      "  Using cached stix2_validator-3.2.0-py2.py3-none-any.whl.metadata (10 kB)\n",
      "Collecting stixmarx>=1.0.8 (from stix2-elevator->mitreattack-python==2.0.14->-r FortiQAGPTQrequirements.txt (line 14))\n",
      "  Using cached stixmarx-1.0.8-py2.py3-none-any.whl.metadata (5.4 kB)\n",
      "Requirement already satisfied: mpmath>=0.19 in /opt/conda/lib/python3.11/site-packages (from sympy->torch==2.2.0->-r FortiQAGPTQrequirements.txt (line 23)) (1.3.0)\n",
      "Requirement already satisfied: mdurl~=0.1 in /opt/conda/lib/python3.11/site-packages (from markdown-it-py>=2.2.0->rich->mitreattack-python==2.0.14->-r FortiQAGPTQrequirements.txt (line 14)) (0.1.2)\n",
      "Requirement already satisfied: chardet<6,>=3.0.4 in /opt/conda/lib/python3.11/site-packages (from mbstrdecoder<2,>=1.0.0->pytablewriter->lm_eval==0.4.7->-r FortiQAGPTQrequirements.txt (line 1)) (5.2.0)\n",
      "Collecting mixbox>=1.0.4 (from stix<1.2.1.0,>=1.1.1.9->stix2-elevator->mitreattack-python==2.0.14->-r FortiQAGPTQrequirements.txt (line 14))\n",
      "  Using cached mixbox-1.0.5-py2.py3-none-any.whl.metadata (2.5 kB)\n",
      "Collecting cybox<2.1.1.0,>=2.1.0.13 (from stix<1.2.1.0,>=1.1.1.9->stix2-elevator->mitreattack-python==2.0.14->-r FortiQAGPTQrequirements.txt (line 14))\n",
      "  Using cached cybox-2.1.0.21-py2.py3-none-any.whl.metadata (5.6 kB)\n",
      "Collecting antlr4-python3-runtime~=4.9.0 (from stix2-patterns>=1.2.0->stix2->mitreattack-python==2.0.14->-r FortiQAGPTQrequirements.txt (line 14))\n",
      "  Using cached antlr4_python3_runtime-4.9.3-py3-none-any.whl\n",
      "Collecting cpe (from stix2-validator>=3.0.0->stix2-elevator->mitreattack-python==2.0.14->-r FortiQAGPTQrequirements.txt (line 14))\n",
      "  Using cached cpe-1.3.1-py3-none-any.whl\n",
      "Requirement already satisfied: jsonschema>=4.20.0 in /opt/conda/lib/python3.11/site-packages (from jsonschema[format-nongpl]>=4.20.0->stix2-validator>=3.0.0->stix2-elevator->mitreattack-python==2.0.14->-r FortiQAGPTQrequirements.txt (line 14)) (4.22.0)\n",
      "Requirement already satisfied: mypy-extensions>=0.3.0 in /opt/conda/lib/python3.11/site-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain-community==0.3.4->-r FortiQAGPTQrequirements.txt (line 9)) (1.0.0)\n",
      "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /opt/conda/lib/python3.11/site-packages (from jsonschema>=4.20.0->jsonschema[format-nongpl]>=4.20.0->stix2-validator>=3.0.0->stix2-elevator->mitreattack-python==2.0.14->-r FortiQAGPTQrequirements.txt (line 14)) (2023.12.1)\n",
      "Requirement already satisfied: referencing>=0.28.4 in /opt/conda/lib/python3.11/site-packages (from jsonschema>=4.20.0->jsonschema[format-nongpl]>=4.20.0->stix2-validator>=3.0.0->stix2-elevator->mitreattack-python==2.0.14->-r FortiQAGPTQrequirements.txt (line 14)) (0.35.1)\n",
      "Requirement already satisfied: rpds-py>=0.7.1 in /opt/conda/lib/python3.11/site-packages (from jsonschema>=4.20.0->jsonschema[format-nongpl]>=4.20.0->stix2-validator>=3.0.0->stix2-elevator->mitreattack-python==2.0.14->-r FortiQAGPTQrequirements.txt (line 14)) (0.18.1)\n",
      "Requirement already satisfied: fqdn in /opt/conda/lib/python3.11/site-packages (from jsonschema[format-nongpl]>=4.20.0->stix2-validator>=3.0.0->stix2-elevator->mitreattack-python==2.0.14->-r FortiQAGPTQrequirements.txt (line 14)) (1.5.1)\n",
      "Requirement already satisfied: isoduration in /opt/conda/lib/python3.11/site-packages (from jsonschema[format-nongpl]>=4.20.0->stix2-validator>=3.0.0->stix2-elevator->mitreattack-python==2.0.14->-r FortiQAGPTQrequirements.txt (line 14)) (20.11.0)\n",
      "Requirement already satisfied: rfc3339-validator in /opt/conda/lib/python3.11/site-packages (from jsonschema[format-nongpl]>=4.20.0->stix2-validator>=3.0.0->stix2-elevator->mitreattack-python==2.0.14->-r FortiQAGPTQrequirements.txt (line 14)) (0.1.4)\n",
      "Requirement already satisfied: rfc3986-validator>0.1.0 in /opt/conda/lib/python3.11/site-packages (from jsonschema[format-nongpl]>=4.20.0->stix2-validator>=3.0.0->stix2-elevator->mitreattack-python==2.0.14->-r FortiQAGPTQrequirements.txt (line 14)) (0.1.1)\n",
      "Requirement already satisfied: uri-template in /opt/conda/lib/python3.11/site-packages (from jsonschema[format-nongpl]>=4.20.0->stix2-validator>=3.0.0->stix2-elevator->mitreattack-python==2.0.14->-r FortiQAGPTQrequirements.txt (line 14)) (1.3.0)\n",
      "Requirement already satisfied: webcolors>=1.11 in /opt/conda/lib/python3.11/site-packages (from jsonschema[format-nongpl]>=4.20.0->stix2-validator>=3.0.0->stix2-elevator->mitreattack-python==2.0.14->-r FortiQAGPTQrequirements.txt (line 14)) (1.13)\n",
      "Collecting ordered-set (from mixbox>=1.0.4->stix<1.2.1.0,>=1.1.1.9->stix2-elevator->mitreattack-python==2.0.14->-r FortiQAGPTQrequirements.txt (line 14))\n",
      "  Using cached ordered_set-4.1.0-py3-none-any.whl.metadata (5.3 kB)\n",
      "Collecting weakrefmethod>=1.0.3 (from mixbox>=1.0.4->stix<1.2.1.0,>=1.1.1.9->stix2-elevator->mitreattack-python==2.0.14->-r FortiQAGPTQrequirements.txt (line 14))\n",
      "  Using cached weakrefmethod-1.0.3-py3-none-any.whl\n",
      "Requirement already satisfied: arrow>=0.15.0 in /opt/conda/lib/python3.11/site-packages (from isoduration->jsonschema[format-nongpl]>=4.20.0->stix2-validator>=3.0.0->stix2-elevator->mitreattack-python==2.0.14->-r FortiQAGPTQrequirements.txt (line 14)) (1.3.0)\n",
      "Requirement already satisfied: types-python-dateutil>=2.8.10 in /opt/conda/lib/python3.11/site-packages (from arrow>=0.15.0->isoduration->jsonschema[format-nongpl]>=4.20.0->stix2-validator>=3.0.0->stix2-elevator->mitreattack-python==2.0.14->-r FortiQAGPTQrequirements.txt (line 14)) (2.9.0.20240316)\n",
      "Using cached beautifulsoup4-4.10.0-py3-none-any.whl (97 kB)\n",
      "Using cached evaluate-0.4.0-py3-none-any.whl (81 kB)\n",
      "Using cached langchain-0.3.7-py3-none-any.whl (1.0 MB)\n",
      "Using cached langchain_community-0.3.4-py3-none-any.whl (2.4 MB)\n",
      "Using cached langchain_core-0.3.15-py3-none-any.whl (408 kB)\n",
      "Using cached langchain_huggingface-0.1.0-py3-none-any.whl (20 kB)\n",
      "Using cached langchain_openai-0.2.4-py3-none-any.whl (50 kB)\n",
      "Using cached Markdown-3.4.4-py3-none-any.whl (94 kB)\n",
      "Using cached mitreattack_python-2.0.14-py3-none-any.whl (532 kB)\n",
      "Using cached nltk-3.9-py3-none-any.whl (1.5 MB)\n",
      "Using cached openai-1.54.1-py3-none-any.whl (389 kB)\n",
      "Using cached peft-0.4.0-py3-none-any.whl (72 kB)\n",
      "Using cached sentence_transformers-3.1.1-py3-none-any.whl (245 kB)\n",
      "Using cached tokenizers-0.20.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.0 MB)\n",
      "Using cached torch-2.2.0-cp311-cp311-manylinux1_x86_64.whl (755.5 MB)\n",
      "Using cached tqdm-4.66.3-py3-none-any.whl (78 kB)\n",
      "Using cached transformers-4.45.2-py3-none-any.whl (9.9 MB)\n",
      "Using cached nvidia_nccl_cu12-2.19.3-py3-none-manylinux1_x86_64.whl (166.0 MB)\n",
      "Using cached triton-2.2.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (167.9 MB)\n",
      "Using cached drawsvg-2.4.0-py3-none-any.whl (44 kB)\n",
      "Using cached httpx_sse-0.4.0-py3-none-any.whl (7.8 kB)\n",
      "Using cached langchain_text_splitters-0.3.2-py3-none-any.whl (25 kB)\n",
      "Using cached langsmith-0.1.147-py3-none-any.whl (311 kB)\n",
      "Using cached pydantic-2.10.6-py3-none-any.whl (431 kB)\n",
      "Using cached pydantic_core-2.27.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.0 MB)\n",
      "Downloading pydantic_settings-2.8.0-py3-none-any.whl (30 kB)\n",
      "Using cached responses-0.18.0-py3-none-any.whl (38 kB)\n",
      "Using cached typing_extensions-4.12.2-py3-none-any.whl (37 kB)\n",
      "Using cached colour-0.1.5-py2.py3-none-any.whl (23 kB)\n",
      "Using cached deepdiff-8.2.0-py3-none-any.whl (83 kB)\n",
      "Using cached loguru-0.7.3-py3-none-any.whl (61 kB)\n",
      "Using cached pooch-1.8.2-py3-none-any.whl (64 kB)\n",
      "Using cached stix2-3.0.1-py2.py3-none-any.whl (177 kB)\n",
      "Using cached stix2_elevator-4.1.7-py2.py3-none-any.whl (104 kB)\n",
      "Using cached taxii2_client-2.3.0-py2.py3-none-any.whl (24 kB)\n",
      "Using cached XlsxWriter-3.2.2-py3-none-any.whl (165 kB)\n",
      "Using cached orderly_set-5.3.0-py3-none-any.whl (12 kB)\n",
      "Using cached pycountry-24.6.1-py3-none-any.whl (6.3 MB)\n",
      "Using cached requests_toolbelt-1.0.0-py2.py3-none-any.whl (54 kB)\n",
      "Using cached stix-1.2.0.11-py2.py3-none-any.whl (290 kB)\n",
      "Using cached stix2_patterns-2.0.0-py2.py3-none-any.whl (65 kB)\n",
      "Using cached stix2_validator-3.2.0-py2.py3-none-any.whl (965 kB)\n",
      "Using cached stixmarx-1.0.8-py2.py3-none-any.whl (32 kB)\n",
      "Using cached maec-4.1.0.17-py2.py3-none-any.whl (133 kB)\n",
      "Using cached netaddr-1.3.0-py3-none-any.whl (2.3 MB)\n",
      "Using cached pluralizer-1.2.0-py3-none-any.whl (7.6 kB)\n",
      "Downloading simplejson-3.20.1-cp311-cp311-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (144 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m144.8/144.8 kB\u001b[0m \u001b[31m255.6 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hUsing cached cybox-2.1.0.21-py2.py3-none-any.whl (780 kB)\n",
      "Using cached mixbox-1.0.5-py2.py3-none-any.whl (47 kB)\n",
      "Using cached ordered_set-4.1.0-py3-none-any.whl (7.6 kB)\n",
      "Installing collected packages: weakrefmethod, drawsvg, cpe, colour, antlr4-python3-runtime, xlsxwriter, typing-extensions, triton, tqdm, stix2-patterns, simplejson, pycountry, pluralizer, orderly-set, ordered-set, nvidia-nccl-cu12, netaddr, markdown, loguru, httpx-sse, beautifulsoup4, taxii2-client, stix2, responses, requests-toolbelt, pydantic-core, pooch, pandas, nltk, mixbox, deepdiff, torch, tokenizers, pydantic, cybox, transformers, stix, pydantic-settings, openai, maec, langsmith, stixmarx, stix2-validator, sentence-transformers, peft, langchain-core, evaluate, stix2-elevator, langchain-text-splitters, langchain-openai, langchain-huggingface, mitreattack-python, langchain, langchain-community\n",
      "  Attempting uninstall: typing-extensions\n",
      "    Found existing installation: typing_extensions 4.11.0\n",
      "    Uninstalling typing_extensions-4.11.0:\n",
      "      Successfully uninstalled typing_extensions-4.11.0\n",
      "  Attempting uninstall: triton\n",
      "    Found existing installation: triton 2.3.0\n",
      "    Uninstalling triton-2.3.0:\n",
      "      Successfully uninstalled triton-2.3.0\n",
      "  Attempting uninstall: tqdm\n",
      "    Found existing installation: tqdm 4.66.4\n",
      "    Uninstalling tqdm-4.66.4:\n",
      "      Successfully uninstalled tqdm-4.66.4\n",
      "  Attempting uninstall: nvidia-nccl-cu12\n",
      "    Found existing installation: nvidia-nccl-cu12 2.20.5\n",
      "    Uninstalling nvidia-nccl-cu12-2.20.5:\n",
      "      Successfully uninstalled nvidia-nccl-cu12-2.20.5\n",
      "  Attempting uninstall: markdown\n",
      "    Found existing installation: Markdown 3.6\n",
      "    Uninstalling Markdown-3.6:\n",
      "      Successfully uninstalled Markdown-3.6\n",
      "  Attempting uninstall: beautifulsoup4\n",
      "    Found existing installation: beautifulsoup4 4.12.3\n",
      "    Uninstalling beautifulsoup4-4.12.3:\n",
      "      Successfully uninstalled beautifulsoup4-4.12.3\n",
      "  Attempting uninstall: pydantic-core\n",
      "    Found existing installation: pydantic_core 2.18.2\n",
      "    Uninstalling pydantic_core-2.18.2:\n",
      "      Successfully uninstalled pydantic_core-2.18.2\n",
      "  Attempting uninstall: pandas\n",
      "    Found existing installation: pandas 2.2.2\n",
      "    Uninstalling pandas-2.2.2:\n",
      "      Successfully uninstalled pandas-2.2.2\n",
      "  Attempting uninstall: nltk\n",
      "    Found existing installation: nltk 3.9.1\n",
      "    Uninstalling nltk-3.9.1:\n",
      "      Successfully uninstalled nltk-3.9.1\n",
      "  Attempting uninstall: torch\n",
      "    Found existing installation: torch 2.3.0+cu121\n",
      "    Uninstalling torch-2.3.0+cu121:\n",
      "      Successfully uninstalled torch-2.3.0+cu121\n",
      "  Attempting uninstall: tokenizers\n",
      "    Found existing installation: tokenizers 0.21.0\n",
      "    Uninstalling tokenizers-0.21.0:\n",
      "      Successfully uninstalled tokenizers-0.21.0\n",
      "  Attempting uninstall: pydantic\n",
      "    Found existing installation: pydantic 2.7.1\n",
      "    Uninstalling pydantic-2.7.1:\n",
      "      Successfully uninstalled pydantic-2.7.1\n",
      "  Attempting uninstall: transformers\n",
      "    Found existing installation: transformers 4.49.0\n",
      "    Uninstalling transformers-4.49.0:\n",
      "      Successfully uninstalled transformers-4.49.0\n",
      "  Attempting uninstall: openai\n",
      "    Found existing installation: openai 1.30.5\n",
      "    Uninstalling openai-1.30.5:\n",
      "      Successfully uninstalled openai-1.30.5\n",
      "  Attempting uninstall: langsmith\n",
      "    Found existing installation: langsmith 0.1.65\n",
      "    Uninstalling langsmith-0.1.65:\n",
      "      Successfully uninstalled langsmith-0.1.65\n",
      "  Attempting uninstall: peft\n",
      "    Found existing installation: peft 0.14.0\n",
      "    Uninstalling peft-0.14.0:\n",
      "      Successfully uninstalled peft-0.14.0\n",
      "  Attempting uninstall: langchain-core\n",
      "    Found existing installation: langchain-core 0.1.52\n",
      "    Uninstalling langchain-core-0.1.52:\n",
      "      Successfully uninstalled langchain-core-0.1.52\n",
      "  Attempting uninstall: evaluate\n",
      "    Found existing installation: evaluate 0.4.3\n",
      "    Uninstalling evaluate-0.4.3:\n",
      "      Successfully uninstalled evaluate-0.4.3\n",
      "  Attempting uninstall: langchain-text-splitters\n",
      "    Found existing installation: langchain-text-splitters 0.0.2\n",
      "    Uninstalling langchain-text-splitters-0.0.2:\n",
      "      Successfully uninstalled langchain-text-splitters-0.0.2\n",
      "  Attempting uninstall: langchain-openai\n",
      "    Found existing installation: langchain-openai 0.1.7\n",
      "    Uninstalling langchain-openai-0.1.7:\n",
      "      Successfully uninstalled langchain-openai-0.1.7\n",
      "  Attempting uninstall: langchain\n",
      "    Found existing installation: langchain 0.1.20\n",
      "    Uninstalling langchain-0.1.20:\n",
      "      Successfully uninstalled langchain-0.1.20\n",
      "  Attempting uninstall: langchain-community\n",
      "    Found existing installation: langchain-community 0.0.38\n",
      "    Uninstalling langchain-community-0.0.38:\n",
      "      Successfully uninstalled langchain-community-0.0.38\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "langchain-nvidia-ai-endpoints 0.0.19 requires langchain-core<0.3,>=0.1.27, but you have langchain-core 0.3.15 which is incompatible.\n",
      "langchain-google-genai 1.0.4 requires langchain-core<0.3,>=0.1.45, but you have langchain-core 0.3.15 which is incompatible.\n",
      "torchaudio 2.3.0+cu121 requires torch==2.3.0, but you have torch 2.2.0 which is incompatible.\n",
      "langchain-anthropic 0.1.13 requires langchain-core<0.3,>=0.1.43, but you have langchain-core 0.3.15 which is incompatible.\n",
      "torchvision 0.18.0+cu121 requires torch==2.3.0, but you have torch 2.2.0 which is incompatible.\n",
      "jupyter-ai-magics 2.16.0 requires langchain<0.2.0,>=0.1.0, but you have langchain 0.3.7 which is incompatible.\n",
      "dask-expr 1.1.1 requires pandas>=2, but you have pandas 1.4.1 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0mSuccessfully installed antlr4-python3-runtime-4.9.3 beautifulsoup4-4.10.0 colour-0.1.5 cpe-1.3.1 cybox-2.1.0.21 deepdiff-8.2.0 drawsvg-2.4.0 evaluate-0.4.0 httpx-sse-0.4.0 langchain-0.3.7 langchain-community-0.3.4 langchain-core-0.3.15 langchain-huggingface-0.1.0 langchain-openai-0.2.4 langchain-text-splitters-0.3.2 langsmith-0.1.147 loguru-0.7.3 maec-4.1.0.17 markdown-3.4.4 mitreattack-python-2.0.14 mixbox-1.0.5 netaddr-1.3.0 nltk-3.9 nvidia-nccl-cu12-2.19.3 openai-1.54.1 ordered-set-4.1.0 orderly-set-5.3.0 pandas-1.4.1 peft-0.4.0 pluralizer-1.2.0 pooch-1.8.2 pycountry-24.6.1 pydantic-2.10.6 pydantic-core-2.27.2 pydantic-settings-2.8.0 requests-toolbelt-1.0.0 responses-0.18.0 sentence-transformers-3.1.1 simplejson-3.20.1 stix-1.2.0.11 stix2-3.0.1 stix2-elevator-4.1.7 stix2-patterns-2.0.0 stix2-validator-3.2.0 stixmarx-1.0.8 taxii2-client-2.3.0 tokenizers-0.20.2 torch-2.2.0 tqdm-4.66.3 transformers-4.45.2 triton-2.2.0 typing-extensions-4.12.2 weakrefmethod-1.0.3 xlsxwriter-3.2.2\n"
     ]
    }
   ],
   "source": [
    "#setup\n",
    "!pip install -r FortiQAGPTQrequirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d59c261a-7ef8-4f8e-9a61-09fe1e5ec08b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting gptqmodel\n",
      "  Using cached gptqmodel-1.9.0+cu121torch2.3-cp311-cp311-linux_x86_64.whl\n",
      "Discarding \u001b[4;34mhttps://files.pythonhosted.org/packages/db/b6/348569757042bb3a674935fe20ae059e56866b4c544e0fa354daf47db14f/gptqmodel-1.9.0.tar.gz (from https://pypi.org/simple/gptqmodel/) (requires-python:>=3.9.0)\u001b[0m: \u001b[33mRequested gptqmodel from file:///home/jovyan/.cache/pip/wheels/75/dc/a8/85f4e3aafe265c6f4df9f372b22be86b20de8d1b65b0680268/gptqmodel-1.9.0%2Bcu121torch2.3-cp311-cp311-linux_x86_64.whl has inconsistent version: expected '1.9.0', but metadata has '1.9.0+cu121torch2.3'\u001b[0m\n",
      "  Using cached gptqmodel-1.8.1+cu121torch2.3-cp311-cp311-linux_x86_64.whl\n",
      "Discarding \u001b[4;34mhttps://files.pythonhosted.org/packages/46/30/cb98de206a29807a59e63c10238eb90570143229df9b67a9a7f2342672bd/gptqmodel-1.8.1.tar.gz (from https://pypi.org/simple/gptqmodel/) (requires-python:>=3.9.0)\u001b[0m: \u001b[33mRequested gptqmodel from file:///home/jovyan/.cache/pip/wheels/64/3e/c4/a4d5f7b326cc1970ddee6324a2d6652b2cd290f40cda86cfc9/gptqmodel-1.8.1%2Bcu121torch2.3-cp311-cp311-linux_x86_64.whl has inconsistent version: expected '1.8.1', but metadata has '1.8.1+cu121torch2.3'\u001b[0m\n",
      "  Using cached gptqmodel-1.8.0+cu121torch2.3-cp311-cp311-linux_x86_64.whl\n",
      "Discarding \u001b[4;34mhttps://files.pythonhosted.org/packages/a2/de/aed10b4936b7c56870d3af7892ce51ebcdff2d5d0f13a09cb9b337e91df0/gptqmodel-1.8.0.tar.gz (from https://pypi.org/simple/gptqmodel/) (requires-python:>=3.9.0)\u001b[0m: \u001b[33mRequested gptqmodel from file:///home/jovyan/.cache/pip/wheels/02/57/fe/68ece9edf903fa00e392f794ca6b3a915d352a71a9aafe4246/gptqmodel-1.8.0%2Bcu121torch2.3-cp311-cp311-linux_x86_64.whl has inconsistent version: expected '1.8.0', but metadata has '1.8.0+cu121torch2.3'\u001b[0m\n",
      "  Using cached gptqmodel-1.7.4+cu121torch2.3-cp311-cp311-linux_x86_64.whl\n",
      "Discarding \u001b[4;34mhttps://files.pythonhosted.org/packages/b3/03/bbe6e9cd935f24f4a789b8919bcc7948bbe9860b2c67c972d4f474e12632/gptqmodel-1.7.4.tar.gz (from https://pypi.org/simple/gptqmodel/) (requires-python:>=3.9.0)\u001b[0m: \u001b[33mRequested gptqmodel from file:///home/jovyan/.cache/pip/wheels/b0/d9/43/6f4492a30c6ea2cb0b8e078b029f952ebbc11b9ff94ea6d376/gptqmodel-1.7.4%2Bcu121torch2.3-cp311-cp311-linux_x86_64.whl has inconsistent version: expected '1.7.4', but metadata has '1.7.4+cu121torch2.3'\u001b[0m\n",
      "  Using cached gptqmodel-1.7.3.tar.gz (295 kB)\n",
      "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hRequirement already satisfied: accelerate>=1.2.1 in /opt/conda/lib/python3.11/site-packages (from gptqmodel) (1.4.0)\n",
      "Requirement already satisfied: datasets>=3.1.0 in /opt/conda/lib/python3.11/site-packages (from gptqmodel) (3.3.2)\n",
      "Requirement already satisfied: numpy>=1.26.4 in /opt/conda/lib/python3.11/site-packages (from gptqmodel) (2.2.3)\n",
      "Requirement already satisfied: torch>=2.0.0 in /opt/conda/lib/python3.11/site-packages (from gptqmodel) (2.3.0+cu121)\n",
      "Requirement already satisfied: safetensors>=0.4.5 in /opt/conda/lib/python3.11/site-packages (from gptqmodel) (0.5.2)\n",
      "Requirement already satisfied: transformers>=4.47.1 in /opt/conda/lib/python3.11/site-packages (from gptqmodel) (4.49.0)\n",
      "Requirement already satisfied: threadpoolctl>=3.5.0 in /opt/conda/lib/python3.11/site-packages (from gptqmodel) (3.5.0)\n",
      "Requirement already satisfied: packaging>=24.2 in /opt/conda/lib/python3.11/site-packages (from gptqmodel) (24.2)\n",
      "Requirement already satisfied: device-smi==0.3.3 in /opt/conda/lib/python3.11/site-packages (from gptqmodel) (0.3.3)\n",
      "Requirement already satisfied: sentencepiece>=0.2.0 in /opt/conda/lib/python3.11/site-packages (from gptqmodel) (0.2.0)\n",
      "Requirement already satisfied: protobuf>=5.29.1 in /opt/conda/lib/python3.11/site-packages (from gptqmodel) (5.29.3)\n",
      "Requirement already satisfied: pillow>=10.4.0 in /opt/conda/lib/python3.11/site-packages (from gptqmodel) (11.1.0)\n",
      "Requirement already satisfied: psutil in /opt/conda/lib/python3.11/site-packages (from accelerate>=1.2.1->gptqmodel) (5.9.8)\n",
      "Requirement already satisfied: pyyaml in /opt/conda/lib/python3.11/site-packages (from accelerate>=1.2.1->gptqmodel) (6.0.1)\n",
      "Requirement already satisfied: huggingface-hub>=0.21.0 in /opt/conda/lib/python3.11/site-packages (from accelerate>=1.2.1->gptqmodel) (0.29.1)\n",
      "Requirement already satisfied: filelock in /opt/conda/lib/python3.11/site-packages (from datasets>=3.1.0->gptqmodel) (3.13.1)\n",
      "Requirement already satisfied: pyarrow>=15.0.0 in /opt/conda/lib/python3.11/site-packages (from datasets>=3.1.0->gptqmodel) (16.1.0)\n",
      "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /opt/conda/lib/python3.11/site-packages (from datasets>=3.1.0->gptqmodel) (0.3.8)\n",
      "Requirement already satisfied: pandas in /opt/conda/lib/python3.11/site-packages (from datasets>=3.1.0->gptqmodel) (2.2.2)\n",
      "Requirement already satisfied: requests>=2.32.2 in /opt/conda/lib/python3.11/site-packages (from datasets>=3.1.0->gptqmodel) (2.32.3)\n",
      "Requirement already satisfied: tqdm>=4.66.3 in /opt/conda/lib/python3.11/site-packages (from datasets>=3.1.0->gptqmodel) (4.66.4)\n",
      "Requirement already satisfied: xxhash in /opt/conda/lib/python3.11/site-packages (from datasets>=3.1.0->gptqmodel) (3.5.0)\n",
      "Requirement already satisfied: multiprocess<0.70.17 in /opt/conda/lib/python3.11/site-packages (from datasets>=3.1.0->gptqmodel) (0.70.16)\n",
      "Requirement already satisfied: fsspec<=2024.12.0,>=2023.1.0 in /opt/conda/lib/python3.11/site-packages (from fsspec[http]<=2024.12.0,>=2023.1.0->datasets>=3.1.0->gptqmodel) (2024.5.0)\n",
      "Requirement already satisfied: aiohttp in /opt/conda/lib/python3.11/site-packages (from datasets>=3.1.0->gptqmodel) (3.9.5)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in /opt/conda/lib/python3.11/site-packages (from torch>=2.0.0->gptqmodel) (4.11.0)\n",
      "Requirement already satisfied: sympy in /opt/conda/lib/python3.11/site-packages (from torch>=2.0.0->gptqmodel) (1.12)\n",
      "Requirement already satisfied: networkx in /opt/conda/lib/python3.11/site-packages (from torch>=2.0.0->gptqmodel) (3.3)\n",
      "Requirement already satisfied: jinja2 in /opt/conda/lib/python3.11/site-packages (from torch>=2.0.0->gptqmodel) (3.1.4)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /opt/conda/lib/python3.11/site-packages (from torch>=2.0.0->gptqmodel) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /opt/conda/lib/python3.11/site-packages (from torch>=2.0.0->gptqmodel) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /opt/conda/lib/python3.11/site-packages (from torch>=2.0.0->gptqmodel) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /opt/conda/lib/python3.11/site-packages (from torch>=2.0.0->gptqmodel) (8.9.2.26)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /opt/conda/lib/python3.11/site-packages (from torch>=2.0.0->gptqmodel) (12.1.3.1)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /opt/conda/lib/python3.11/site-packages (from torch>=2.0.0->gptqmodel) (11.0.2.54)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /opt/conda/lib/python3.11/site-packages (from torch>=2.0.0->gptqmodel) (10.3.2.106)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /opt/conda/lib/python3.11/site-packages (from torch>=2.0.0->gptqmodel) (11.4.5.107)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /opt/conda/lib/python3.11/site-packages (from torch>=2.0.0->gptqmodel) (12.1.0.106)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.20.5 in /opt/conda/lib/python3.11/site-packages (from torch>=2.0.0->gptqmodel) (2.20.5)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /opt/conda/lib/python3.11/site-packages (from torch>=2.0.0->gptqmodel) (12.1.105)\n",
      "Requirement already satisfied: triton==2.3.0 in /opt/conda/lib/python3.11/site-packages (from torch>=2.0.0->gptqmodel) (2.3.0)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12 in /opt/conda/lib/python3.11/site-packages (from nvidia-cusolver-cu12==11.4.5.107->torch>=2.0.0->gptqmodel) (12.3.101)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.11/site-packages (from transformers>=4.47.1->gptqmodel) (2024.5.15)\n",
      "Requirement already satisfied: tokenizers<0.22,>=0.21 in /opt/conda/lib/python3.11/site-packages (from transformers>=4.47.1->gptqmodel) (0.21.0)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /opt/conda/lib/python3.11/site-packages (from aiohttp->datasets>=3.1.0->gptqmodel) (1.3.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /opt/conda/lib/python3.11/site-packages (from aiohttp->datasets>=3.1.0->gptqmodel) (23.2.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /opt/conda/lib/python3.11/site-packages (from aiohttp->datasets>=3.1.0->gptqmodel) (1.4.1)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /opt/conda/lib/python3.11/site-packages (from aiohttp->datasets>=3.1.0->gptqmodel) (6.0.5)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /opt/conda/lib/python3.11/site-packages (from aiohttp->datasets>=3.1.0->gptqmodel) (1.9.4)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.11/site-packages (from requests>=2.32.2->datasets>=3.1.0->gptqmodel) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.11/site-packages (from requests>=2.32.2->datasets>=3.1.0->gptqmodel) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.11/site-packages (from requests>=2.32.2->datasets>=3.1.0->gptqmodel) (2.2.1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.11/site-packages (from requests>=2.32.2->datasets>=3.1.0->gptqmodel) (2024.2.2)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.11/site-packages (from jinja2->torch>=2.0.0->gptqmodel) (2.1.5)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /opt/conda/lib/python3.11/site-packages (from pandas->datasets>=3.1.0->gptqmodel) (2.9.0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.11/site-packages (from pandas->datasets>=3.1.0->gptqmodel) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /opt/conda/lib/python3.11/site-packages (from pandas->datasets>=3.1.0->gptqmodel) (2024.1)\n",
      "Requirement already satisfied: mpmath>=0.19 in /opt/conda/lib/python3.11/site-packages (from sympy->torch>=2.0.0->gptqmodel) (1.3.0)\n",
      "Requirement already satisfied: six>=1.5 in /opt/conda/lib/python3.11/site-packages (from python-dateutil>=2.8.2->pandas->datasets>=3.1.0->gptqmodel) (1.16.0)\n",
      "Building wheels for collected packages: gptqmodel\n",
      "  Building wheel for gptqmodel (setup.py) ... \u001b[?25lerror\n",
      "  \u001b[1;31merror\u001b[0m: \u001b[1msubprocess-exited-with-error\u001b[0m\n",
      "  \n",
      "  \u001b[31m×\u001b[0m \u001b[32mpython setup.py bdist_wheel\u001b[0m did not run successfully.\n",
      "  \u001b[31m│\u001b[0m exit code: \u001b[1;36m1\u001b[0m\n",
      "  \u001b[31m╰─>\u001b[0m \u001b[31m[226 lines of output]\u001b[0m\n",
      "  \u001b[31m   \u001b[0m Requirement already satisfied: accelerate>=1.2.1 in /opt/conda/lib/python3.11/site-packages (from -r requirements.txt (line 1)) (1.4.0)\n",
      "  \u001b[31m   \u001b[0m Requirement already satisfied: datasets>=3.1.0 in /opt/conda/lib/python3.11/site-packages (from -r requirements.txt (line 2)) (3.3.2)\n",
      "  \u001b[31m   \u001b[0m Requirement already satisfied: numpy>=1.26.4 in /opt/conda/lib/python3.11/site-packages (from -r requirements.txt (line 3)) (2.2.3)\n",
      "  \u001b[31m   \u001b[0m Requirement already satisfied: torch>=2.0.0 in /opt/conda/lib/python3.11/site-packages (from -r requirements.txt (line 4)) (2.3.0+cu121)\n",
      "  \u001b[31m   \u001b[0m Requirement already satisfied: safetensors>=0.4.5 in /opt/conda/lib/python3.11/site-packages (from -r requirements.txt (line 5)) (0.5.2)\n",
      "  \u001b[31m   \u001b[0m Requirement already satisfied: transformers>=4.47.1 in /opt/conda/lib/python3.11/site-packages (from -r requirements.txt (line 6)) (4.49.0)\n",
      "  \u001b[31m   \u001b[0m Requirement already satisfied: threadpoolctl>=3.5.0 in /opt/conda/lib/python3.11/site-packages (from -r requirements.txt (line 7)) (3.5.0)\n",
      "  \u001b[31m   \u001b[0m Requirement already satisfied: packaging>=24.2 in /opt/conda/lib/python3.11/site-packages (from -r requirements.txt (line 8)) (24.2)\n",
      "  \u001b[31m   \u001b[0m Requirement already satisfied: device-smi==0.3.3 in /opt/conda/lib/python3.11/site-packages (from -r requirements.txt (line 9)) (0.3.3)\n",
      "  \u001b[31m   \u001b[0m Requirement already satisfied: sentencepiece>=0.2.0 in /opt/conda/lib/python3.11/site-packages (from -r requirements.txt (line 10)) (0.2.0)\n",
      "  \u001b[31m   \u001b[0m Requirement already satisfied: protobuf>=5.29.1 in /opt/conda/lib/python3.11/site-packages (from -r requirements.txt (line 11)) (5.29.3)\n",
      "  \u001b[31m   \u001b[0m Requirement already satisfied: pillow>=10.4.0 in /opt/conda/lib/python3.11/site-packages (from -r requirements.txt (line 12)) (11.1.0)\n",
      "  \u001b[31m   \u001b[0m Requirement already satisfied: psutil in /opt/conda/lib/python3.11/site-packages (from accelerate>=1.2.1->-r requirements.txt (line 1)) (5.9.8)\n",
      "  \u001b[31m   \u001b[0m Requirement already satisfied: pyyaml in /opt/conda/lib/python3.11/site-packages (from accelerate>=1.2.1->-r requirements.txt (line 1)) (6.0.1)\n",
      "  \u001b[31m   \u001b[0m Requirement already satisfied: huggingface-hub>=0.21.0 in /opt/conda/lib/python3.11/site-packages (from accelerate>=1.2.1->-r requirements.txt (line 1)) (0.29.1)\n",
      "  \u001b[31m   \u001b[0m Requirement already satisfied: filelock in /opt/conda/lib/python3.11/site-packages (from datasets>=3.1.0->-r requirements.txt (line 2)) (3.13.1)\n",
      "  \u001b[31m   \u001b[0m Requirement already satisfied: pyarrow>=15.0.0 in /opt/conda/lib/python3.11/site-packages (from datasets>=3.1.0->-r requirements.txt (line 2)) (16.1.0)\n",
      "  \u001b[31m   \u001b[0m Requirement already satisfied: dill<0.3.9,>=0.3.0 in /opt/conda/lib/python3.11/site-packages (from datasets>=3.1.0->-r requirements.txt (line 2)) (0.3.8)\n",
      "  \u001b[31m   \u001b[0m Requirement already satisfied: pandas in /opt/conda/lib/python3.11/site-packages (from datasets>=3.1.0->-r requirements.txt (line 2)) (2.2.2)\n",
      "  \u001b[31m   \u001b[0m Requirement already satisfied: requests>=2.32.2 in /opt/conda/lib/python3.11/site-packages (from datasets>=3.1.0->-r requirements.txt (line 2)) (2.32.3)\n",
      "  \u001b[31m   \u001b[0m Requirement already satisfied: tqdm>=4.66.3 in /opt/conda/lib/python3.11/site-packages (from datasets>=3.1.0->-r requirements.txt (line 2)) (4.66.4)\n",
      "  \u001b[31m   \u001b[0m Requirement already satisfied: xxhash in /opt/conda/lib/python3.11/site-packages (from datasets>=3.1.0->-r requirements.txt (line 2)) (3.5.0)\n",
      "  \u001b[31m   \u001b[0m Requirement already satisfied: multiprocess<0.70.17 in /opt/conda/lib/python3.11/site-packages (from datasets>=3.1.0->-r requirements.txt (line 2)) (0.70.16)\n",
      "  \u001b[31m   \u001b[0m Requirement already satisfied: fsspec<=2024.12.0,>=2023.1.0 in /opt/conda/lib/python3.11/site-packages (from fsspec[http]<=2024.12.0,>=2023.1.0->datasets>=3.1.0->-r requirements.txt (line 2)) (2024.5.0)\n",
      "  \u001b[31m   \u001b[0m Requirement already satisfied: aiohttp in /opt/conda/lib/python3.11/site-packages (from datasets>=3.1.0->-r requirements.txt (line 2)) (3.9.5)\n",
      "  \u001b[31m   \u001b[0m Requirement already satisfied: typing-extensions>=4.8.0 in /opt/conda/lib/python3.11/site-packages (from torch>=2.0.0->-r requirements.txt (line 4)) (4.11.0)\n",
      "  \u001b[31m   \u001b[0m Requirement already satisfied: sympy in /opt/conda/lib/python3.11/site-packages (from torch>=2.0.0->-r requirements.txt (line 4)) (1.12)\n",
      "  \u001b[31m   \u001b[0m Requirement already satisfied: networkx in /opt/conda/lib/python3.11/site-packages (from torch>=2.0.0->-r requirements.txt (line 4)) (3.3)\n",
      "  \u001b[31m   \u001b[0m Requirement already satisfied: jinja2 in /opt/conda/lib/python3.11/site-packages (from torch>=2.0.0->-r requirements.txt (line 4)) (3.1.4)\n",
      "  \u001b[31m   \u001b[0m Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /opt/conda/lib/python3.11/site-packages (from torch>=2.0.0->-r requirements.txt (line 4)) (12.1.105)\n",
      "  \u001b[31m   \u001b[0m Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /opt/conda/lib/python3.11/site-packages (from torch>=2.0.0->-r requirements.txt (line 4)) (12.1.105)\n",
      "  \u001b[31m   \u001b[0m Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /opt/conda/lib/python3.11/site-packages (from torch>=2.0.0->-r requirements.txt (line 4)) (12.1.105)\n",
      "  \u001b[31m   \u001b[0m Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /opt/conda/lib/python3.11/site-packages (from torch>=2.0.0->-r requirements.txt (line 4)) (8.9.2.26)\n",
      "  \u001b[31m   \u001b[0m Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /opt/conda/lib/python3.11/site-packages (from torch>=2.0.0->-r requirements.txt (line 4)) (12.1.3.1)\n",
      "  \u001b[31m   \u001b[0m Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /opt/conda/lib/python3.11/site-packages (from torch>=2.0.0->-r requirements.txt (line 4)) (11.0.2.54)\n",
      "  \u001b[31m   \u001b[0m Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /opt/conda/lib/python3.11/site-packages (from torch>=2.0.0->-r requirements.txt (line 4)) (10.3.2.106)\n",
      "  \u001b[31m   \u001b[0m Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /opt/conda/lib/python3.11/site-packages (from torch>=2.0.0->-r requirements.txt (line 4)) (11.4.5.107)\n",
      "  \u001b[31m   \u001b[0m Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /opt/conda/lib/python3.11/site-packages (from torch>=2.0.0->-r requirements.txt (line 4)) (12.1.0.106)\n",
      "  \u001b[31m   \u001b[0m Requirement already satisfied: nvidia-nccl-cu12==2.20.5 in /opt/conda/lib/python3.11/site-packages (from torch>=2.0.0->-r requirements.txt (line 4)) (2.20.5)\n",
      "  \u001b[31m   \u001b[0m Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /opt/conda/lib/python3.11/site-packages (from torch>=2.0.0->-r requirements.txt (line 4)) (12.1.105)\n",
      "  \u001b[31m   \u001b[0m Requirement already satisfied: triton==2.3.0 in /opt/conda/lib/python3.11/site-packages (from torch>=2.0.0->-r requirements.txt (line 4)) (2.3.0)\n",
      "  \u001b[31m   \u001b[0m Requirement already satisfied: nvidia-nvjitlink-cu12 in /opt/conda/lib/python3.11/site-packages (from nvidia-cusolver-cu12==11.4.5.107->torch>=2.0.0->-r requirements.txt (line 4)) (12.3.101)\n",
      "  \u001b[31m   \u001b[0m Requirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.11/site-packages (from transformers>=4.47.1->-r requirements.txt (line 6)) (2024.5.15)\n",
      "  \u001b[31m   \u001b[0m Requirement already satisfied: tokenizers<0.22,>=0.21 in /opt/conda/lib/python3.11/site-packages (from transformers>=4.47.1->-r requirements.txt (line 6)) (0.21.0)\n",
      "  \u001b[31m   \u001b[0m Requirement already satisfied: aiosignal>=1.1.2 in /opt/conda/lib/python3.11/site-packages (from aiohttp->datasets>=3.1.0->-r requirements.txt (line 2)) (1.3.1)\n",
      "  \u001b[31m   \u001b[0m Requirement already satisfied: attrs>=17.3.0 in /opt/conda/lib/python3.11/site-packages (from aiohttp->datasets>=3.1.0->-r requirements.txt (line 2)) (23.2.0)\n",
      "  \u001b[31m   \u001b[0m Requirement already satisfied: frozenlist>=1.1.1 in /opt/conda/lib/python3.11/site-packages (from aiohttp->datasets>=3.1.0->-r requirements.txt (line 2)) (1.4.1)\n",
      "  \u001b[31m   \u001b[0m Requirement already satisfied: multidict<7.0,>=4.5 in /opt/conda/lib/python3.11/site-packages (from aiohttp->datasets>=3.1.0->-r requirements.txt (line 2)) (6.0.5)\n",
      "  \u001b[31m   \u001b[0m Requirement already satisfied: yarl<2.0,>=1.0 in /opt/conda/lib/python3.11/site-packages (from aiohttp->datasets>=3.1.0->-r requirements.txt (line 2)) (1.9.4)\n",
      "  \u001b[31m   \u001b[0m Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.11/site-packages (from requests>=2.32.2->datasets>=3.1.0->-r requirements.txt (line 2)) (3.3.2)\n",
      "  \u001b[31m   \u001b[0m Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.11/site-packages (from requests>=2.32.2->datasets>=3.1.0->-r requirements.txt (line 2)) (3.7)\n",
      "  \u001b[31m   \u001b[0m Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.11/site-packages (from requests>=2.32.2->datasets>=3.1.0->-r requirements.txt (line 2)) (2.2.1)\n",
      "  \u001b[31m   \u001b[0m Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.11/site-packages (from requests>=2.32.2->datasets>=3.1.0->-r requirements.txt (line 2)) (2024.2.2)\n",
      "  \u001b[31m   \u001b[0m Requirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.11/site-packages (from jinja2->torch>=2.0.0->-r requirements.txt (line 4)) (2.1.5)\n",
      "  \u001b[31m   \u001b[0m Requirement already satisfied: python-dateutil>=2.8.2 in /opt/conda/lib/python3.11/site-packages (from pandas->datasets>=3.1.0->-r requirements.txt (line 2)) (2.9.0)\n",
      "  \u001b[31m   \u001b[0m Requirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.11/site-packages (from pandas->datasets>=3.1.0->-r requirements.txt (line 2)) (2024.1)\n",
      "  \u001b[31m   \u001b[0m Requirement already satisfied: tzdata>=2022.7 in /opt/conda/lib/python3.11/site-packages (from pandas->datasets>=3.1.0->-r requirements.txt (line 2)) (2024.1)\n",
      "  \u001b[31m   \u001b[0m Requirement already satisfied: mpmath>=0.19 in /opt/conda/lib/python3.11/site-packages (from sympy->torch>=2.0.0->-r requirements.txt (line 4)) (1.3.0)\n",
      "  \u001b[31m   \u001b[0m Requirement already satisfied: six>=1.5 in /opt/conda/lib/python3.11/site-packages (from python-dateutil>=2.8.2->pandas->datasets>=3.1.0->-r requirements.txt (line 2)) (1.16.0)\n",
      "  \u001b[31m   \u001b[0m conda_cuda_include_dir /opt/conda/lib/python3.11/site-packages/nvidia/cuda_runtime/include\n",
      "  \u001b[31m   \u001b[0m appending conda cuda include dir /opt/conda/lib/python3.11/site-packages/nvidia/cuda_runtime/include\n",
      "  \u001b[31m   \u001b[0m marlin kernel only supports compute capability >= 8.0, there's no such cuda device, skipped.\n",
      "  \u001b[31m   \u001b[0m running bdist_wheel\n",
      "  \u001b[31m   \u001b[0m /opt/conda/lib/python3.11/site-packages/torch/utils/cpp_extension.py:499: UserWarning: Attempted to use ninja as the BuildExtension backend but we could not find ninja.. Falling back to using the slow distutils backend.\n",
      "  \u001b[31m   \u001b[0m   warnings.warn(msg.format('we could not find ninja.'))\n",
      "  \u001b[31m   \u001b[0m running build\n",
      "  \u001b[31m   \u001b[0m running build_py\n",
      "  \u001b[31m   \u001b[0m creating build\n",
      "  \u001b[31m   \u001b[0m creating build/lib.linux-x86_64-cpython-311\n",
      "  \u001b[31m   \u001b[0m creating build/lib.linux-x86_64-cpython-311/gptqmodel\n",
      "  \u001b[31m   \u001b[0m copying gptqmodel/__init__.py -> build/lib.linux-x86_64-cpython-311/gptqmodel\n",
      "  \u001b[31m   \u001b[0m copying gptqmodel/version.py -> build/lib.linux-x86_64-cpython-311/gptqmodel\n",
      "  \u001b[31m   \u001b[0m creating build/lib.linux-x86_64-cpython-311/gptqmodel/integration\n",
      "  \u001b[31m   \u001b[0m copying gptqmodel/integration/__init__.py -> build/lib.linux-x86_64-cpython-311/gptqmodel/integration\n",
      "  \u001b[31m   \u001b[0m copying gptqmodel/integration/integration.py -> build/lib.linux-x86_64-cpython-311/gptqmodel/integration\n",
      "  \u001b[31m   \u001b[0m copying gptqmodel/integration/integration_vllm.py -> build/lib.linux-x86_64-cpython-311/gptqmodel/integration\n",
      "  \u001b[31m   \u001b[0m creating build/lib.linux-x86_64-cpython-311/gptqmodel/models\n",
      "  \u001b[31m   \u001b[0m copying gptqmodel/models/__init__.py -> build/lib.linux-x86_64-cpython-311/gptqmodel/models\n",
      "  \u001b[31m   \u001b[0m copying gptqmodel/models/_const.py -> build/lib.linux-x86_64-cpython-311/gptqmodel/models\n",
      "  \u001b[31m   \u001b[0m copying gptqmodel/models/auto.py -> build/lib.linux-x86_64-cpython-311/gptqmodel/models\n",
      "  \u001b[31m   \u001b[0m copying gptqmodel/models/base.py -> build/lib.linux-x86_64-cpython-311/gptqmodel/models\n",
      "  \u001b[31m   \u001b[0m copying gptqmodel/models/loader.py -> build/lib.linux-x86_64-cpython-311/gptqmodel/models\n",
      "  \u001b[31m   \u001b[0m copying gptqmodel/models/writer.py -> build/lib.linux-x86_64-cpython-311/gptqmodel/models\n",
      "  \u001b[31m   \u001b[0m creating build/lib.linux-x86_64-cpython-311/gptqmodel/nn_modules\n",
      "  \u001b[31m   \u001b[0m copying gptqmodel/nn_modules/__init__.py -> build/lib.linux-x86_64-cpython-311/gptqmodel/nn_modules\n",
      "  \u001b[31m   \u001b[0m copying gptqmodel/nn_modules/hooked_linear.py -> build/lib.linux-x86_64-cpython-311/gptqmodel/nn_modules\n",
      "  \u001b[31m   \u001b[0m creating build/lib.linux-x86_64-cpython-311/gptqmodel/quantization\n",
      "  \u001b[31m   \u001b[0m copying gptqmodel/quantization/__init__.py -> build/lib.linux-x86_64-cpython-311/gptqmodel/quantization\n",
      "  \u001b[31m   \u001b[0m copying gptqmodel/quantization/config.py -> build/lib.linux-x86_64-cpython-311/gptqmodel/quantization\n",
      "  \u001b[31m   \u001b[0m copying gptqmodel/quantization/gptq.py -> build/lib.linux-x86_64-cpython-311/gptqmodel/quantization\n",
      "  \u001b[31m   \u001b[0m copying gptqmodel/quantization/quantizer.py -> build/lib.linux-x86_64-cpython-311/gptqmodel/quantization\n",
      "  \u001b[31m   \u001b[0m creating build/lib.linux-x86_64-cpython-311/gptqmodel/utils\n",
      "  \u001b[31m   \u001b[0m copying gptqmodel/utils/__init__.py -> build/lib.linux-x86_64-cpython-311/gptqmodel/utils\n",
      "  \u001b[31m   \u001b[0m copying gptqmodel/utils/backend.py -> build/lib.linux-x86_64-cpython-311/gptqmodel/utils\n",
      "  \u001b[31m   \u001b[0m copying gptqmodel/utils/bitblas.py -> build/lib.linux-x86_64-cpython-311/gptqmodel/utils\n",
      "  \u001b[31m   \u001b[0m copying gptqmodel/utils/calibration.py -> build/lib.linux-x86_64-cpython-311/gptqmodel/utils\n",
      "  \u001b[31m   \u001b[0m copying gptqmodel/utils/data.py -> build/lib.linux-x86_64-cpython-311/gptqmodel/utils\n",
      "  \u001b[31m   \u001b[0m copying gptqmodel/utils/device.py -> build/lib.linux-x86_64-cpython-311/gptqmodel/utils\n",
      "  \u001b[31m   \u001b[0m copying gptqmodel/utils/eval.py -> build/lib.linux-x86_64-cpython-311/gptqmodel/utils\n",
      "  \u001b[31m   \u001b[0m copying gptqmodel/utils/exllama.py -> build/lib.linux-x86_64-cpython-311/gptqmodel/utils\n",
      "  \u001b[31m   \u001b[0m copying gptqmodel/utils/image.py -> build/lib.linux-x86_64-cpython-311/gptqmodel/utils\n",
      "  \u001b[31m   \u001b[0m copying gptqmodel/utils/importer.py -> build/lib.linux-x86_64-cpython-311/gptqmodel/utils\n",
      "  \u001b[31m   \u001b[0m copying gptqmodel/utils/logger.py -> build/lib.linux-x86_64-cpython-311/gptqmodel/utils\n",
      "  \u001b[31m   \u001b[0m copying gptqmodel/utils/marlin.py -> build/lib.linux-x86_64-cpython-311/gptqmodel/utils\n",
      "  \u001b[31m   \u001b[0m copying gptqmodel/utils/mlx.py -> build/lib.linux-x86_64-cpython-311/gptqmodel/utils\n",
      "  \u001b[31m   \u001b[0m copying gptqmodel/utils/model.py -> build/lib.linux-x86_64-cpython-311/gptqmodel/utils\n",
      "  \u001b[31m   \u001b[0m copying gptqmodel/utils/openai_server.py -> build/lib.linux-x86_64-cpython-311/gptqmodel/utils\n",
      "  \u001b[31m   \u001b[0m copying gptqmodel/utils/perplexity.py -> build/lib.linux-x86_64-cpython-311/gptqmodel/utils\n",
      "  \u001b[31m   \u001b[0m copying gptqmodel/utils/plotly.py -> build/lib.linux-x86_64-cpython-311/gptqmodel/utils\n",
      "  \u001b[31m   \u001b[0m copying gptqmodel/utils/progress.py -> build/lib.linux-x86_64-cpython-311/gptqmodel/utils\n",
      "  \u001b[31m   \u001b[0m copying gptqmodel/utils/rocm.py -> build/lib.linux-x86_64-cpython-311/gptqmodel/utils\n",
      "  \u001b[31m   \u001b[0m copying gptqmodel/utils/sglang.py -> build/lib.linux-x86_64-cpython-311/gptqmodel/utils\n",
      "  \u001b[31m   \u001b[0m copying gptqmodel/utils/tensor.py -> build/lib.linux-x86_64-cpython-311/gptqmodel/utils\n",
      "  \u001b[31m   \u001b[0m copying gptqmodel/utils/torch.py -> build/lib.linux-x86_64-cpython-311/gptqmodel/utils\n",
      "  \u001b[31m   \u001b[0m copying gptqmodel/utils/vllm.py -> build/lib.linux-x86_64-cpython-311/gptqmodel/utils\n",
      "  \u001b[31m   \u001b[0m copying gptqmodel/utils/vram.py -> build/lib.linux-x86_64-cpython-311/gptqmodel/utils\n",
      "  \u001b[31m   \u001b[0m creating build/lib.linux-x86_64-cpython-311/gptqmodel/integration/src\n",
      "  \u001b[31m   \u001b[0m copying gptqmodel/integration/src/__init__.py -> build/lib.linux-x86_64-cpython-311/gptqmodel/integration/src\n",
      "  \u001b[31m   \u001b[0m creating build/lib.linux-x86_64-cpython-311/gptqmodel/integration/src/optimum\n",
      "  \u001b[31m   \u001b[0m copying gptqmodel/integration/src/optimum/__init__.py -> build/lib.linux-x86_64-cpython-311/gptqmodel/integration/src/optimum\n",
      "  \u001b[31m   \u001b[0m creating build/lib.linux-x86_64-cpython-311/gptqmodel/integration/src/peft\n",
      "  \u001b[31m   \u001b[0m copying gptqmodel/integration/src/peft/__init__.py -> build/lib.linux-x86_64-cpython-311/gptqmodel/integration/src/peft\n",
      "  \u001b[31m   \u001b[0m copying gptqmodel/integration/src/peft/import_utils.py -> build/lib.linux-x86_64-cpython-311/gptqmodel/integration/src/peft\n",
      "  \u001b[31m   \u001b[0m creating build/lib.linux-x86_64-cpython-311/gptqmodel/integration/src/transformers\n",
      "  \u001b[31m   \u001b[0m copying gptqmodel/integration/src/transformers/__init__.py -> build/lib.linux-x86_64-cpython-311/gptqmodel/integration/src/transformers\n",
      "  \u001b[31m   \u001b[0m copying gptqmodel/integration/src/transformers/testing_utils.py -> build/lib.linux-x86_64-cpython-311/gptqmodel/integration/src/transformers\n",
      "  \u001b[31m   \u001b[0m creating build/lib.linux-x86_64-cpython-311/gptqmodel/integration/src/vllm\n",
      "  \u001b[31m   \u001b[0m copying gptqmodel/integration/src/vllm/__init__.py -> build/lib.linux-x86_64-cpython-311/gptqmodel/integration/src/vllm\n",
      "  \u001b[31m   \u001b[0m copying gptqmodel/integration/src/vllm/gptq_marlin.py -> build/lib.linux-x86_64-cpython-311/gptqmodel/integration/src/vllm\n",
      "  \u001b[31m   \u001b[0m creating build/lib.linux-x86_64-cpython-311/gptqmodel/integration/src/optimum/gptq\n",
      "  \u001b[31m   \u001b[0m copying gptqmodel/integration/src/optimum/gptq/__init__.py -> build/lib.linux-x86_64-cpython-311/gptqmodel/integration/src/optimum/gptq\n",
      "  \u001b[31m   \u001b[0m copying gptqmodel/integration/src/optimum/gptq/quantizer.py -> build/lib.linux-x86_64-cpython-311/gptqmodel/integration/src/optimum/gptq\n",
      "  \u001b[31m   \u001b[0m copying gptqmodel/integration/src/optimum/gptq/utils.py -> build/lib.linux-x86_64-cpython-311/gptqmodel/integration/src/optimum/gptq\n",
      "  \u001b[31m   \u001b[0m creating build/lib.linux-x86_64-cpython-311/gptqmodel/integration/src/optimum/utils\n",
      "  \u001b[31m   \u001b[0m copying gptqmodel/integration/src/optimum/utils/__init__.py -> build/lib.linux-x86_64-cpython-311/gptqmodel/integration/src/optimum/utils\n",
      "  \u001b[31m   \u001b[0m copying gptqmodel/integration/src/optimum/utils/import_utils.py -> build/lib.linux-x86_64-cpython-311/gptqmodel/integration/src/optimum/utils\n",
      "  \u001b[31m   \u001b[0m copying gptqmodel/integration/src/optimum/utils/testing_utils.py -> build/lib.linux-x86_64-cpython-311/gptqmodel/integration/src/optimum/utils\n",
      "  \u001b[31m   \u001b[0m creating build/lib.linux-x86_64-cpython-311/gptqmodel/integration/src/peft/tuners\n",
      "  \u001b[31m   \u001b[0m copying gptqmodel/integration/src/peft/tuners/__init__.py -> build/lib.linux-x86_64-cpython-311/gptqmodel/integration/src/peft/tuners\n",
      "  \u001b[31m   \u001b[0m creating build/lib.linux-x86_64-cpython-311/gptqmodel/integration/src/peft/utils\n",
      "  \u001b[31m   \u001b[0m copying gptqmodel/integration/src/peft/utils/__init__.py -> build/lib.linux-x86_64-cpython-311/gptqmodel/integration/src/peft/utils\n",
      "  \u001b[31m   \u001b[0m copying gptqmodel/integration/src/peft/utils/other.py -> build/lib.linux-x86_64-cpython-311/gptqmodel/integration/src/peft/utils\n",
      "  \u001b[31m   \u001b[0m creating build/lib.linux-x86_64-cpython-311/gptqmodel/integration/src/peft/tuners/adalora\n",
      "  \u001b[31m   \u001b[0m copying gptqmodel/integration/src/peft/tuners/adalora/__init__.py -> build/lib.linux-x86_64-cpython-311/gptqmodel/integration/src/peft/tuners/adalora\n",
      "  \u001b[31m   \u001b[0m copying gptqmodel/integration/src/peft/tuners/adalora/model.py -> build/lib.linux-x86_64-cpython-311/gptqmodel/integration/src/peft/tuners/adalora\n",
      "  \u001b[31m   \u001b[0m creating build/lib.linux-x86_64-cpython-311/gptqmodel/integration/src/peft/tuners/lora\n",
      "  \u001b[31m   \u001b[0m copying gptqmodel/integration/src/peft/tuners/lora/__init__.py -> build/lib.linux-x86_64-cpython-311/gptqmodel/integration/src/peft/tuners/lora\n",
      "  \u001b[31m   \u001b[0m copying gptqmodel/integration/src/peft/tuners/lora/gptq.py -> build/lib.linux-x86_64-cpython-311/gptqmodel/integration/src/peft/tuners/lora\n",
      "  \u001b[31m   \u001b[0m copying gptqmodel/integration/src/peft/tuners/lora/model.py -> build/lib.linux-x86_64-cpython-311/gptqmodel/integration/src/peft/tuners/lora\n",
      "  \u001b[31m   \u001b[0m creating build/lib.linux-x86_64-cpython-311/gptqmodel/integration/src/transformers/quantizers\n",
      "  \u001b[31m   \u001b[0m copying gptqmodel/integration/src/transformers/quantizers/__init__.py -> build/lib.linux-x86_64-cpython-311/gptqmodel/integration/src/transformers/quantizers\n",
      "  \u001b[31m   \u001b[0m copying gptqmodel/integration/src/transformers/quantizers/quantizer_gptq.py -> build/lib.linux-x86_64-cpython-311/gptqmodel/integration/src/transformers/quantizers\n",
      "  \u001b[31m   \u001b[0m creating build/lib.linux-x86_64-cpython-311/gptqmodel/integration/src/transformers/utils\n",
      "  \u001b[31m   \u001b[0m copying gptqmodel/integration/src/transformers/utils/__init__.py -> build/lib.linux-x86_64-cpython-311/gptqmodel/integration/src/transformers/utils\n",
      "  \u001b[31m   \u001b[0m copying gptqmodel/integration/src/transformers/utils/import_utils.py -> build/lib.linux-x86_64-cpython-311/gptqmodel/integration/src/transformers/utils\n",
      "  \u001b[31m   \u001b[0m copying gptqmodel/integration/src/transformers/utils/quantization_config.py -> build/lib.linux-x86_64-cpython-311/gptqmodel/integration/src/transformers/utils\n",
      "  \u001b[31m   \u001b[0m creating build/lib.linux-x86_64-cpython-311/gptqmodel/models/definitions\n",
      "  \u001b[31m   \u001b[0m copying gptqmodel/models/definitions/__init__.py -> build/lib.linux-x86_64-cpython-311/gptqmodel/models/definitions\n",
      "  \u001b[31m   \u001b[0m copying gptqmodel/models/definitions/baichuan.py -> build/lib.linux-x86_64-cpython-311/gptqmodel/models/definitions\n",
      "  \u001b[31m   \u001b[0m copying gptqmodel/models/definitions/bloom.py -> build/lib.linux-x86_64-cpython-311/gptqmodel/models/definitions\n",
      "  \u001b[31m   \u001b[0m copying gptqmodel/models/definitions/chatglm.py -> build/lib.linux-x86_64-cpython-311/gptqmodel/models/definitions\n",
      "  \u001b[31m   \u001b[0m copying gptqmodel/models/definitions/codegen.py -> build/lib.linux-x86_64-cpython-311/gptqmodel/models/definitions\n",
      "  \u001b[31m   \u001b[0m copying gptqmodel/models/definitions/cohere.py -> build/lib.linux-x86_64-cpython-311/gptqmodel/models/definitions\n",
      "  \u001b[31m   \u001b[0m copying gptqmodel/models/definitions/cohere2.py -> build/lib.linux-x86_64-cpython-311/gptqmodel/models/definitions\n",
      "  \u001b[31m   \u001b[0m copying gptqmodel/models/definitions/dbrx.py -> build/lib.linux-x86_64-cpython-311/gptqmodel/models/definitions\n",
      "  \u001b[31m   \u001b[0m copying gptqmodel/models/definitions/dbrx_converted.py -> build/lib.linux-x86_64-cpython-311/gptqmodel/models/definitions\n",
      "  \u001b[31m   \u001b[0m copying gptqmodel/models/definitions/decilm.py -> build/lib.linux-x86_64-cpython-311/gptqmodel/models/definitions\n",
      "  \u001b[31m   \u001b[0m copying gptqmodel/models/definitions/deepseek_v2.py -> build/lib.linux-x86_64-cpython-311/gptqmodel/models/definitions\n",
      "  \u001b[31m   \u001b[0m copying gptqmodel/models/definitions/exaone.py -> build/lib.linux-x86_64-cpython-311/gptqmodel/models/definitions\n",
      "  \u001b[31m   \u001b[0m copying gptqmodel/models/definitions/gemma.py -> build/lib.linux-x86_64-cpython-311/gptqmodel/models/definitions\n",
      "  \u001b[31m   \u001b[0m copying gptqmodel/models/definitions/gemma2.py -> build/lib.linux-x86_64-cpython-311/gptqmodel/models/definitions\n",
      "  \u001b[31m   \u001b[0m copying gptqmodel/models/definitions/glm.py -> build/lib.linux-x86_64-cpython-311/gptqmodel/models/definitions\n",
      "  \u001b[31m   \u001b[0m copying gptqmodel/models/definitions/gpt2.py -> build/lib.linux-x86_64-cpython-311/gptqmodel/models/definitions\n",
      "  \u001b[31m   \u001b[0m copying gptqmodel/models/definitions/gpt_bigcode.py -> build/lib.linux-x86_64-cpython-311/gptqmodel/models/definitions\n",
      "  \u001b[31m   \u001b[0m copying gptqmodel/models/definitions/gpt_neox.py -> build/lib.linux-x86_64-cpython-311/gptqmodel/models/definitions\n",
      "  \u001b[31m   \u001b[0m copying gptqmodel/models/definitions/gptj.py -> build/lib.linux-x86_64-cpython-311/gptqmodel/models/definitions\n",
      "  \u001b[31m   \u001b[0m copying gptqmodel/models/definitions/granite.py -> build/lib.linux-x86_64-cpython-311/gptqmodel/models/definitions\n",
      "  \u001b[31m   \u001b[0m copying gptqmodel/models/definitions/grinmoe.py -> build/lib.linux-x86_64-cpython-311/gptqmodel/models/definitions\n",
      "  \u001b[31m   \u001b[0m copying gptqmodel/models/definitions/hymba.py -> build/lib.linux-x86_64-cpython-311/gptqmodel/models/definitions\n",
      "  \u001b[31m   \u001b[0m copying gptqmodel/models/definitions/internlm.py -> build/lib.linux-x86_64-cpython-311/gptqmodel/models/definitions\n",
      "  \u001b[31m   \u001b[0m copying gptqmodel/models/definitions/internlm2.py -> build/lib.linux-x86_64-cpython-311/gptqmodel/models/definitions\n",
      "  \u001b[31m   \u001b[0m copying gptqmodel/models/definitions/llama.py -> build/lib.linux-x86_64-cpython-311/gptqmodel/models/definitions\n",
      "  \u001b[31m   \u001b[0m copying gptqmodel/models/definitions/longllama.py -> build/lib.linux-x86_64-cpython-311/gptqmodel/models/definitions\n",
      "  \u001b[31m   \u001b[0m copying gptqmodel/models/definitions/minicpm.py -> build/lib.linux-x86_64-cpython-311/gptqmodel/models/definitions\n",
      "  \u001b[31m   \u001b[0m copying gptqmodel/models/definitions/minicpm3.py -> build/lib.linux-x86_64-cpython-311/gptqmodel/models/definitions\n",
      "  \u001b[31m   \u001b[0m copying gptqmodel/models/definitions/mistral.py -> build/lib.linux-x86_64-cpython-311/gptqmodel/models/definitions\n",
      "  \u001b[31m   \u001b[0m copying gptqmodel/models/definitions/mixtral.py -> build/lib.linux-x86_64-cpython-311/gptqmodel/models/definitions\n",
      "  \u001b[31m   \u001b[0m copying gptqmodel/models/definitions/mllama.py -> build/lib.linux-x86_64-cpython-311/gptqmodel/models/definitions\n",
      "  \u001b[31m   \u001b[0m copying gptqmodel/models/definitions/mobilellm.py -> build/lib.linux-x86_64-cpython-311/gptqmodel/models/definitions\n",
      "  \u001b[31m   \u001b[0m copying gptqmodel/models/definitions/moss.py -> build/lib.linux-x86_64-cpython-311/gptqmodel/models/definitions\n",
      "  \u001b[31m   \u001b[0m copying gptqmodel/models/definitions/mpt.py -> build/lib.linux-x86_64-cpython-311/gptqmodel/models/definitions\n",
      "  \u001b[31m   \u001b[0m copying gptqmodel/models/definitions/olmo2.py -> build/lib.linux-x86_64-cpython-311/gptqmodel/models/definitions\n",
      "  \u001b[31m   \u001b[0m copying gptqmodel/models/definitions/opt.py -> build/lib.linux-x86_64-cpython-311/gptqmodel/models/definitions\n",
      "  \u001b[31m   \u001b[0m copying gptqmodel/models/definitions/ovis.py -> build/lib.linux-x86_64-cpython-311/gptqmodel/models/definitions\n",
      "  \u001b[31m   \u001b[0m copying gptqmodel/models/definitions/phi.py -> build/lib.linux-x86_64-cpython-311/gptqmodel/models/definitions\n",
      "  \u001b[31m   \u001b[0m copying gptqmodel/models/definitions/phi3.py -> build/lib.linux-x86_64-cpython-311/gptqmodel/models/definitions\n",
      "  \u001b[31m   \u001b[0m copying gptqmodel/models/definitions/qwen.py -> build/lib.linux-x86_64-cpython-311/gptqmodel/models/definitions\n",
      "  \u001b[31m   \u001b[0m copying gptqmodel/models/definitions/qwen2.py -> build/lib.linux-x86_64-cpython-311/gptqmodel/models/definitions\n",
      "  \u001b[31m   \u001b[0m copying gptqmodel/models/definitions/qwen2_moe.py -> build/lib.linux-x86_64-cpython-311/gptqmodel/models/definitions\n",
      "  \u001b[31m   \u001b[0m copying gptqmodel/models/definitions/qwen2_vl.py -> build/lib.linux-x86_64-cpython-311/gptqmodel/models/definitions\n",
      "  \u001b[31m   \u001b[0m copying gptqmodel/models/definitions/rw.py -> build/lib.linux-x86_64-cpython-311/gptqmodel/models/definitions\n",
      "  \u001b[31m   \u001b[0m copying gptqmodel/models/definitions/stablelmepoch.py -> build/lib.linux-x86_64-cpython-311/gptqmodel/models/definitions\n",
      "  \u001b[31m   \u001b[0m copying gptqmodel/models/definitions/starcoder2.py -> build/lib.linux-x86_64-cpython-311/gptqmodel/models/definitions\n",
      "  \u001b[31m   \u001b[0m copying gptqmodel/models/definitions/telechat2.py -> build/lib.linux-x86_64-cpython-311/gptqmodel/models/definitions\n",
      "  \u001b[31m   \u001b[0m copying gptqmodel/models/definitions/xverse.py -> build/lib.linux-x86_64-cpython-311/gptqmodel/models/definitions\n",
      "  \u001b[31m   \u001b[0m copying gptqmodel/models/definitions/yi.py -> build/lib.linux-x86_64-cpython-311/gptqmodel/models/definitions\n",
      "  \u001b[31m   \u001b[0m creating build/lib.linux-x86_64-cpython-311/gptqmodel/nn_modules/qlinear\n",
      "  \u001b[31m   \u001b[0m copying gptqmodel/nn_modules/qlinear/__init__.py -> build/lib.linux-x86_64-cpython-311/gptqmodel/nn_modules/qlinear\n",
      "  \u001b[31m   \u001b[0m copying gptqmodel/nn_modules/qlinear/bitblas.py -> build/lib.linux-x86_64-cpython-311/gptqmodel/nn_modules/qlinear\n",
      "  \u001b[31m   \u001b[0m copying gptqmodel/nn_modules/qlinear/bitblas_target_detector.py -> build/lib.linux-x86_64-cpython-311/gptqmodel/nn_modules/qlinear\n",
      "  \u001b[31m   \u001b[0m copying gptqmodel/nn_modules/qlinear/dynamic_cuda.py -> build/lib.linux-x86_64-cpython-311/gptqmodel/nn_modules/qlinear\n",
      "  \u001b[31m   \u001b[0m copying gptqmodel/nn_modules/qlinear/exllama.py -> build/lib.linux-x86_64-cpython-311/gptqmodel/nn_modules/qlinear\n",
      "  \u001b[31m   \u001b[0m copying gptqmodel/nn_modules/qlinear/exllamav2.py -> build/lib.linux-x86_64-cpython-311/gptqmodel/nn_modules/qlinear\n",
      "  \u001b[31m   \u001b[0m copying gptqmodel/nn_modules/qlinear/ipex.py -> build/lib.linux-x86_64-cpython-311/gptqmodel/nn_modules/qlinear\n",
      "  \u001b[31m   \u001b[0m copying gptqmodel/nn_modules/qlinear/marlin.py -> build/lib.linux-x86_64-cpython-311/gptqmodel/nn_modules/qlinear\n",
      "  \u001b[31m   \u001b[0m copying gptqmodel/nn_modules/qlinear/torch.py -> build/lib.linux-x86_64-cpython-311/gptqmodel/nn_modules/qlinear\n",
      "  \u001b[31m   \u001b[0m copying gptqmodel/nn_modules/qlinear/tritonv2.py -> build/lib.linux-x86_64-cpython-311/gptqmodel/nn_modules/qlinear\n",
      "  \u001b[31m   \u001b[0m copying gptqmodel/nn_modules/qlinear/utils.py -> build/lib.linux-x86_64-cpython-311/gptqmodel/nn_modules/qlinear\n",
      "  \u001b[31m   \u001b[0m creating build/lib.linux-x86_64-cpython-311/gptqmodel/nn_modules/triton_utils\n",
      "  \u001b[31m   \u001b[0m copying gptqmodel/nn_modules/triton_utils/__init__.py -> build/lib.linux-x86_64-cpython-311/gptqmodel/nn_modules/triton_utils\n",
      "  \u001b[31m   \u001b[0m copying gptqmodel/nn_modules/triton_utils/custom_autotune.py -> build/lib.linux-x86_64-cpython-311/gptqmodel/nn_modules/triton_utils\n",
      "  \u001b[31m   \u001b[0m copying gptqmodel/nn_modules/triton_utils/dequant.py -> build/lib.linux-x86_64-cpython-311/gptqmodel/nn_modules/triton_utils\n",
      "  \u001b[31m   \u001b[0m copying gptqmodel/nn_modules/triton_utils/kernels.py -> build/lib.linux-x86_64-cpython-311/gptqmodel/nn_modules/triton_utils\n",
      "  \u001b[31m   \u001b[0m copying gptqmodel/nn_modules/triton_utils/mixin.py -> build/lib.linux-x86_64-cpython-311/gptqmodel/nn_modules/triton_utils\n",
      "  \u001b[31m   \u001b[0m running build_ext\n",
      "  \u001b[31m   \u001b[0m error: [Errno 2] No such file or directory: '/usr/local/cuda-12.4/bin/nvcc'\n",
      "  \u001b[31m   \u001b[0m \u001b[31m[end of output]\u001b[0m\n",
      "  \n",
      "  \u001b[1;35mnote\u001b[0m: This error originates from a subprocess, and is likely not a problem with pip.\n",
      "\u001b[31m  ERROR: Failed building wheel for gptqmodel\u001b[0m\u001b[31m\n",
      "\u001b[0m\u001b[?25h  Running setup.py clean for gptqmodel\n",
      "Failed to build gptqmodel\n",
      "\u001b[31mERROR: Could not build wheels for gptqmodel, which is required to install pyproject.toml-based projects\u001b[0m\u001b[31m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!pip install gptqmodel --no-build-isolation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7f89bcca-ff67-46b5-8318-d3e408c05865",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "853.16s - pydevd: Sending message related to process being replaced timed-out after 5 seconds\n",
      "Usage: pip [options]\n",
      "\n",
      "\u001b[31mERROR: Invalid requirement: gptqmodel --no-build-isolation\n",
      "pip: error: no such option: --no-build-isolation\n",
      "\u001b[0m\u001b[31m\n",
      "\u001b[0m858.75s - pydevd: Sending message related to process being replaced timed-out after 5 seconds\n",
      "863.88s - pydevd: Sending message related to process being replaced timed-out after 5 seconds\n",
      "869.01s - pydevd: Sending message related to process being replaced timed-out after 5 seconds\n"
     ]
    }
   ],
   "source": [
    "YAML_secqa_string = \"\"\"\n",
    "task: secqa\n",
    "dataset_path: zefang-liu/secqa\n",
    "dataset_name: secqa_v1\n",
    "output_type: multiple_choice\n",
    "training_split: dev\n",
    "validation_split: val\n",
    "test_split: test\n",
    "doc_to_text: \"{{Question}}\\nA) {{A}}\\nB) {{B}}\\nC) {{C}}\\nD) {{D}}\\nWhat is the correct answer? Use only the letter.\"\n",
    "doc_to_target: Answer\n",
    "doc_to_choice: [\"A\",\"B\",\"C\",\"D\"]\n",
    "should_decontaminate: true\n",
    "doc_to_decontamination_query: passage\n",
    "output_type: multiple_choice\n",
    "metric_list:\n",
    "  - metric: acc\n",
    "\"\"\"\n",
    "with open(\"secqa.yaml\", \"w\") as f:\n",
    "    f.write(YAML_secqa_string)\n",
    "\n",
    "\n",
    "!mkdir -p /opt/conda/lib/python3.11/site-packages/lm_eval/tasks/secqa\n",
    "!cp /home/jovyan/secqa.yaml /opt/conda/lib/python3.11/site-packages/lm_eval/tasks/secqa/\n",
    "\n",
    "\n",
    "!export GIT_DISCOVERY_ACROSS_FILESYSTEM=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0970c0a9-95de-4328-8feb-166cff48cc30",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-02-24 17:19:35.264104: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2025-02-24 17:19:36.689710: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "2025-02-24:17:19:39,452 INFO     [lm_eval.__main__:307] Including path: /opt/conda/lib/python3.11/site-packages/lm_eval/tasks/\n",
      "2025-02-24:17:19:44,224 DEBUG    [lm_eval.tasks:523] File _evalita-mp_ner_adg.yaml in /opt/conda/lib/python3.11/site-packages/lm_eval/tasks/evalita_llm could not be loaded\n",
      "2025-02-24:17:19:44,230 DEBUG    [lm_eval.tasks:523] File _evalita-mp_ner_fic.yaml in /opt/conda/lib/python3.11/site-packages/lm_eval/tasks/evalita_llm could not be loaded\n",
      "2025-02-24:17:19:44,237 DEBUG    [lm_eval.tasks:523] File _evalita-mp_ner_wn.yaml in /opt/conda/lib/python3.11/site-packages/lm_eval/tasks/evalita_llm could not be loaded\n",
      "2025-02-24:17:19:52,068 INFO     [lm_eval.tasks:460] The tag 'kobest' is already registered as a group, this tag will not be registered. This may affect tasks you want to call.\n",
      "2025-02-24:17:19:52,070 INFO     [lm_eval.tasks:460] The tag 'kobest' is already registered as a group, this tag will not be registered. This may affect tasks you want to call.\n",
      "2025-02-24:17:19:52,073 INFO     [lm_eval.tasks:460] The tag 'kobest' is already registered as a group, this tag will not be registered. This may affect tasks you want to call.\n",
      "2025-02-24:17:19:52,076 INFO     [lm_eval.tasks:460] The tag 'kobest' is already registered as a group, this tag will not be registered. This may affect tasks you want to call.\n",
      "2025-02-24:17:19:52,078 INFO     [lm_eval.tasks:460] The tag 'kobest' is already registered as a group, this tag will not be registered. This may affect tasks you want to call.\n",
      "2025-02-24:17:20:02,314 DEBUG    [lm_eval.tasks:523] File _evalita-mp_ner_adg.yaml in /opt/conda/lib/python3.11/site-packages/lm_eval/tasks/evalita_llm could not be loaded\n",
      "2025-02-24:17:20:02,319 DEBUG    [lm_eval.tasks:523] File _evalita-mp_ner_fic.yaml in /opt/conda/lib/python3.11/site-packages/lm_eval/tasks/evalita_llm could not be loaded\n",
      "2025-02-24:17:20:02,327 DEBUG    [lm_eval.tasks:523] File _evalita-mp_ner_wn.yaml in /opt/conda/lib/python3.11/site-packages/lm_eval/tasks/evalita_llm could not be loaded\n",
      "2025-02-24:17:20:10,170 INFO     [lm_eval.tasks:460] The tag 'kobest' is already registered as a group, this tag will not be registered. This may affect tasks you want to call.\n",
      "2025-02-24:17:20:10,173 INFO     [lm_eval.tasks:460] The tag 'kobest' is already registered as a group, this tag will not be registered. This may affect tasks you want to call.\n",
      "2025-02-24:17:20:10,176 INFO     [lm_eval.tasks:460] The tag 'kobest' is already registered as a group, this tag will not be registered. This may affect tasks you want to call.\n",
      "2025-02-24:17:20:10,178 INFO     [lm_eval.tasks:460] The tag 'kobest' is already registered as a group, this tag will not be registered. This may affect tasks you want to call.\n",
      "2025-02-24:17:20:10,181 INFO     [lm_eval.tasks:460] The tag 'kobest' is already registered as a group, this tag will not be registered. This may affect tasks you want to call.\n",
      "2025-02-24:17:20:15,632 WARNING  [lm_eval.__main__:316]  --limit SHOULD ONLY BE USED FOR TESTING.REAL METRICS SHOULD NOT BE COMPUTED USING LIMIT.\n",
      "0\n",
      "Selected Tasks: ['secqa']\n",
      "2025-02-24:17:20:15,637 INFO     [lm_eval.evaluator:169] Setting random seed to 0 | Setting numpy seed to 1234 | Setting torch manual seed to 1234 | Setting fewshot manual seed to 1234\n",
      "2025-02-24:17:20:15,637 INFO     [lm_eval.evaluator:206] Initializing hf model, with arguments: {'pretrained': 'TheBloke/TinyLlama-1.1B-Chat-v1.0-GPTQ', 'gptqmodel': True}\n",
      "2025-02-24:17:20:15,768 INFO     [lm_eval.models.huggingface:136] Using device 'cuda'\n",
      "2025-02-24:17:20:21,007 DEBUG    [lm_eval.models.huggingface:492] Using model type 'causal'\n",
      "2025-02-24:17:20:21,279 INFO     [lm_eval.models.huggingface:376] Model parallel was set to False, max memory was not set, and device map was set to {'': 'cuda'}\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.11/site-packages/lm_eval/models/huggingface.py\", line 622, in _create_model\n",
      "    from gptqmodel import GPTQModel\n",
      "ModuleNotFoundError: No module named 'gptqmodel'\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/bin/lm_eval\", line 8, in <module>\n",
      "    sys.exit(cli_evaluate())\n",
      "             ^^^^^^^^^^^^^^\n",
      "  File \"/opt/conda/lib/python3.11/site-packages/lm_eval/__main__.py\", line 388, in cli_evaluate\n",
      "    results = evaluator.simple_evaluate(\n",
      "              ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/conda/lib/python3.11/site-packages/lm_eval/utils.py\", line 422, in _wrapper\n",
      "    return fn(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/conda/lib/python3.11/site-packages/lm_eval/evaluator.py\", line 209, in simple_evaluate\n",
      "    lm = lm_eval.api.registry.get_model(model).create_from_arg_string(\n",
      "         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/conda/lib/python3.11/site-packages/lm_eval/api/model.py\", line 151, in create_from_arg_string\n",
      "    return cls(**args, **args2)\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/conda/lib/python3.11/site-packages/lm_eval/models/huggingface.py\", line 191, in __init__\n",
      "    self._create_model(\n",
      "  File \"/opt/conda/lib/python3.11/site-packages/lm_eval/models/huggingface.py\", line 624, in _create_model\n",
      "    raise type(exception)(\n",
      "ModuleNotFoundError: ('Tried to load gptqmodel, but gptqmodel is not installed ', 'please install gptqmodel via `pip install gptqmodel --no-build-isolation` or `pip install lm-eval[gptqmodel] --no-build-isolation`')\n"
     ]
    }
   ],
   "source": [
    "# TheBloke/TinyLlama-1.1B-Chat-v1.0-GPTQ\n",
    "!lm_eval \\\n",
    "    --model hf \\\n",
    "    --include_path /opt/conda/lib/python3.11/site-packages/lm_eval/tasks/ \\\n",
    "    --model_args pretrained=TheBloke/TinyLlama-1.1B-Chat-v1.0-GPTQ,gptqmodel=True \\\n",
    "    --tasks secqa \\\n",
    "    --limit 120 \\\n",
    "    --verbosity DEBUG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "9179bdf5-65de-474d-b396-1dcd1a60070c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-02-18 23:29:43.368286: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "2025-02-18:23:29:44,805 INFO     [__main__.py:284] Verbosity set to DEBUG\n",
      "2025-02-18:23:29:44,806 INFO     [__main__.py:308] Including path: /opt/conda/lib/python3.11/site-packages/lm_eval/tasks/\n",
      "2025-02-18:23:29:46,958 DEBUG    [__init__.py:522] File _evalita-mp_ner_adg.yaml in /opt/conda/lib/python3.11/site-packages/lm_eval/tasks/evalita_llm could not be loaded\n",
      "2025-02-18:23:29:46,961 DEBUG    [__init__.py:522] File _evalita-mp_ner_fic.yaml in /opt/conda/lib/python3.11/site-packages/lm_eval/tasks/evalita_llm could not be loaded\n",
      "2025-02-18:23:29:46,964 DEBUG    [__init__.py:522] File _evalita-mp_ner_wn.yaml in /opt/conda/lib/python3.11/site-packages/lm_eval/tasks/evalita_llm could not be loaded\n",
      "2025-02-18:23:29:50,494 INFO     [__init__.py:459] The tag 'kobest' is already registered as a group, this tag will not be registered. This may affect tasks you want to call.\n",
      "2025-02-18:23:29:50,495 INFO     [__init__.py:459] The tag 'kobest' is already registered as a group, this tag will not be registered. This may affect tasks you want to call.\n",
      "2025-02-18:23:29:50,497 INFO     [__init__.py:459] The tag 'kobest' is already registered as a group, this tag will not be registered. This may affect tasks you want to call.\n",
      "2025-02-18:23:29:50,498 INFO     [__init__.py:459] The tag 'kobest' is already registered as a group, this tag will not be registered. This may affect tasks you want to call.\n",
      "2025-02-18:23:29:50,499 INFO     [__init__.py:459] The tag 'kobest' is already registered as a group, this tag will not be registered. This may affect tasks you want to call.\n",
      "2025-02-18:23:29:55,110 DEBUG    [__init__.py:522] File _evalita-mp_ner_adg.yaml in /opt/conda/lib/python3.11/site-packages/lm_eval/tasks/evalita_llm could not be loaded\n",
      "2025-02-18:23:29:55,113 DEBUG    [__init__.py:522] File _evalita-mp_ner_fic.yaml in /opt/conda/lib/python3.11/site-packages/lm_eval/tasks/evalita_llm could not be loaded\n",
      "2025-02-18:23:29:55,116 DEBUG    [__init__.py:522] File _evalita-mp_ner_wn.yaml in /opt/conda/lib/python3.11/site-packages/lm_eval/tasks/evalita_llm could not be loaded\n",
      "2025-02-18:23:29:58,664 INFO     [__init__.py:459] The tag 'kobest' is already registered as a group, this tag will not be registered. This may affect tasks you want to call.\n",
      "2025-02-18:23:29:58,665 INFO     [__init__.py:459] The tag 'kobest' is already registered as a group, this tag will not be registered. This may affect tasks you want to call.\n",
      "2025-02-18:23:29:58,666 INFO     [__init__.py:459] The tag 'kobest' is already registered as a group, this tag will not be registered. This may affect tasks you want to call.\n",
      "2025-02-18:23:29:58,668 INFO     [__init__.py:459] The tag 'kobest' is already registered as a group, this tag will not be registered. This may affect tasks you want to call.\n",
      "2025-02-18:23:29:58,669 INFO     [__init__.py:459] The tag 'kobest' is already registered as a group, this tag will not be registered. This may affect tasks you want to call.\n",
      "2025-02-18:23:30:01,137 WARNING  [__main__.py:317]  --limit SHOULD ONLY BE USED FOR TESTING.REAL METRICS SHOULD NOT BE COMPUTED USING LIMIT.\n",
      "2025-02-18:23:30:01,138 INFO     [__main__.py:381] Selected Tasks: ['secqa']\n",
      "2025-02-18:23:30:01,140 INFO     [evaluator.py:165] Setting random seed to 0 | Setting numpy seed to 1234 | Setting torch manual seed to 1234 | Setting fewshot manual seed to 1234\n",
      "2025-02-18:23:30:01,140 INFO     [evaluator.py:202] Initializing hf model, with arguments: {'pretrained': 'TheBloke/Llama-2-7B-GPTQ', 'gptqmodel': True, 'device_map': 'auto'}\n",
      "2025-02-18:23:30:01,236 INFO     [huggingface.py:135] Using device 'cuda'\n",
      "2025-02-18:23:30:01,650 DEBUG    [huggingface.py:491] Using model type 'causal'\n",
      "You are using the default legacy behaviour of the <class 'transformers.models.llama.tokenization_llama_fast.LlamaTokenizerFast'>. This is expected, and simply means that the `legacy` (previous) behavior will be used so nothing changes for you. If you want to use the new behaviour, set `legacy=False`. This should only be set if you understand what it means, and thoroughly read the reason why this was added as explained in https://github.com/huggingface/transformers/pull/24565 - if you loaded a llama tokenizer from a GGUF file you can ignore this message.\n",
      "2025-02-18:23:30:01,848 INFO     [huggingface.py:381] Model parallel was set to False.\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/bin/lm_eval\", line 8, in <module>\n",
      "    sys.exit(cli_evaluate())\n",
      "             ^^^^^^^^^^^^^^\n",
      "  File \"/opt/conda/lib/python3.11/site-packages/lm_eval/__main__.py\", line 387, in cli_evaluate\n",
      "    results = evaluator.simple_evaluate(\n",
      "              ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/conda/lib/python3.11/site-packages/lm_eval/utils.py\", line 402, in _wrapper\n",
      "    return fn(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/conda/lib/python3.11/site-packages/lm_eval/evaluator.py\", line 205, in simple_evaluate\n",
      "    lm = lm_eval.api.registry.get_model(model).create_from_arg_string(\n",
      "         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/conda/lib/python3.11/site-packages/lm_eval/api/model.py\", line 151, in create_from_arg_string\n",
      "    return cls(**args, **args2)\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/conda/lib/python3.11/site-packages/lm_eval/models/huggingface.py\", line 190, in __init__\n",
      "    self._create_model(\n",
      "  File \"/opt/conda/lib/python3.11/site-packages/lm_eval/models/huggingface.py\", line 628, in _create_model\n",
      "    self._model = GPTQModel.from_quantized(\n",
      "                  ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/conda/lib/python3.11/site-packages/gptqmodel/models/auto.py\", line 260, in from_quantized\n",
      "    return MODEL_MAP[model_type].from_quantized(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/conda/lib/python3.11/site-packages/gptqmodel/models/loader.py\", line 262, in from_quantized\n",
      "    model_local_path = get_model_local_path(model_id_or_path, **kwargs)\n",
      "                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/conda/lib/python3.11/site-packages/gptqmodel/models/loader.py\", line 115, in get_model_local_path\n",
      "    return snapshot_download(pretrained_model_id_or_path, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/conda/lib/python3.11/site-packages/huggingface_hub/utils/_validators.py\", line 114, in _inner_fn\n",
      "    return fn(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^\n",
      "TypeError: snapshot_download() got an unexpected keyword argument 'max_memory'\n"
     ]
    }
   ],
   "source": [
    "# TheBloke/Llama-2-7B-GPTQ \n",
    "# !pip uninstall -y huggingface_hub\n",
    "# !pip install huggingface_hub==0.17.3\n",
    "!lm_eval \\\n",
    "    --model hf \\\n",
    "    --include_path /opt/conda/lib/python3.11/site-packages/lm_eval/tasks/ \\\n",
    "    --model_args pretrained=TheBloke/Llama-2-7B-GPTQ,gptqmodel=True,device_map=auto \\\n",
    "    --tasks secqa \\\n",
    "    --limit 120 \\\n",
    "    --verbosity DEBUG \\\n",
    "    --output_path results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "3973dc51-81a1-4eaa-b5f9-1dc909a0f4cd",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-02-17 20:02:58.896038: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "2025-02-17:20:03:00,376 INFO     [__main__.py:284] Verbosity set to DEBUG\n",
      "2025-02-17:20:03:00,376 INFO     [__main__.py:308] Including path: /opt/conda/lib/python3.11/site-packages/lm_eval/tasks/\n",
      "2025-02-17:20:03:02,556 DEBUG    [__init__.py:522] File _evalita-mp_ner_adg.yaml in /opt/conda/lib/python3.11/site-packages/lm_eval/tasks/evalita_llm could not be loaded\n",
      "2025-02-17:20:03:02,559 DEBUG    [__init__.py:522] File _evalita-mp_ner_fic.yaml in /opt/conda/lib/python3.11/site-packages/lm_eval/tasks/evalita_llm could not be loaded\n",
      "2025-02-17:20:03:02,562 DEBUG    [__init__.py:522] File _evalita-mp_ner_wn.yaml in /opt/conda/lib/python3.11/site-packages/lm_eval/tasks/evalita_llm could not be loaded\n",
      "2025-02-17:20:03:06,142 INFO     [__init__.py:459] The tag 'kobest' is already registered as a group, this tag will not be registered. This may affect tasks you want to call.\n",
      "2025-02-17:20:03:06,144 INFO     [__init__.py:459] The tag 'kobest' is already registered as a group, this tag will not be registered. This may affect tasks you want to call.\n",
      "2025-02-17:20:03:06,145 INFO     [__init__.py:459] The tag 'kobest' is already registered as a group, this tag will not be registered. This may affect tasks you want to call.\n",
      "2025-02-17:20:03:06,146 INFO     [__init__.py:459] The tag 'kobest' is already registered as a group, this tag will not be registered. This may affect tasks you want to call.\n",
      "2025-02-17:20:03:06,147 INFO     [__init__.py:459] The tag 'kobest' is already registered as a group, this tag will not be registered. This may affect tasks you want to call.\n",
      "2025-02-17:20:03:10,783 DEBUG    [__init__.py:522] File _evalita-mp_ner_adg.yaml in /opt/conda/lib/python3.11/site-packages/lm_eval/tasks/evalita_llm could not be loaded\n",
      "2025-02-17:20:03:10,786 DEBUG    [__init__.py:522] File _evalita-mp_ner_fic.yaml in /opt/conda/lib/python3.11/site-packages/lm_eval/tasks/evalita_llm could not be loaded\n",
      "2025-02-17:20:03:10,789 DEBUG    [__init__.py:522] File _evalita-mp_ner_wn.yaml in /opt/conda/lib/python3.11/site-packages/lm_eval/tasks/evalita_llm could not be loaded\n",
      "2025-02-17:20:03:14,356 INFO     [__init__.py:459] The tag 'kobest' is already registered as a group, this tag will not be registered. This may affect tasks you want to call.\n",
      "2025-02-17:20:03:14,357 INFO     [__init__.py:459] The tag 'kobest' is already registered as a group, this tag will not be registered. This may affect tasks you want to call.\n",
      "2025-02-17:20:03:14,358 INFO     [__init__.py:459] The tag 'kobest' is already registered as a group, this tag will not be registered. This may affect tasks you want to call.\n",
      "2025-02-17:20:03:14,360 INFO     [__init__.py:459] The tag 'kobest' is already registered as a group, this tag will not be registered. This may affect tasks you want to call.\n",
      "2025-02-17:20:03:14,361 INFO     [__init__.py:459] The tag 'kobest' is already registered as a group, this tag will not be registered. This may affect tasks you want to call.\n",
      "2025-02-17:20:03:16,834 WARNING  [__main__.py:317]  --limit SHOULD ONLY BE USED FOR TESTING.REAL METRICS SHOULD NOT BE COMPUTED USING LIMIT.\n",
      "2025-02-17:20:03:16,835 INFO     [__main__.py:381] Selected Tasks: ['secqa']\n",
      "2025-02-17:20:03:16,837 INFO     [evaluator.py:165] Setting random seed to 0 | Setting numpy seed to 1234 | Setting torch manual seed to 1234 | Setting fewshot manual seed to 1234\n",
      "2025-02-17:20:03:16,837 INFO     [evaluator.py:202] Initializing hf model, with arguments: {'pretrained': 'TheBloke/Mistral-7B-v0.1-GPTQ', 'gptqmodel': True}\n",
      "2025-02-17:20:03:16,917 INFO     [huggingface.py:135] Using device 'cuda'\n",
      "config.json: 100%|█████████████████████████████| 963/963 [00:00<00:00, 12.5MB/s]\n",
      "2025-02-17:20:03:17,371 DEBUG    [huggingface.py:491] Using model type 'causal'\n",
      "tokenizer_config.json: 100%|███████████████████| 962/962 [00:00<00:00, 8.12MB/s]\n",
      "tokenizer.model: 100%|███████████████████████| 493k/493k [00:00<00:00, 1.83MB/s]\n",
      "tokenizer.json: 100%|██████████████████████| 1.80M/1.80M [00:00<00:00, 6.71MB/s]\n",
      "added_tokens.json: 100%|██████████████████████| 42.0/42.0 [00:00<00:00, 296kB/s]\n",
      "special_tokens_map.json: 100%|███████████████| 72.0/72.0 [00:00<00:00, 1.21MB/s]\n",
      "2025-02-17:20:03:19,472 INFO     [huggingface.py:375] Model parallel was set to False, max memory was not set, and device map was set to {'': 'cuda'}\n",
      ".gitattributes: 100%|██████████████████████| 1.52k/1.52k [00:00<00:00, 22.0MB/s]\n",
      "README.md: 100%|███████████████████████████| 18.6k/18.6k [00:00<00:00, 84.0MB/s]\n",
      "generation_config.json: 100%|██████████████████| 116/116 [00:00<00:00, 1.23MB/s]\n",
      "model.safetensors: 100%|███████████████████▉| 4.16G/4.16G [00:06<00:00, 657MB/s]\n",
      "quantize_config.json: 100%|████████████████████| 186/186 [00:00<00:00, 2.64MB/s]\n",
      "INFO - Ignoring unknown parameter in the quantization configuration: model_name_or_path.\n",
      "INFO - Ignoring unknown parameter in the quantization configuration: model_file_base_name.\n",
      "INFO - `checkpoint_format` is missing from the quantization configuration and is automatically inferred to gptq\n",
      "INFO - Estimated Quantization BPW (bits per weight): 4.1875 bpw, based on [bits: 4, group_size: 128]\n",
      "INFO - Hint: Model is compatible with the Marlin kernel. Marlin is optimized for batched inference on Nvidia GPU: `model = GPTQModel.load(..., backend=BACKEND.MARLIN)`.\n",
      "INFO - Auto enabling flash attention2\n",
      "INFO - Auto pick kernel based on compatibility: <class 'gptqmodel.nn_modules.qlinear.marlin.MarlinQuantLinear'>\n",
      "INFO - make_quant: Linear candidates: [<class 'gptqmodel.nn_modules.qlinear.marlin.MarlinQuantLinear'>, <class 'gptqmodel.nn_modules.qlinear.exllamav2.ExllamaV2QuantLinear'>, <class 'gptqmodel.nn_modules.qlinear.exllama.ExllamaQuantLinear'>, <class 'gptqmodel.nn_modules.qlinear.dynamic_cuda.DynamicCudaQuantLinear'>, <class 'gptqmodel.nn_modules.qlinear.torch.TorchQuantLinear'>]\n",
      "INFO - make_quant: Selected linear: `<class 'gptqmodel.nn_modules.qlinear.marlin.MarlinQuantLinear'>`.\n",
      "2025-02-17:20:03:28,683 WARNING  [modeling.py:1959] Some weights of the model checkpoint at /home/jovyan/.cache/huggingface/hub/models--TheBloke--Mistral-7B-v0.1-GPTQ/snapshots/81de15eeac5938bc3b4065dfddf798fe5d215881/model.safetensors were not used when initializing MistralForCausalLM: {'model.layers.16.mlp.down_proj.bias', 'model.layers.22.self_attn.q_proj.bias', 'model.layers.3.self_attn.v_proj.bias', 'model.layers.17.mlp.up_proj.bias', 'model.layers.1.self_attn.k_proj.bias', 'model.layers.27.self_attn.k_proj.bias', 'model.layers.15.self_attn.k_proj.bias', 'model.layers.20.mlp.gate_proj.bias', 'model.layers.30.self_attn.o_proj.bias', 'model.layers.4.self_attn.k_proj.bias', 'model.layers.5.mlp.down_proj.bias', 'model.layers.7.self_attn.q_proj.bias', 'model.layers.21.self_attn.v_proj.bias', 'model.layers.23.mlp.down_proj.bias', 'model.layers.28.self_attn.q_proj.bias', 'model.layers.4.mlp.up_proj.bias', 'model.layers.11.self_attn.v_proj.bias', 'model.layers.21.self_attn.o_proj.bias', 'model.layers.25.mlp.down_proj.bias', 'model.layers.9.mlp.down_proj.bias', 'model.layers.20.self_attn.k_proj.bias', 'model.layers.10.self_attn.k_proj.bias', 'model.layers.17.self_attn.q_proj.bias', 'model.layers.29.mlp.gate_proj.bias', 'model.layers.1.self_attn.v_proj.bias', 'model.layers.30.self_attn.q_proj.bias', 'model.layers.9.self_attn.k_proj.bias', 'model.layers.10.self_attn.o_proj.bias', 'model.layers.31.mlp.gate_proj.bias', 'model.layers.21.mlp.gate_proj.bias', 'model.layers.26.self_attn.o_proj.bias', 'model.layers.21.self_attn.k_proj.bias', 'model.layers.20.self_attn.q_proj.bias', 'model.layers.12.self_attn.q_proj.bias', 'model.layers.31.mlp.up_proj.bias', 'model.layers.5.self_attn.o_proj.bias', 'model.layers.9.self_attn.o_proj.bias', 'model.layers.6.mlp.up_proj.bias', 'model.layers.19.self_attn.k_proj.bias', 'model.layers.18.mlp.down_proj.bias', 'model.layers.1.mlp.down_proj.bias', 'model.layers.18.self_attn.k_proj.bias', 'model.layers.23.self_attn.k_proj.bias', 'model.layers.18.self_attn.v_proj.bias', 'model.layers.5.self_attn.k_proj.bias', 'model.layers.30.mlp.up_proj.bias', 'model.layers.4.mlp.gate_proj.bias', 'model.layers.10.mlp.gate_proj.bias', 'model.layers.24.mlp.down_proj.bias', 'model.layers.0.mlp.gate_proj.bias', 'model.layers.16.mlp.up_proj.bias', 'model.layers.27.self_attn.o_proj.bias', 'model.layers.4.self_attn.o_proj.bias', 'model.layers.22.mlp.up_proj.bias', 'model.layers.3.self_attn.q_proj.bias', 'model.layers.30.mlp.down_proj.bias', 'model.layers.15.self_attn.q_proj.bias', 'model.layers.27.self_attn.q_proj.bias', 'model.layers.8.self_attn.q_proj.bias', 'model.layers.20.mlp.up_proj.bias', 'model.layers.18.self_attn.q_proj.bias', 'model.layers.29.self_attn.k_proj.bias', 'model.layers.8.self_attn.v_proj.bias', 'model.layers.21.self_attn.q_proj.bias', 'model.layers.2.self_attn.q_proj.bias', 'model.layers.4.mlp.down_proj.bias', 'model.layers.18.self_attn.o_proj.bias', 'model.layers.14.mlp.down_proj.bias', 'model.layers.2.self_attn.v_proj.bias', 'model.layers.14.self_attn.k_proj.bias', 'model.layers.20.self_attn.o_proj.bias', 'model.layers.30.self_attn.k_proj.bias', 'model.layers.30.self_attn.v_proj.bias', 'model.layers.25.self_attn.o_proj.bias', 'model.layers.31.self_attn.o_proj.bias', 'model.layers.5.self_attn.q_proj.bias', 'model.layers.6.self_attn.k_proj.bias', 'model.layers.26.mlp.down_proj.bias', 'model.layers.13.self_attn.o_proj.bias', 'model.layers.23.self_attn.v_proj.bias', 'model.layers.24.self_attn.o_proj.bias', 'model.layers.29.self_attn.o_proj.bias', 'model.layers.20.self_attn.v_proj.bias', 'model.layers.26.self_attn.k_proj.bias', 'model.layers.22.self_attn.k_proj.bias', 'model.layers.7.self_attn.o_proj.bias', 'model.layers.22.self_attn.v_proj.bias', 'model.layers.26.mlp.gate_proj.bias', 'model.layers.16.self_attn.v_proj.bias', 'model.layers.0.mlp.up_proj.bias', 'model.layers.15.self_attn.o_proj.bias', 'model.layers.19.self_attn.q_proj.bias', 'model.layers.23.mlp.up_proj.bias', 'model.layers.28.self_attn.v_proj.bias', 'model.layers.6.mlp.gate_proj.bias', 'model.layers.14.mlp.up_proj.bias', 'model.layers.17.mlp.gate_proj.bias', 'model.layers.13.self_attn.v_proj.bias', 'model.layers.17.self_attn.o_proj.bias', 'model.layers.16.self_attn.k_proj.bias', 'model.layers.0.self_attn.o_proj.bias', 'model.layers.12.mlp.gate_proj.bias', 'model.layers.31.self_attn.q_proj.bias', 'model.layers.4.self_attn.q_proj.bias', 'model.layers.2.mlp.down_proj.bias', 'model.layers.2.self_attn.o_proj.bias', 'model.layers.6.self_attn.v_proj.bias', 'model.layers.27.mlp.down_proj.bias', 'model.layers.3.mlp.down_proj.bias', 'model.layers.15.mlp.gate_proj.bias', 'model.layers.26.self_attn.v_proj.bias', 'model.layers.12.self_attn.k_proj.bias', 'model.layers.11.self_attn.o_proj.bias', 'model.layers.24.self_attn.q_proj.bias', 'model.layers.13.self_attn.k_proj.bias', 'model.layers.16.mlp.gate_proj.bias', 'model.layers.11.self_attn.k_proj.bias', 'model.layers.28.mlp.down_proj.bias', 'model.layers.9.mlp.up_proj.bias', 'model.layers.29.self_attn.v_proj.bias', 'model.layers.1.self_attn.q_proj.bias', 'model.layers.31.mlp.down_proj.bias', 'model.layers.22.mlp.gate_proj.bias', 'model.layers.2.mlp.up_proj.bias', 'model.layers.11.mlp.gate_proj.bias', 'model.layers.24.mlp.gate_proj.bias', 'model.layers.0.self_attn.q_proj.bias', 'model.layers.14.self_attn.q_proj.bias', 'model.layers.17.mlp.down_proj.bias', 'model.layers.8.self_attn.k_proj.bias', 'model.layers.7.self_attn.v_proj.bias', 'model.layers.24.self_attn.k_proj.bias', 'model.layers.20.mlp.down_proj.bias', 'model.layers.19.mlp.down_proj.bias', 'model.layers.25.self_attn.k_proj.bias', 'model.layers.25.self_attn.q_proj.bias', 'model.layers.5.mlp.up_proj.bias', 'model.layers.0.self_attn.k_proj.bias', 'model.layers.28.mlp.gate_proj.bias', 'model.layers.29.mlp.down_proj.bias', 'model.layers.15.mlp.down_proj.bias', 'model.layers.22.mlp.down_proj.bias', 'model.layers.31.self_attn.k_proj.bias', 'model.layers.2.self_attn.k_proj.bias', 'model.layers.6.mlp.down_proj.bias', 'model.layers.25.self_attn.v_proj.bias', 'model.layers.13.mlp.gate_proj.bias', 'model.layers.1.mlp.up_proj.bias', 'model.layers.18.mlp.up_proj.bias', 'model.layers.3.mlp.gate_proj.bias', 'model.layers.23.self_attn.q_proj.bias', 'model.layers.24.mlp.up_proj.bias', 'model.layers.11.mlp.up_proj.bias', 'model.layers.2.mlp.gate_proj.bias', 'model.layers.10.self_attn.q_proj.bias', 'model.layers.16.self_attn.q_proj.bias', 'model.layers.24.self_attn.v_proj.bias', 'model.layers.13.self_attn.q_proj.bias', 'model.layers.19.self_attn.o_proj.bias', 'model.layers.26.mlp.up_proj.bias', 'model.layers.14.self_attn.v_proj.bias', 'model.layers.7.self_attn.k_proj.bias', 'model.layers.8.mlp.down_proj.bias', 'model.layers.12.self_attn.o_proj.bias', 'model.layers.3.mlp.up_proj.bias', 'model.layers.10.self_attn.v_proj.bias', 'model.layers.26.self_attn.q_proj.bias', 'model.layers.10.mlp.down_proj.bias', 'model.layers.12.mlp.down_proj.bias', 'model.layers.3.self_attn.k_proj.bias', 'model.layers.9.mlp.gate_proj.bias', 'model.layers.8.mlp.gate_proj.bias', 'model.layers.17.self_attn.v_proj.bias', 'model.layers.21.mlp.up_proj.bias', 'model.layers.25.mlp.up_proj.bias', 'model.layers.29.mlp.up_proj.bias', 'model.layers.19.mlp.gate_proj.bias', 'model.layers.12.mlp.up_proj.bias', 'model.layers.7.mlp.down_proj.bias', 'model.layers.13.mlp.down_proj.bias', 'model.layers.15.self_attn.v_proj.bias', 'model.layers.12.self_attn.v_proj.bias', 'model.layers.15.mlp.up_proj.bias', 'model.layers.3.self_attn.o_proj.bias', 'model.layers.27.self_attn.v_proj.bias', 'model.layers.21.mlp.down_proj.bias', 'model.layers.11.self_attn.q_proj.bias', 'model.layers.28.self_attn.o_proj.bias', 'model.layers.23.mlp.gate_proj.bias', 'model.layers.22.self_attn.o_proj.bias', 'model.layers.8.self_attn.o_proj.bias', 'model.layers.5.mlp.gate_proj.bias', 'model.layers.0.self_attn.v_proj.bias', 'model.layers.9.self_attn.v_proj.bias', 'model.layers.30.mlp.gate_proj.bias', 'model.layers.23.self_attn.o_proj.bias', 'model.layers.14.mlp.gate_proj.bias', 'model.layers.1.self_attn.o_proj.bias', 'model.layers.19.mlp.up_proj.bias', 'model.layers.31.self_attn.v_proj.bias', 'model.layers.10.mlp.up_proj.bias', 'model.layers.17.self_attn.k_proj.bias', 'model.layers.6.self_attn.o_proj.bias', 'model.layers.7.mlp.up_proj.bias', 'model.layers.8.mlp.up_proj.bias', 'model.layers.27.mlp.up_proj.bias', 'model.layers.4.self_attn.v_proj.bias', 'model.layers.11.mlp.down_proj.bias', 'model.layers.6.self_attn.q_proj.bias', 'model.layers.16.self_attn.o_proj.bias', 'model.layers.0.mlp.down_proj.bias', 'model.layers.14.self_attn.o_proj.bias', 'model.layers.27.mlp.gate_proj.bias', 'model.layers.1.mlp.gate_proj.bias', 'model.layers.29.self_attn.q_proj.bias', 'model.layers.9.self_attn.q_proj.bias', 'model.layers.28.self_attn.k_proj.bias', 'model.layers.5.self_attn.v_proj.bias', 'model.layers.25.mlp.gate_proj.bias', 'model.layers.19.self_attn.v_proj.bias', 'model.layers.18.mlp.gate_proj.bias', 'model.layers.28.mlp.up_proj.bias', 'model.layers.13.mlp.up_proj.bias', 'model.layers.7.mlp.gate_proj.bias'}. This may or may not be an issue - make sure that the checkpoint does not have unnecessary parameters, or that the model definition correctly corresponds to the checkpoint.\n",
      "INFO - Converting `checkpoint_format` from `gptq` to internal `gptq_v2`.\n",
      "INFO - Conversion complete: 0.017548322677612305s\n",
      "2025-02-17:20:03:29,218 WARNING  [task.py:804] [Task: secqa] metric acc is defined, but aggregation is not. using default aggregation=mean\n",
      "2025-02-17:20:03:29,218 WARNING  [task.py:816] [Task: secqa] metric acc is defined, but higher_is_better is not. using default higher_is_better=True\n",
      "2025-02-17:20:03:30,606 INFO     [task.py:420] Building contexts for secqa on rank 0...\n",
      "100%|███████████████████████████████████████| 110/110 [00:00<00:00, 2342.32it/s]\n",
      "2025-02-17:20:03:30,657 DEBUG    [evaluator.py:484] Task: secqa; number of requests on this rank: 440\n",
      "2025-02-17:20:03:30,657 INFO     [evaluator.py:513] Running loglikelihood requests\n",
      "Running loglikelihood requests: 100%|████████| 440/440 [00:04<00:00, 104.04it/s]\n",
      "fatal: not a git repository (or any parent up to mount point /home)\n",
      "Stopping at filesystem boundary (GIT_DISCOVERY_ACROSS_FILESYSTEM not set).\n",
      "2025-02-17:20:03:41,214 INFO     [evaluation_tracker.py:269] Output path not provided, skipping saving results aggregated\n",
      "hf (pretrained=TheBloke/Mistral-7B-v0.1-GPTQ,gptqmodel=True), gen_kwargs: (None), limit: 120.0, num_fewshot: None, batch_size: 1\n",
      "|Tasks|Version|Filter|n-shot|Metric|   |Value |   |Stderr|\n",
      "|-----|-------|------|-----:|------|---|-----:|---|-----:|\n",
      "|secqa|Yaml   |none  |     0|acc   |↑  |0.2091|±  | 0.039|\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# TheBloke/Mistral-7B-v0.1-GPTQ\n",
    "!lm_eval \\\n",
    "    --model hf \\\n",
    "    --include_path /opt/conda/lib/python3.11/site-packages/lm_eval/tasks/ \\\n",
    "    --model_args pretrained=TheBloke/Mistral-7B-v0.1-GPTQ,gptqmodel=True \\\n",
    "    --tasks secqa \\\n",
    "    --limit 120 \\\n",
    "    --verbosity DEBUG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "a2f560fe-ab89-4ff6-acc3-4b7b910f1780",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-02-17 20:04:30.240346: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "2025-02-17:20:04:31,714 INFO     [__main__.py:284] Verbosity set to DEBUG\n",
      "2025-02-17:20:04:31,715 INFO     [__main__.py:308] Including path: /opt/conda/lib/python3.11/site-packages/lm_eval/tasks/\n",
      "2025-02-17:20:04:33,894 DEBUG    [__init__.py:522] File _evalita-mp_ner_adg.yaml in /opt/conda/lib/python3.11/site-packages/lm_eval/tasks/evalita_llm could not be loaded\n",
      "2025-02-17:20:04:33,897 DEBUG    [__init__.py:522] File _evalita-mp_ner_fic.yaml in /opt/conda/lib/python3.11/site-packages/lm_eval/tasks/evalita_llm could not be loaded\n",
      "2025-02-17:20:04:33,900 DEBUG    [__init__.py:522] File _evalita-mp_ner_wn.yaml in /opt/conda/lib/python3.11/site-packages/lm_eval/tasks/evalita_llm could not be loaded\n",
      "2025-02-17:20:04:37,500 INFO     [__init__.py:459] The tag 'kobest' is already registered as a group, this tag will not be registered. This may affect tasks you want to call.\n",
      "2025-02-17:20:04:37,501 INFO     [__init__.py:459] The tag 'kobest' is already registered as a group, this tag will not be registered. This may affect tasks you want to call.\n",
      "2025-02-17:20:04:37,502 INFO     [__init__.py:459] The tag 'kobest' is already registered as a group, this tag will not be registered. This may affect tasks you want to call.\n",
      "2025-02-17:20:04:37,504 INFO     [__init__.py:459] The tag 'kobest' is already registered as a group, this tag will not be registered. This may affect tasks you want to call.\n",
      "2025-02-17:20:04:37,505 INFO     [__init__.py:459] The tag 'kobest' is already registered as a group, this tag will not be registered. This may affect tasks you want to call.\n",
      "2025-02-17:20:04:42,151 DEBUG    [__init__.py:522] File _evalita-mp_ner_adg.yaml in /opt/conda/lib/python3.11/site-packages/lm_eval/tasks/evalita_llm could not be loaded\n",
      "2025-02-17:20:04:42,154 DEBUG    [__init__.py:522] File _evalita-mp_ner_fic.yaml in /opt/conda/lib/python3.11/site-packages/lm_eval/tasks/evalita_llm could not be loaded\n",
      "2025-02-17:20:04:42,158 DEBUG    [__init__.py:522] File _evalita-mp_ner_wn.yaml in /opt/conda/lib/python3.11/site-packages/lm_eval/tasks/evalita_llm could not be loaded\n",
      "2025-02-17:20:04:45,757 INFO     [__init__.py:459] The tag 'kobest' is already registered as a group, this tag will not be registered. This may affect tasks you want to call.\n",
      "2025-02-17:20:04:45,758 INFO     [__init__.py:459] The tag 'kobest' is already registered as a group, this tag will not be registered. This may affect tasks you want to call.\n",
      "2025-02-17:20:04:45,760 INFO     [__init__.py:459] The tag 'kobest' is already registered as a group, this tag will not be registered. This may affect tasks you want to call.\n",
      "2025-02-17:20:04:45,761 INFO     [__init__.py:459] The tag 'kobest' is already registered as a group, this tag will not be registered. This may affect tasks you want to call.\n",
      "2025-02-17:20:04:45,762 INFO     [__init__.py:459] The tag 'kobest' is already registered as a group, this tag will not be registered. This may affect tasks you want to call.\n",
      "2025-02-17:20:04:48,244 WARNING  [__main__.py:317]  --limit SHOULD ONLY BE USED FOR TESTING.REAL METRICS SHOULD NOT BE COMPUTED USING LIMIT.\n",
      "2025-02-17:20:04:48,245 INFO     [__main__.py:381] Selected Tasks: ['secqa']\n",
      "2025-02-17:20:04:48,247 INFO     [evaluator.py:165] Setting random seed to 0 | Setting numpy seed to 1234 | Setting torch manual seed to 1234 | Setting fewshot manual seed to 1234\n",
      "2025-02-17:20:04:48,247 INFO     [evaluator.py:202] Initializing hf model, with arguments: {'pretrained': 'TheBloke/Mistral-7B-Instruct-v0.2-GPTQ', 'gptqmodel': True}\n",
      "2025-02-17:20:04:48,285 INFO     [huggingface.py:135] Using device 'cuda'\n",
      "config.json: 100%|█████████████████████████| 1.08k/1.08k [00:00<00:00, 13.4MB/s]\n",
      "2025-02-17:20:04:49,181 DEBUG    [huggingface.py:491] Using model type 'causal'\n",
      "tokenizer_config.json: 100%|███████████████| 1.46k/1.46k [00:00<00:00, 13.5MB/s]\n",
      "tokenizer.model: 100%|███████████████████████| 493k/493k [00:00<00:00, 2.19MB/s]\n",
      "tokenizer.json: 100%|██████████████████████| 1.80M/1.80M [00:00<00:00, 5.64MB/s]\n",
      "special_tokens_map.json: 100%|████████████████| 72.0/72.0 [00:00<00:00, 643kB/s]\n",
      "2025-02-17:20:04:51,214 INFO     [huggingface.py:375] Model parallel was set to False, max memory was not set, and device map was set to {'': 'cuda'}\n",
      ".gitattributes: 100%|██████████████████████| 1.52k/1.52k [00:00<00:00, 21.7MB/s]\n",
      "README.md: 100%|████████████████████████████| 23.1k/23.1k [00:00<00:00, 184MB/s]\n",
      "generation_config.json: 100%|██████████████████| 111/111 [00:00<00:00, 2.23MB/s]\n",
      "model.safetensors: 100%|███████████████████▉| 4.16G/4.16G [00:06<00:00, 690MB/s]\n",
      "quantize_config.json: 100%|████████████████████| 186/186 [00:00<00:00, 2.83MB/s]\n",
      "INFO - Ignoring unknown parameter in the quantization configuration: model_name_or_path.\n",
      "INFO - Ignoring unknown parameter in the quantization configuration: model_file_base_name.\n",
      "INFO - `checkpoint_format` is missing from the quantization configuration and is automatically inferred to gptq\n",
      "INFO - Estimated Quantization BPW (bits per weight): 4.1875 bpw, based on [bits: 4, group_size: 128]\n",
      "INFO - Hint: Model is compatible with the Marlin kernel. Marlin is optimized for batched inference on Nvidia GPU: `model = GPTQModel.load(..., backend=BACKEND.MARLIN)`.\n",
      "INFO - Auto enabling flash attention2\n",
      "INFO - Auto pick kernel based on compatibility: <class 'gptqmodel.nn_modules.qlinear.marlin.MarlinQuantLinear'>\n",
      "INFO - make_quant: Linear candidates: [<class 'gptqmodel.nn_modules.qlinear.marlin.MarlinQuantLinear'>, <class 'gptqmodel.nn_modules.qlinear.exllamav2.ExllamaV2QuantLinear'>, <class 'gptqmodel.nn_modules.qlinear.exllama.ExllamaQuantLinear'>, <class 'gptqmodel.nn_modules.qlinear.dynamic_cuda.DynamicCudaQuantLinear'>, <class 'gptqmodel.nn_modules.qlinear.torch.TorchQuantLinear'>]\n",
      "INFO - make_quant: Selected linear: `<class 'gptqmodel.nn_modules.qlinear.marlin.MarlinQuantLinear'>`.\n",
      "2025-02-17:20:05:00,706 WARNING  [modeling.py:1959] Some weights of the model checkpoint at /home/jovyan/.cache/huggingface/hub/models--TheBloke--Mistral-7B-Instruct-v0.2-GPTQ/snapshots/7532d6bc89ef9300fb39d2d94ed4414ec534b72a/model.safetensors were not used when initializing MistralForCausalLM: {'model.layers.26.mlp.down_proj.bias', 'model.layers.28.mlp.up_proj.bias', 'model.layers.29.mlp.down_proj.bias', 'model.layers.31.self_attn.k_proj.bias', 'model.layers.9.mlp.up_proj.bias', 'model.layers.6.mlp.gate_proj.bias', 'model.layers.4.mlp.up_proj.bias', 'model.layers.7.mlp.gate_proj.bias', 'model.layers.23.mlp.down_proj.bias', 'model.layers.14.mlp.gate_proj.bias', 'model.layers.27.mlp.down_proj.bias', 'model.layers.0.self_attn.k_proj.bias', 'model.layers.13.self_attn.q_proj.bias', 'model.layers.2.self_attn.k_proj.bias', 'model.layers.22.self_attn.q_proj.bias', 'model.layers.23.self_attn.v_proj.bias', 'model.layers.29.self_attn.k_proj.bias', 'model.layers.18.mlp.down_proj.bias', 'model.layers.19.self_attn.o_proj.bias', 'model.layers.16.self_attn.o_proj.bias', 'model.layers.2.mlp.down_proj.bias', 'model.layers.16.self_attn.k_proj.bias', 'model.layers.22.mlp.down_proj.bias', 'model.layers.14.mlp.up_proj.bias', 'model.layers.23.mlp.up_proj.bias', 'model.layers.29.mlp.up_proj.bias', 'model.layers.3.mlp.down_proj.bias', 'model.layers.13.mlp.gate_proj.bias', 'model.layers.3.self_attn.k_proj.bias', 'model.layers.31.self_attn.v_proj.bias', 'model.layers.13.mlp.down_proj.bias', 'model.layers.7.self_attn.k_proj.bias', 'model.layers.20.mlp.gate_proj.bias', 'model.layers.12.self_attn.k_proj.bias', 'model.layers.10.self_attn.o_proj.bias', 'model.layers.9.self_attn.o_proj.bias', 'model.layers.8.mlp.gate_proj.bias', 'model.layers.21.self_attn.v_proj.bias', 'model.layers.28.self_attn.k_proj.bias', 'model.layers.25.self_attn.o_proj.bias', 'model.layers.29.self_attn.q_proj.bias', 'model.layers.12.mlp.up_proj.bias', 'model.layers.22.mlp.up_proj.bias', 'model.layers.10.self_attn.q_proj.bias', 'model.layers.2.mlp.gate_proj.bias', 'model.layers.24.mlp.gate_proj.bias', 'model.layers.25.self_attn.q_proj.bias', 'model.layers.27.self_attn.k_proj.bias', 'model.layers.28.self_attn.q_proj.bias', 'model.layers.6.mlp.up_proj.bias', 'model.layers.29.self_attn.v_proj.bias', 'model.layers.27.mlp.gate_proj.bias', 'model.layers.20.self_attn.o_proj.bias', 'model.layers.8.self_attn.q_proj.bias', 'model.layers.0.mlp.up_proj.bias', 'model.layers.14.self_attn.k_proj.bias', 'model.layers.3.mlp.up_proj.bias', 'model.layers.11.self_attn.k_proj.bias', 'model.layers.10.mlp.gate_proj.bias', 'model.layers.25.mlp.up_proj.bias', 'model.layers.22.self_attn.k_proj.bias', 'model.layers.5.self_attn.v_proj.bias', 'model.layers.15.self_attn.o_proj.bias', 'model.layers.16.self_attn.v_proj.bias', 'model.layers.13.mlp.up_proj.bias', 'model.layers.27.self_attn.q_proj.bias', 'model.layers.12.self_attn.q_proj.bias', 'model.layers.31.mlp.gate_proj.bias', 'model.layers.9.self_attn.q_proj.bias', 'model.layers.3.self_attn.q_proj.bias', 'model.layers.13.self_attn.o_proj.bias', 'model.layers.30.self_attn.o_proj.bias', 'model.layers.22.self_attn.v_proj.bias', 'model.layers.9.mlp.gate_proj.bias', 'model.layers.19.self_attn.v_proj.bias', 'model.layers.3.self_attn.v_proj.bias', 'model.layers.3.self_attn.o_proj.bias', 'model.layers.9.mlp.down_proj.bias', 'model.layers.9.self_attn.v_proj.bias', 'model.layers.30.mlp.gate_proj.bias', 'model.layers.27.mlp.up_proj.bias', 'model.layers.10.mlp.up_proj.bias', 'model.layers.31.mlp.up_proj.bias', 'model.layers.4.self_attn.q_proj.bias', 'model.layers.2.self_attn.v_proj.bias', 'model.layers.1.mlp.down_proj.bias', 'model.layers.15.self_attn.k_proj.bias', 'model.layers.13.self_attn.k_proj.bias', 'model.layers.14.self_attn.q_proj.bias', 'model.layers.30.mlp.down_proj.bias', 'model.layers.6.self_attn.q_proj.bias', 'model.layers.7.self_attn.q_proj.bias', 'model.layers.11.self_attn.o_proj.bias', 'model.layers.6.self_attn.v_proj.bias', 'model.layers.18.mlp.gate_proj.bias', 'model.layers.23.self_attn.q_proj.bias', 'model.layers.2.mlp.up_proj.bias', 'model.layers.4.self_attn.v_proj.bias', 'model.layers.15.mlp.up_proj.bias', 'model.layers.24.self_attn.k_proj.bias', 'model.layers.15.mlp.gate_proj.bias', 'model.layers.5.mlp.up_proj.bias', 'model.layers.16.mlp.down_proj.bias', 'model.layers.11.self_attn.q_proj.bias', 'model.layers.30.self_attn.q_proj.bias', 'model.layers.7.self_attn.o_proj.bias', 'model.layers.12.mlp.down_proj.bias', 'model.layers.30.self_attn.v_proj.bias', 'model.layers.15.self_attn.v_proj.bias', 'model.layers.5.self_attn.o_proj.bias', 'model.layers.25.mlp.gate_proj.bias', 'model.layers.26.self_attn.o_proj.bias', 'model.layers.1.mlp.up_proj.bias', 'model.layers.18.self_attn.o_proj.bias', 'model.layers.5.mlp.gate_proj.bias', 'model.layers.31.mlp.down_proj.bias', 'model.layers.16.self_attn.q_proj.bias', 'model.layers.24.self_attn.o_proj.bias', 'model.layers.0.self_attn.v_proj.bias', 'model.layers.12.self_attn.o_proj.bias', 'model.layers.31.self_attn.q_proj.bias', 'model.layers.11.mlp.down_proj.bias', 'model.layers.4.mlp.down_proj.bias', 'model.layers.4.self_attn.k_proj.bias', 'model.layers.17.self_attn.v_proj.bias', 'model.layers.7.mlp.down_proj.bias', 'model.layers.26.self_attn.q_proj.bias', 'model.layers.21.mlp.down_proj.bias', 'model.layers.28.mlp.down_proj.bias', 'model.layers.23.mlp.gate_proj.bias', 'model.layers.26.self_attn.k_proj.bias', 'model.layers.30.mlp.up_proj.bias', 'model.layers.5.self_attn.k_proj.bias', 'model.layers.20.self_attn.k_proj.bias', 'model.layers.8.self_attn.k_proj.bias', 'model.layers.10.self_attn.v_proj.bias', 'model.layers.2.self_attn.q_proj.bias', 'model.layers.27.self_attn.o_proj.bias', 'model.layers.7.mlp.up_proj.bias', 'model.layers.16.mlp.gate_proj.bias', 'model.layers.1.self_attn.q_proj.bias', 'model.layers.17.mlp.up_proj.bias', 'model.layers.27.self_attn.v_proj.bias', 'model.layers.20.self_attn.v_proj.bias', 'model.layers.15.mlp.down_proj.bias', 'model.layers.1.self_attn.k_proj.bias', 'model.layers.14.self_attn.v_proj.bias', 'model.layers.31.self_attn.o_proj.bias', 'model.layers.15.self_attn.q_proj.bias', 'model.layers.26.mlp.gate_proj.bias', 'model.layers.21.mlp.gate_proj.bias', 'model.layers.24.self_attn.v_proj.bias', 'model.layers.25.mlp.down_proj.bias', 'model.layers.12.mlp.gate_proj.bias', 'model.layers.0.mlp.gate_proj.bias', 'model.layers.17.self_attn.o_proj.bias', 'model.layers.9.self_attn.k_proj.bias', 'model.layers.22.mlp.gate_proj.bias', 'model.layers.23.self_attn.k_proj.bias', 'model.layers.8.mlp.up_proj.bias', 'model.layers.20.self_attn.q_proj.bias', 'model.layers.24.mlp.down_proj.bias', 'model.layers.19.mlp.gate_proj.bias', 'model.layers.19.self_attn.q_proj.bias', 'model.layers.8.mlp.down_proj.bias', 'model.layers.8.self_attn.v_proj.bias', 'model.layers.19.mlp.down_proj.bias', 'model.layers.17.self_attn.q_proj.bias', 'model.layers.10.mlp.down_proj.bias', 'model.layers.2.self_attn.o_proj.bias', 'model.layers.16.mlp.up_proj.bias', 'model.layers.6.self_attn.o_proj.bias', 'model.layers.17.mlp.down_proj.bias', 'model.layers.4.self_attn.o_proj.bias', 'model.layers.3.mlp.gate_proj.bias', 'model.layers.4.mlp.gate_proj.bias', 'model.layers.1.mlp.gate_proj.bias', 'model.layers.25.self_attn.k_proj.bias', 'model.layers.19.self_attn.k_proj.bias', 'model.layers.30.self_attn.k_proj.bias', 'model.layers.5.mlp.down_proj.bias', 'model.layers.5.self_attn.q_proj.bias', 'model.layers.0.self_attn.q_proj.bias', 'model.layers.7.self_attn.v_proj.bias', 'model.layers.24.mlp.up_proj.bias', 'model.layers.26.mlp.up_proj.bias', 'model.layers.14.mlp.down_proj.bias', 'model.layers.18.mlp.up_proj.bias', 'model.layers.13.self_attn.v_proj.bias', 'model.layers.11.self_attn.v_proj.bias', 'model.layers.18.self_attn.v_proj.bias', 'model.layers.29.mlp.gate_proj.bias', 'model.layers.11.mlp.up_proj.bias', 'model.layers.29.self_attn.o_proj.bias', 'model.layers.10.self_attn.k_proj.bias', 'model.layers.14.self_attn.o_proj.bias', 'model.layers.28.self_attn.v_proj.bias', 'model.layers.18.self_attn.k_proj.bias', 'model.layers.21.mlp.up_proj.bias', 'model.layers.21.self_attn.q_proj.bias', 'model.layers.1.self_attn.v_proj.bias', 'model.layers.0.mlp.down_proj.bias', 'model.layers.18.self_attn.q_proj.bias', 'model.layers.20.mlp.up_proj.bias', 'model.layers.19.mlp.up_proj.bias', 'model.layers.20.mlp.down_proj.bias', 'model.layers.21.self_attn.k_proj.bias', 'model.layers.24.self_attn.q_proj.bias', 'model.layers.6.self_attn.k_proj.bias', 'model.layers.25.self_attn.v_proj.bias', 'model.layers.11.mlp.gate_proj.bias', 'model.layers.12.self_attn.v_proj.bias', 'model.layers.17.self_attn.k_proj.bias', 'model.layers.8.self_attn.o_proj.bias', 'model.layers.21.self_attn.o_proj.bias', 'model.layers.23.self_attn.o_proj.bias', 'model.layers.28.mlp.gate_proj.bias', 'model.layers.1.self_attn.o_proj.bias', 'model.layers.22.self_attn.o_proj.bias', 'model.layers.28.self_attn.o_proj.bias', 'model.layers.6.mlp.down_proj.bias', 'model.layers.17.mlp.gate_proj.bias', 'model.layers.0.self_attn.o_proj.bias', 'model.layers.26.self_attn.v_proj.bias'}. This may or may not be an issue - make sure that the checkpoint does not have unnecessary parameters, or that the model definition correctly corresponds to the checkpoint.\n",
      "INFO - Converting `checkpoint_format` from `gptq` to internal `gptq_v2`.\n",
      "INFO - Conversion complete: 0.013204097747802734s\n",
      "2025-02-17:20:05:01,235 WARNING  [task.py:804] [Task: secqa] metric acc is defined, but aggregation is not. using default aggregation=mean\n",
      "2025-02-17:20:05:01,235 WARNING  [task.py:816] [Task: secqa] metric acc is defined, but higher_is_better is not. using default higher_is_better=True\n",
      "2025-02-17:20:05:02,880 INFO     [task.py:420] Building contexts for secqa on rank 0...\n",
      "100%|███████████████████████████████████████| 110/110 [00:00<00:00, 2322.63it/s]\n",
      "2025-02-17:20:05:02,931 DEBUG    [evaluator.py:484] Task: secqa; number of requests on this rank: 440\n",
      "2025-02-17:20:05:02,931 INFO     [evaluator.py:513] Running loglikelihood requests\n",
      "Running loglikelihood requests: 100%|████████| 440/440 [00:04<00:00, 103.72it/s]\n",
      "fatal: not a git repository (or any parent up to mount point /home)\n",
      "Stopping at filesystem boundary (GIT_DISCOVERY_ACROSS_FILESYSTEM not set).\n",
      "2025-02-17:20:05:13,600 INFO     [evaluation_tracker.py:269] Output path not provided, skipping saving results aggregated\n",
      "hf (pretrained=TheBloke/Mistral-7B-Instruct-v0.2-GPTQ,gptqmodel=True), gen_kwargs: (None), limit: 120.0, num_fewshot: None, batch_size: 1\n",
      "|Tasks|Version|Filter|n-shot|Metric|   |Value |   |Stderr|\n",
      "|-----|-------|------|-----:|------|---|-----:|---|-----:|\n",
      "|secqa|Yaml   |none  |     0|acc   |↑  |0.8636|±  |0.0329|\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# TheBloke/Mistral-7B-Instruct-v0.2-GPTQ\n",
    "!lm_eval \\\n",
    "    --model hf \\\n",
    "    --include_path /opt/conda/lib/python3.11/site-packages/lm_eval/tasks/ \\\n",
    "    --model_args pretrained=TheBloke/Mistral-7B-Instruct-v0.2-GPTQ,gptqmodel=True \\\n",
    "    --tasks secqa \\\n",
    "    --limit 120 \\\n",
    "    --verbosity DEBUG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "871eb38e-9942-4ef6-b35f-d0d3a52360e2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-02-18 23:18:22.808749: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "2025-02-18:23:18:24,237 INFO     [__main__.py:284] Verbosity set to DEBUG\n",
      "2025-02-18:23:18:24,237 INFO     [__main__.py:308] Including path: /opt/conda/lib/python3.11/site-packages/lm_eval/tasks/\n",
      "2025-02-18:23:18:26,454 DEBUG    [__init__.py:522] File _evalita-mp_ner_adg.yaml in /opt/conda/lib/python3.11/site-packages/lm_eval/tasks/evalita_llm could not be loaded\n",
      "2025-02-18:23:18:26,457 DEBUG    [__init__.py:522] File _evalita-mp_ner_fic.yaml in /opt/conda/lib/python3.11/site-packages/lm_eval/tasks/evalita_llm could not be loaded\n",
      "2025-02-18:23:18:26,460 DEBUG    [__init__.py:522] File _evalita-mp_ner_wn.yaml in /opt/conda/lib/python3.11/site-packages/lm_eval/tasks/evalita_llm could not be loaded\n",
      "2025-02-18:23:18:30,122 INFO     [__init__.py:459] The tag 'kobest' is already registered as a group, this tag will not be registered. This may affect tasks you want to call.\n",
      "2025-02-18:23:18:30,124 INFO     [__init__.py:459] The tag 'kobest' is already registered as a group, this tag will not be registered. This may affect tasks you want to call.\n",
      "2025-02-18:23:18:30,125 INFO     [__init__.py:459] The tag 'kobest' is already registered as a group, this tag will not be registered. This may affect tasks you want to call.\n",
      "2025-02-18:23:18:30,126 INFO     [__init__.py:459] The tag 'kobest' is already registered as a group, this tag will not be registered. This may affect tasks you want to call.\n",
      "2025-02-18:23:18:30,127 INFO     [__init__.py:459] The tag 'kobest' is already registered as a group, this tag will not be registered. This may affect tasks you want to call.\n",
      "2025-02-18:23:18:34,852 DEBUG    [__init__.py:522] File _evalita-mp_ner_adg.yaml in /opt/conda/lib/python3.11/site-packages/lm_eval/tasks/evalita_llm could not be loaded\n",
      "2025-02-18:23:18:34,855 DEBUG    [__init__.py:522] File _evalita-mp_ner_fic.yaml in /opt/conda/lib/python3.11/site-packages/lm_eval/tasks/evalita_llm could not be loaded\n",
      "2025-02-18:23:18:34,858 DEBUG    [__init__.py:522] File _evalita-mp_ner_wn.yaml in /opt/conda/lib/python3.11/site-packages/lm_eval/tasks/evalita_llm could not be loaded\n",
      "2025-02-18:23:18:38,510 INFO     [__init__.py:459] The tag 'kobest' is already registered as a group, this tag will not be registered. This may affect tasks you want to call.\n",
      "2025-02-18:23:18:38,511 INFO     [__init__.py:459] The tag 'kobest' is already registered as a group, this tag will not be registered. This may affect tasks you want to call.\n",
      "2025-02-18:23:18:38,512 INFO     [__init__.py:459] The tag 'kobest' is already registered as a group, this tag will not be registered. This may affect tasks you want to call.\n",
      "2025-02-18:23:18:38,513 INFO     [__init__.py:459] The tag 'kobest' is already registered as a group, this tag will not be registered. This may affect tasks you want to call.\n",
      "2025-02-18:23:18:38,514 INFO     [__init__.py:459] The tag 'kobest' is already registered as a group, this tag will not be registered. This may affect tasks you want to call.\n",
      "2025-02-18:23:18:41,035 WARNING  [__main__.py:317]  --limit SHOULD ONLY BE USED FOR TESTING.REAL METRICS SHOULD NOT BE COMPUTED USING LIMIT.\n",
      "2025-02-18:23:18:41,036 INFO     [__main__.py:381] Selected Tasks: ['secqa']\n",
      "2025-02-18:23:18:41,038 INFO     [evaluator.py:165] Setting random seed to 0 | Setting numpy seed to 1234 | Setting torch manual seed to 1234 | Setting fewshot manual seed to 1234\n",
      "2025-02-18:23:18:41,038 INFO     [evaluator.py:202] Initializing hf model, with arguments: {'pretrained': 'TheBloke/zephyr-7B-beta-GPTQ', 'gptqmodel': True}\n",
      "2025-02-18:23:18:41,114 INFO     [huggingface.py:135] Using device 'cuda'\n",
      "config.json: 100%|█████████████████████████| 1.31k/1.31k [00:00<00:00, 15.2MB/s]\n",
      "2025-02-18:23:18:43,168 DEBUG    [huggingface.py:491] Using model type 'causal'\n",
      "tokenizer_config.json: 100%|███████████████| 1.43k/1.43k [00:00<00:00, 11.7MB/s]\n",
      "tokenizer.model: 100%|███████████████████████| 493k/493k [00:00<00:00, 2.20MB/s]\n",
      "tokenizer.json: 100%|██████████████████████| 1.80M/1.80M [00:00<00:00, 6.33MB/s]\n",
      "special_tokens_map.json: 100%|█████████████████| 168/168 [00:00<00:00, 1.45MB/s]\n",
      "2025-02-18:23:18:45,572 INFO     [huggingface.py:375] Model parallel was set to False, max memory was not set, and device map was set to {'': 'cuda'}\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/bin/lm_eval\", line 8, in <module>\n",
      "    sys.exit(cli_evaluate())\n",
      "             ^^^^^^^^^^^^^^\n",
      "  File \"/opt/conda/lib/python3.11/site-packages/lm_eval/__main__.py\", line 387, in cli_evaluate\n",
      "    results = evaluator.simple_evaluate(\n",
      "              ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/conda/lib/python3.11/site-packages/lm_eval/utils.py\", line 402, in _wrapper\n",
      "    return fn(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/conda/lib/python3.11/site-packages/lm_eval/evaluator.py\", line 205, in simple_evaluate\n",
      "    lm = lm_eval.api.registry.get_model(model).create_from_arg_string(\n",
      "         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/conda/lib/python3.11/site-packages/lm_eval/api/model.py\", line 151, in create_from_arg_string\n",
      "    return cls(**args, **args2)\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/conda/lib/python3.11/site-packages/lm_eval/models/huggingface.py\", line 190, in __init__\n",
      "    self._create_model(\n",
      "  File \"/opt/conda/lib/python3.11/site-packages/lm_eval/models/huggingface.py\", line 628, in _create_model\n",
      "    self._model = GPTQModel.from_quantized(\n",
      "                  ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/conda/lib/python3.11/site-packages/gptqmodel/models/auto.py\", line 260, in from_quantized\n",
      "    return MODEL_MAP[model_type].from_quantized(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/conda/lib/python3.11/site-packages/gptqmodel/models/loader.py\", line 262, in from_quantized\n",
      "    model_local_path = get_model_local_path(model_id_or_path, **kwargs)\n",
      "                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/conda/lib/python3.11/site-packages/gptqmodel/models/loader.py\", line 115, in get_model_local_path\n",
      "    return snapshot_download(pretrained_model_id_or_path, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/conda/lib/python3.11/site-packages/huggingface_hub/utils/_validators.py\", line 114, in _inner_fn\n",
      "    return fn(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^\n",
      "TypeError: snapshot_download() got an unexpected keyword argument 'max_memory'\n"
     ]
    }
   ],
   "source": [
    "# TheBloke/zephyr-7B-beta-GPTQ\n",
    "!lm_eval \\\n",
    "    --model hf \\\n",
    "    --include_path /opt/conda/lib/python3.11/site-packages/lm_eval/tasks/ \\\n",
    "    --model_args pretrained=TheBloke/zephyr-7B-beta-GPTQ,gptqmodel=True \\\n",
    "    --tasks secqa \\\n",
    "    --limit 120 \\\n",
    "    --verbosity DEBUG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "f082dcb7-7352-47fb-85a8-df318acf6abf",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-02-17 20:03:45.971965: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "2025-02-17:20:03:47,451 INFO     [__main__.py:284] Verbosity set to DEBUG\n",
      "2025-02-17:20:03:47,451 INFO     [__main__.py:308] Including path: /opt/conda/lib/python3.11/site-packages/lm_eval/tasks/\n",
      "2025-02-17:20:03:49,611 DEBUG    [__init__.py:522] File _evalita-mp_ner_adg.yaml in /opt/conda/lib/python3.11/site-packages/lm_eval/tasks/evalita_llm could not be loaded\n",
      "2025-02-17:20:03:49,614 DEBUG    [__init__.py:522] File _evalita-mp_ner_fic.yaml in /opt/conda/lib/python3.11/site-packages/lm_eval/tasks/evalita_llm could not be loaded\n",
      "2025-02-17:20:03:49,617 DEBUG    [__init__.py:522] File _evalita-mp_ner_wn.yaml in /opt/conda/lib/python3.11/site-packages/lm_eval/tasks/evalita_llm could not be loaded\n",
      "2025-02-17:20:03:53,184 INFO     [__init__.py:459] The tag 'kobest' is already registered as a group, this tag will not be registered. This may affect tasks you want to call.\n",
      "2025-02-17:20:03:53,186 INFO     [__init__.py:459] The tag 'kobest' is already registered as a group, this tag will not be registered. This may affect tasks you want to call.\n",
      "2025-02-17:20:03:53,187 INFO     [__init__.py:459] The tag 'kobest' is already registered as a group, this tag will not be registered. This may affect tasks you want to call.\n",
      "2025-02-17:20:03:53,188 INFO     [__init__.py:459] The tag 'kobest' is already registered as a group, this tag will not be registered. This may affect tasks you want to call.\n",
      "2025-02-17:20:03:53,189 INFO     [__init__.py:459] The tag 'kobest' is already registered as a group, this tag will not be registered. This may affect tasks you want to call.\n",
      "2025-02-17:20:03:57,800 DEBUG    [__init__.py:522] File _evalita-mp_ner_adg.yaml in /opt/conda/lib/python3.11/site-packages/lm_eval/tasks/evalita_llm could not be loaded\n",
      "2025-02-17:20:03:57,802 DEBUG    [__init__.py:522] File _evalita-mp_ner_fic.yaml in /opt/conda/lib/python3.11/site-packages/lm_eval/tasks/evalita_llm could not be loaded\n",
      "2025-02-17:20:03:57,806 DEBUG    [__init__.py:522] File _evalita-mp_ner_wn.yaml in /opt/conda/lib/python3.11/site-packages/lm_eval/tasks/evalita_llm could not be loaded\n",
      "2025-02-17:20:04:01,366 INFO     [__init__.py:459] The tag 'kobest' is already registered as a group, this tag will not be registered. This may affect tasks you want to call.\n",
      "2025-02-17:20:04:01,367 INFO     [__init__.py:459] The tag 'kobest' is already registered as a group, this tag will not be registered. This may affect tasks you want to call.\n",
      "2025-02-17:20:04:01,368 INFO     [__init__.py:459] The tag 'kobest' is already registered as a group, this tag will not be registered. This may affect tasks you want to call.\n",
      "2025-02-17:20:04:01,370 INFO     [__init__.py:459] The tag 'kobest' is already registered as a group, this tag will not be registered. This may affect tasks you want to call.\n",
      "2025-02-17:20:04:01,371 INFO     [__init__.py:459] The tag 'kobest' is already registered as a group, this tag will not be registered. This may affect tasks you want to call.\n",
      "2025-02-17:20:04:03,833 WARNING  [__main__.py:317]  --limit SHOULD ONLY BE USED FOR TESTING.REAL METRICS SHOULD NOT BE COMPUTED USING LIMIT.\n",
      "2025-02-17:20:04:03,834 INFO     [__main__.py:381] Selected Tasks: ['secqa']\n",
      "2025-02-17:20:04:03,836 INFO     [evaluator.py:165] Setting random seed to 0 | Setting numpy seed to 1234 | Setting torch manual seed to 1234 | Setting fewshot manual seed to 1234\n",
      "2025-02-17:20:04:03,836 INFO     [evaluator.py:202] Initializing hf model, with arguments: {'pretrained': 'TheBloke/phi-2-GPTQ', 'gptqmodel': True}\n",
      "2025-02-17:20:04:03,932 INFO     [huggingface.py:135] Using device 'cuda'\n",
      "config.json: 100%|█████████████████████████| 1.59k/1.59k [00:00<00:00, 15.6MB/s]\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/bin/lm_eval\", line 8, in <module>\n",
      "    sys.exit(cli_evaluate())\n",
      "             ^^^^^^^^^^^^^^\n",
      "  File \"/opt/conda/lib/python3.11/site-packages/lm_eval/__main__.py\", line 387, in cli_evaluate\n",
      "    results = evaluator.simple_evaluate(\n",
      "              ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/conda/lib/python3.11/site-packages/lm_eval/utils.py\", line 402, in _wrapper\n",
      "    return fn(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/conda/lib/python3.11/site-packages/lm_eval/evaluator.py\", line 205, in simple_evaluate\n",
      "    lm = lm_eval.api.registry.get_model(model).create_from_arg_string(\n",
      "         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/conda/lib/python3.11/site-packages/lm_eval/api/model.py\", line 151, in create_from_arg_string\n",
      "    return cls(**args, **args2)\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/conda/lib/python3.11/site-packages/lm_eval/models/huggingface.py\", line 166, in __init__\n",
      "    self._get_config(\n",
      "  File \"/opt/conda/lib/python3.11/site-packages/lm_eval/models/huggingface.py\", line 520, in _get_config\n",
      "    self._config = transformers.AutoConfig.from_pretrained(\n",
      "                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/conda/lib/python3.11/site-packages/transformers/models/auto/configuration_auto.py\", line 1078, in from_pretrained\n",
      "    trust_remote_code = resolve_trust_remote_code(\n",
      "                        ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/conda/lib/python3.11/site-packages/transformers/dynamic_module_utils.py\", line 679, in resolve_trust_remote_code\n",
      "    raise ValueError(\n",
      "ValueError: Loading TheBloke/phi-2-GPTQ requires you to execute the configuration file in that repo on your local machine. Make sure you have read the code there to avoid malicious use, then set the option `trust_remote_code=True` to remove this error.\n"
     ]
    }
   ],
   "source": [
    "# TheBloke/phi-2-GPTQ\n",
    "!lm_eval \\\n",
    "    --model hf \\\n",
    "    --include_path /opt/conda/lib/python3.11/site-packages/lm_eval/tasks/ \\\n",
    "    --model_args pretrained=TheBloke/phi-2-GPTQ,gptqmodel=True \\\n",
    "    --tasks secqa \\\n",
    "    --limit 120 \\\n",
    "    --verbosity DEBUG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6465604-4261-43e8-8ad9-aff45e745622",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
